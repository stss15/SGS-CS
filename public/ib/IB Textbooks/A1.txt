A1 Computer fundamentals

Hl What are registers?
Registers are very small amounts of storage that are available directly on the CPU to hold
temporary data that the CPU may be working on. The registers are instruction register (IR),
program counter (PC), memory address register (MAR), memory data register (MDR) and

accumulator (AC).

Instruction register
‘When an instruction is fetched from memory, it is held in the IR within the CPU. This register

holds the instruction that is currently being executed by the CPU.
Program counter
The PC holds the address of the next instruction that is to be fetched from memory. Once the
instruction has been fetched, the PC updates to point to the next instruction that will be needed.

Memory address register
The MAR holds the memory address that is currently being fetched. The content from the PC
is copied to the MAR, and the MAR provides this address to the memory unit, so that data and
instructions can be read from or copied to that location.
Memory data register
This holds the data that has been fetched or is about to be written to the memory address

currently in the MAR.
Accumulator (AC)
This stores the intermediate arithmetic or logical results produced by the ALU.

Bl What are buses?
Buses are a critical component of the computer system, as they transfer data between various
devices, including the CPU, memory, storage and peripherals. Buses have widths that are
measured in bits. The bigger the width of the bus, the more data it can transmit at one time.
There are three main types of buses: control bus, data bus and address bus.

Control bus
The control bus is used to transmit command and control signals from the CPU to other

# Bidirectional bus:
a busi that can an:
transfer

data in both directions.

components of the system, and vice versa. Due to the need for signals to be sent and received,
this bus is bidirectional. Some of the signals that would be transmitted via the control bus are
read / write operations, interrupt requests, clock signals for synchronization and status signals
from hardware components.

Data bus
The data bus carries the data being processed between the CPU, memory and other
peripherals. The width of the data bus is important for determining the amount of data it can
transfer at one time. Common data bus widths are 8, 16, 32 and 64 bits. As data needs to be

read from and written to memory, data buses are usually bidirectional.

Address bus
The address bus is used to transmit the address that is to be read [rom or written to in
memory. The width of this bus determines the memory capacity of the system. For example, a
32-bit address bus can address 2** memory locations.

A1.1 Computer hardware and operation

B What are cores?
CPUs come in a number of different configurations. These include single-core processors,

multi-core processors and co-processors.

Single-core processors
This CPU has a single processing unit, meaning it can only handle one task at a time. These

are more often found in low-end computers or older machines. They are adequate for simple
tasks that do not require heavy multitasking. Single-core processors are able to run more than

a single application at a time, but the CPU has to be shared between these applications, which
can impact performance.

Multi-core processors
A CPU with multi-core processors has two or more cores that can run multiple instructions
simultaneously. These are often referred to as dual-core (two processors), quad-core (four

processors), hexa-core (six) or octa-core (eight). Their performance is significantly faster

than single-core processors and they are ideal for multitasking, gaming and servers. However,
software has to be written to take advantage of these extra cores. Older software that does not

do this would likely run at a similar speed as on a single-core processor.
Co-processors
A co-processor is a special type of pracessor that has a specific job to support the main CPU.
These are built with a distinct purpose to achieve optimal performance compared to a general-

purpose CPU. Tasks are offloaded by the CPU to the co-processor so they can run in parallel,
enhancing the system’s performance. Examples of co-processors are graphics processing units
(covered in Section A1.1.2), audio processors and digital signal processors (DSPs), which are

used in telecommunications and image compression.

(;Common mistake
A common mistake is thinking that adding more cores to a CPU always makes it faster in a

W N =
moh

straightforward way — like assuming a dual-core CPU is twice as fast as a single-core, or a quadcore is four times faster. This isn't always true, because the speed increase depends on how well
the software can use multiple cores at the same time. Many programs aren’t designed to take
full advantage of multiple cores, so the extra cores may not make a noticeable difference. Other
factors, such as memory speed and how the CPU is designed, also affect how fast it can run. So,
just having more cores doesn't automatically mean much faster processing.

What is the primary function of the arithmetic logic unit (ALU) in a computer’s CPU?
How does the control unit (CU) direct the operations of the CPU?
Why is the program counter (PC) important for executing a sequence of instructions?
What roles do the data bus and address bus play in the functioning of the CPU?
How does the memory address register (MAR) work in conjunction with other CPU
components to access memory?

6

How do multi-core processors differ from single-core processors in handling tasks?

A1 Computer fundamentals

A1.1.2 Role of a graphics processing unit
A graphics processing unit (GPU) is a specialized electronic circuit designed to accelerate the

rendering of images, videos and animations by performing rapid mathematical calculations.
Initially developed to handle the demanding graphics workloads of video games and visual

applications, GPUs have evolved to play a crucial role in various fields beyond graphics
rendering. Their structure, consisting of thousands of small, efficient cores, allows them
to process multiple tasks simultaneously, making them exceptionally well-suited for
computationally intensive applications. This capability has led to their widespread adoprion
in scientific research, machine learning, artificial intelligence and cryptocurrency mining. By
offloading these intensive tasks from the CPU, GPUs enhance overall system performance,
enabling faster and more efficient data processing and visualization.
M A graphics processing
unit (GPU)

B Graphics processing

M Video game graphics

GPUs are designed with a highly parallel structure, enabling them to perform many
# Shaders and
textures: techniques
used in 3D rendering to
apply effects, lighting
and details to models.
# Parallel processing:
the ability of the
GPU to perform
many calculations
simultaneously due to its
highly parallel structure.
# Matrix and vector
multiplications:
fundamental operations
in machine learning and
graphics that involve
complex mathematical
calculations.

calculations simultaneously. This makes them exceptionally well-suited for rendering the

complex and resource-intensive graphics seen in modern video games and applications. They
also handle the application of shaders and textures to 3D models, which includes lighting,
shading and texture mapping, enhancing the realism of the scene.

H Video processing
GPUs assist in the decoding and encoding of video files, making processes such as playback,
streaming and editing more efficient and faster. This is particularly helpful for those working
with high-resolution video files of 4k or higher.

B Artificial intelligence and machine learning
GPUs were originally created for graphical processing; however, in the early 2000s, researchers
and engineers began to recognize their potential for handling general-purpose calculations,
including those required for machine learning and Al The shift towards using GPUs for this
was largely due to their ability to perform many simple calculations simultaneously, and
because many GPUs can be run in parallel. Many Al models rely heavily on matrix and vector
multiplications, and GPUs far outperform a CPU when trying to process these quickly.

A1.1 Computer hardware and operation

4 Deep learning:
a subset of machine
learning that uses an
artificial neural network
to imitate the design
of the human brain to
find generalizations
in complex data
that can be used for
decision-making.

This realization gained momentum as machine learning models, especially deep learning
models, became more complex and required significant computational power for training,
By the mid-2000s, GPUs had become essential tools in the field of AT and machine learning,
transforming how data scientists and researchers approached problems, significantly reducing

the time it took to train complex models.

B Blockchain and cryptocurrency mining

# Proof of work: a
consensus mechanism
requiring cryptominers
to solve complex
problems to add a new
block to the blockchain.

M The cryptocurrency boom — at its peak in November 2021, the total market capitalization of
cryptocurrencies reached approximately $3 trillion

In 2010, the use of GPUs for Bitcoin mining surged as miners discovered that GPUs
significantly outperformed CPUs in solving cryptographic puzzles, such as finding the nonce

in the hashing algorithm for the proof-of-work system. This realization led to a dramatic shift
towards GPU mining. The cryptocurrency boom between 2017 and 2021 further escalated the
demand for GPUs, resulting in skyrocketing prices and global shortages.
As of 2023, this demand had reduced somewhat and prices of GPUs were becoming more
stable. This was for a number of reasons:
B The volarility and reduced profitability of cryptocurrency mining had led to less demand

for GPUs, specifically for mining purposes.
® Big manufacturers had increased production to meet the demands.
m

Application-Specific Integrated Circuits (ASICs), which are specifically designed for
mining, had largely replaced the use of GPUs in many mining operations.

1

What is the role of a graphics processing unit (GPU) in a computer?

3

Why have GPUs become essential in fields such as artificial intelligence, machine learning
and cryptocurrency mining?

ATNO TH

How do GPUs enhance the performance of video games and video processing tasks?

A1.1.3 Differences between the
CPU and the GPU (HL)
The central processing unit (CPU) and the graphical processing unit (GPU) are both core

components of modern computers. They are designed differently, which is why they are used
for different kinds of tasks. The CPU is great for handling various jobs, but the GPU is better for
doing the same job many times on a lot of data at once.

A1 Computer fundamentals

H Design philosophies
CPUs are generally called “general-purpose processors” because they can handle many types
of tasks. They are designed to run the operating system, process user input and manage

programs. CPUs are good at tasks where decisions need to be made quickly, and where
different types of work are being done at the same time.
GPUs are specialized processors because they tocus on specific types of tasks. They are
made for processing large amounts of data in parallel. This means they can work on many
calculations at the same time. For example, GPUs are used to process images and videos
because they can work on thousands of pixels at once.

B Core architecture
The CPU has only a few cores, but these cores are very powerful. Each core can handle many
different instructions, but it works best when doing one task at a time. This makes the CPU

very good for such tasks as running the operating system, where quick responses are needed.
CPUs also have features including branch prediction (where the CPU tries to guess what will

happen next) and out-of-order execution (where the CPU can work on tasks that are ready
before others).
The GPU has many smaller cores. These cores are not as powerful as the CPU cores, but there
are thousands of them, and they all work at the same time. This is why the GPU is very good

for tasks such as rendering 3D images, where many similar calculations need to happen at
once. The GPU’s architecture is designed to work on large sets of data all at the same time.

Bl Memory access and power efficiency
The CPU and GPU access memory differently. The CPU uses a smaller, high-speed memory
cache to get data quickly. This is useful when the CPU needs to access small amounts of data

many times, such as when running programs or handling user inputs.
The GPU uses its own special memory called VRAM (video RAM). VRAM has a very high
bandwidth, meaning it can move large amounts of data at once, such as images and videos.

However, the GPU uses more power because it must process a lot of data at the same time,
especially when rendering videos or running complex simulations.
B Comparison of central processing units (CPUs) and graphics processing units (GPUs)
Processor | Processing
CPU

operations such as arithmetic,
lagic and controlling input/
output (I/Q) operations, as
directed by the operating
system.
GPU

# Rendering: the
process of generating
an image from a model
by means of computer
programs.

Architecture

Functionality

It is a general purpose
CPUs generally have fewer
Allows the user to switch
processor, capable of handling | cores. General user devices
between multiple tasks
many different tasks. It
tend to have between 4 and
and applications. This
executes the instructions of
8 cores; however, there are
makes it ideal for running
computer programs, invalving | some advanced CPUs that now | the operating system

It is a specialized processor,
with a focus on handling
graphics, rendering images,
video and animations

| have 64 cores or mare. Each
core is very versatile, making it
capable of handling complex
computations that require
sequential processing.
Composed of hundreds or
thousands of small cores that are

well-suited for tasks that can be
run in parallel. While each core

is not as powerful as a standard
CPU core, the high number of
cores allows them to perform
a large number of calculations
simultaneously, making them
perfect for graphical processing

A1.1 Computer hardware and operation

and general software
applications.

Suited for tasks that require
simultaneous processing
of large blocks of data,
such as rendering images,

video processing and deep
learning applications.

AINO TH

(;Key information
To summarize, CPUs are better for tasks that require high-speed, complex decision-making and
versatility. GPUs are better when the same operation needs to be performed on many data points
simultaneously. This means that for tasks such as gaming, video editing and computational research
(Al and machine learning), GPUs often significantly outperform CPUs.

B How the CPU and GPU work together to increase
video-game performance
When playing video games, the CPU and GPU work together to deliver a seamless and
immersive experience. The CPU handles the game’s core logic, including rules, physical
calculations and AT behaviour. It processes the inputs from the player (processing the
outcomes of their actions and updating the game state accordingly). The GPU’s primary role
4 Vertex and pixel
data: data used by
the GPU to render 3D
objects and images.

is to render the game’s visuals. It processes vertex and pixel data to draw images on to the
screen, including 3D objects, textures and effects such as lighting and shadows.

# Frame: a single image
in a sequence of images
that makes up a video or
animation.

Run benchmark software on your device to see your overall system performance. There are many

options out there that you can search for; https://novabench.com and www.userbenchmark.com
have free versions.

Typical scenario
1

Player input: The player presses a key to move a character. The CPU processes this input,
updates the character’s position based on game physics and determines the new game state.

2 Data preparation: The CPU prepares the new position and state data and sends it to the GPU.
3

Rendering: The GPU updates the frame with the character’s new position, applies lighting
and shading and renders the scene.

4 Display: The rendered frame is displayed on the screen, providing immediate feedback ro
the player.

How do the CPU and GPU work together to enhance video-game performance?
Why is a GPU better suited than a CPU for tasks such as video rendering or Al computations?
What are shaders and textures, and how do they contribute to the rendering process
handled by the GPU?

A1.1.4 Purposes of different
primary memory types
Hl Memory types
The primary memory of the computer stores data and instructions that the CPU needs in
order to process tasks. Primary memory includes several different types: RAM (random access
memory), ROM (read-only memory), caches and registers (covered in Section A1.1.1). These are

all types of primary memory, meaning they are used directly by the CPU.
A1 Computer fundamentals

RAM
RAM (random access memory) holds instructions and data

for programs that are currently running. For example,
when you open an app on your phone or computer, it loads
into RAM so that is can be accessed quickly by the CPU.
RAM is volatile, meaning that it loses its contents when
the power to the computer is turned off. This is why, when
playing a game, you lose your progress unless you save the
game (which is then stored in secondary memory).
One real-world example of using RAM is in smartphones,

which use RAM to switch quickly between apps. When you
leave an app, it stays in the RAM, so you can return to it

quickly without reloading it from scratch.

ROM
ROM (read-only memory) is used for storing instructions
that are very rarely modified. ROM is used for the BIOS
(basic input / output system) of the computer, which is

located on the motherboard. The BIOS main role is to
initialize and test the system hardware components on
startup, and to load the operating system (OS) software
v.

a

'

; AT

;\\

=

M Read-only memory (ROM) attached to a motherboard

from the secondary memory storage into the RAM, ready
for the CPU to fetch, decode and execute the instructions.

@ Volatile: a type of

ROM is non-volatile memory, meaning it does not lose its contents when the compurer does

memoary or storage that

not have power. While ROM is “read only”, meaning it cannot easily change its data, most

loses its data when the

modern computers use flash memory, which allows for updates and reprogramming. This

power is turned off.

allows motherboard companies to update their software when required.
A real-world example of using ROM is in smartphones, where ROM stores the operating
system and core applications, which do not change unless you perform an update. This ensures
that your phone can boot up reliably every rime.

Cache (L1, L2 and L3)

CPU

Cache memory

Main memory

Secondary memory

M The order a CPU goes through when trying to retrieve data

Cache memory is small, but provides high-speed access to the CPU compared to the RAM.
It acts as a buffer between the CPU and the slower RAM, storing frequently used data

and instructions.
There are three types of cache: L1, L2 and L3, each with different sizes and speeds. The closer
to the CPU, the faster it is.

A1.1 Computer hardware and operation

(E_

B L1 cache is located directly on the CPU, making it the fastest type of cache. It can be
accessed almost instantly due to its location. However, it is also the smallest, often only
a few kilobytes in size (32KB to 128KB per core). Each CPU core usually has its own
L1 cache, which is typically split into two sections: L1i to store instructions and L1d to
store data.
B L2 cache can either be on the CPU, like L1, or situated very close to the CPU. L2 cache
is larger than L1 and can be up to several megabytes in size (256KB to 2MB per core),
providing more storage for frequently used instructions. It is faster than L3, but slightly
slower than L1, though it still significantly speeds up processing by reducing the need to
fetch data from the slower RAM.

® L3 cache is often located the furthest from the CPU chip. L3 cache may be shared on
multiple-core CPUs, whereas L1 and L2 are usually exclusive to a single core. It is the largest

of the three, and can be up to tens of megabytes in size (2MB to 64MB shared across all
cores). It is the slowest of the three types of caches, but is still significantly faster than RAM.
The terms cache hit and cache miss are used to describe the efficiency of the CPU’s cache

# Cache hit: when the
CPU requests data and

memory when retrieving data. A cache hit is the ideal scenario, where the CPU requests data

it is found in the cache

and it is found in the cache memory. A cache miss means it was not found, necessitating

memaory.

retrieval from the slower main memory (RAM) or even slower storage (SSD / HDD).

# Cache miss: when
the CPU requests data

The percentage of hit rate determines the efficiency and effectiveness of the cache. A low

and it is not found in
the cache memory,

necessitating retrieval
from slower main
memory or storage.

percentage means the system would suffer more from latency, where the data has to be fetched
from elsewhere, hindering pertormance speed. Systems with a larger cache size will generally
perform better, as well as systems with more intelligent prefetching techniques that can predict
which data will be needed soon and load it into cache ahead of time.

(;Top tip!
Imagine an onion with its layers representing the levels of cache:
B

L1 cache is the smallest and fastest, like the very centre of the onion, where everything is

tightly packed and closest to the core of the CPU.
B L2 cache is slightly larger and slower, like the next layer out - still close to the centre, but
not as quick to access as the very core.

B L3 cache is the largest and slowest, like the outer layers of the onion. It's still important, but
it takes a bit longer to get to, just like how the CPU takes a bit more time to access data in
L3 cache compared to L1 and L2.

Optimizing CPU performance with cache
The cache plays a critical role in ensuring that the CPU can access data as quickly as possible.
When the CPU finds the searched-for data in the cache (a cache hit), the data can be processed

very quickly. However, when there is a cache miss, the CPU has to look for the data in the
slower memory, which causes a delay.
Imagine you are playing a video game on a computer. The CPU frequently checks the L1, 1.2
and L3 cache to find the data it needs to run the game smoothly. The game’s core functions,
such as player controls and game logic, might be stored in the L1 cache, while the less
frequently accessed data, such as background textures, may be in the L3 cache. The layering

system helps to ensure that the game runs smoothly, without interruptions.
A CPU with a larger cache or more advanced prefetching (a technique where the CPU predicts
what data it will need and loads it into cache ahead of time) has fewer cache misses and

performs better overall.

A1 Computer fundamentals

1

What is the main purpose of RAM in a computer system, and why is it considered volatile?

2

How does ROM differ from RAM in terms of its function and volatility?

3

Why is cache memory important for CPU performance, and how do the different levels
of cache memory (L1, L2, L3) vary in terms of speed and size?

4

What happens during a cache hit and a cache miss, and how do these events impact
systern performance?

A1.1.5 The fetch-decode-execute cycle
The fetch—decode—execute cycle, also known as the “instruction cycle”, is the fundamental
process that a CPU uses to execute instructions. The cycle consists of three main stages:
Execute

Fetch

1

TFetch: The CPU fetches an instruction from the memory.

2

Decode: The CPU interprets the instruction and prepares the necessary operations to execute it.

3

Execute: The CPU performs the actions required by the instruction.

B Little Man Computer
Decode

M The fetch-decode—
execute cycle

An easier way to see these stages carried out in more detail is to use an educational CPU model

known as Little Man Computer, which you can search for online or use the one available
here: https://peterhigginson.co.uk/Imc. This model uses assembly language — a simple set of
instructions, each represented by three letters, which is stored as a three-digit code in the
memory. The full set of instructions is:
Instruction | Code

Description

INP

901

Input a value and store it in the accumulator

QuT

902

Output the value from the accumulator

DAT

N/A

Used to define data values directly in memory at the point of declaration, often
for constants or variables

LDA

5XX

Load the value from the specified memory address into the accumulator

STA

3XX

Store the value in the accumulator at the specified memory address

ADD

1XX

Add the value from the specified memory address to the accumulator

SUB

2XX

Subtract the value from the specified memory address from the accumulator

HLT

000

Halt the program

BRA

BXX

Branch (jump) to the specified memory address

BRZ

TRX

Branch to the specified memory address if the accumulator is zero

BRP

8XX

Branch to the specified memory address if the accumulator is positive

Enter the following program into the left-hand column and assemble into RAM. You will see
the three-digit representation for each instruction stored at a memory address on the right. For
example, LDA 4 has been stored as 504 in memory address 0.
LDA 4
ADD
STA 5
HLT
DAT

23

DAT

12

A1.1 Computer hardware and operation

Your LMC should look like this:

000 J 000§ oo J oo Jf 0o | 000 Jf 000 Jf ovo Jf 000 Jf 000 |
0vo | 000§ 000 J§ 000 Jf 0oa | 000 | 000 I oo 000 Jf 000
000§ 000 Jf 000 J§ ooo J§ o0 i ooo I 0oo Jf coo I 0o I ooo
000§ 000 000 J§ 000 J§ 000 Jf 000 ) 000 | 000 Jf 000 J 000
i 000 000§ ovo i 0oo Jf 000 | 000 Jf 000l 000§ oo Jf 000 |
mmmmmmmmmm
"

Irmmmmmmmmmm
| 000 000§ voo I ooo I oo oo Jf 000l ooo oo Jf 00 |
I-Irmmmmmmmmmm

;
e

e o

M Peter Higginson's LMC model

First cycle
Click step.
1

TFetch: The PC (program counter) is currently set to 0, so the instruction at memory
location 0 is fetched (504) by opening the 0 address in RAM using the address bus and
fetching the instruction on the data bus. The control bus sends a read signal to initiate this
process. 5 is stored in the instruction register and 04 in the address register.
‘While this happens, you will see the PC gets incremented to 1 via the ALU, ready for the
next instruction.

2

Decode: Once the instruction is fetched, the CPU decodes the instruction. The control unit

uses the control bus to co-ordinate this process. The instruction stored in the instruction
register is 5, which decodes as “load into the accumulator”. The address register 04

indicates the address of the data to load.
3

[Execute: The command is then carried out. Address 4 is opened on the address bus, and

the control bus sends the appropriate signals to retrieve the data (23) from that location on
the data bus and store it into the accumulator.

Second cycle
Click step.
1

TFetch: The CPU now uses the PC to know which instruction to fetch next: 1 is currently
stored. Address 1 is opened, and the instruction 105 is fetched. The control bus
sends a read signal to initiate this. 1 is stored in the instruction register and 05 in the
address register.
The PC is incremented to 2 by the ALU.

2

Decode: The instruction 1 is decoded as “add to accumulator”; the address register is the

address of the data to add (5). The control unit uses the control bus to co-ordinate this.
3 Execute: Address 5 is opened, the data 12 is fetched and both the accumulator
(currently 23) and the fetched data (12) are passed to the ALU. The result of 23 + 12 is
stored in the accumulator (35).

A1 Computer fundamentals

Third cycle
Click step.
1

TFetch: The PC is currently 2, so the instruction at memory address 2 is fetched (305). The

control bus sends a read signal to initiate this. 3 is stored in the instruction register, and 05
is stored in the address register.

The PC is incremented to 3 via the ALU.
8]

Decode: The instruction 3 decodes as “store accumulator to address” and the address
register gives the location of where to store the data (05). The control unit uses the control
bus to co-ordinate this.

w

Execute: Memory address 5 is opened via the address bus, and the control bus sends the
appropriate signals to send the accumulator contents down the data bus and store them at
address 5 (overwriting the current data).

Fourth cycle
Click step.
1

Fetch: The PC is currently 3, so the instruction at memory address 3 is fetched (000). The

control bus sends a read signal to initiate this. 0 is stored in the instruction register, and 00

is stored in the address register.
The PC is incremented to 4 via the ALU.
8]

Decode: The instruction 0 decodes as “halt”. The control unit uses the control bus to signal
this operation.

3 Execute: The computer halts all operations and ends the program.

(‘Common mistake
A common mistake is assuming that the program counter (PC) gets updated after the execute
stage of the fetch—decode—execute cycle. The PC is usually updated during or immediately after
the fetch stage, so it points to the next instruction in memory before the current instruction
is even decoded or executed. This ensures that the CPU always knows where to find the next
instruction in the sequence.

Write an LMC program to:

N

input a number and output whether it is positive or zero

w

input two numbers, add them, and output the result
calculate the sum of the first five natural numbers

vi B

1

input three numbers and output them in ascending order.

1
2

input two numbers and output the larger one

What are the main steps in the fetch—decode-execute cycle, and why is this cydle
fundamental to CPU operations?
How does the CPU use the address, data and control buses during the
fetch—-decode-execute cycle?

3

Why is the interaction between memory and registers crucial during the fetch phase of
the CPU cycle?

A1.1 Computer hardware and operation

ATNO TH

A1.1.6 The process of pipelining in
multi-core architectures (HL)
4 Multi-core
architectures: systems
with multiple CPU
cores on a single
chip, allowing parallel

Pipelining is a powerful technique used in multi-core architectures to enhance CPU
performance by overlapping the execution of multiple instructions. To understand this

concept, imagine a carwash service that processes cars through several stages: initial wash,
detailed cleaning, rinse and drying. Each stage takes five minutes.

execution of instructions

and tasks.

M A carwash team operating in parallel execution to get the job done faster

In a non-pipelined operation, each car must complete all stages before the next car begins:
Car
A

initial
wash

detailed
cleaning

rinse

drying

B

initial
wash

detailed
cleaning

rinse

drying

The total time it takes to process two cars is 5 x 8 = 40 minutes. So the time to clean one car is
40/ 2 = 20 minutes.
The problem with this system is that, once car A has had the initial wash, that stage is then left
idle, waiting for car A to complete, before car B enters. This is not efficient and, if we continue with

this system, the only way we can improve the operation is to increase the speed of each stage.
It is the same situation with the performance of a CPU, where we are limited by the speed of
the hardware, and improving this can be very expensive. Being more efficient with what we
have is more beneficial.
In a pipelined solution, as soon as car A finishes a stage, car B enters that stage:
Car
A
B

initial wash

detailed cleaning | rinse
initial wash

drying

detailed cleaning | rinse

drying

The total time it takes to process two cars is 5 x 5 = 25 minutes. So the time to clean one car is
25/2 = 12.5 minutes.
In this pipelined solution, rather than one stage sitting idle until the cycle is complete, the
moment it is finished with car A, car B enters thar stage.

Bl Design of a basic pipeline
In a pipelined processor, the pipeline consists of multiple stages or segments situated between
an input end and an output end. Each stage performs a specific operation, and the ourput of

one stage becomes the input for the next. Intermediate outputs are held in interface registers,
also known as “latches” or “buffers”. All stages and interface registers are synchronized by a

common clock, ensuring co-ordinated operation across the entire pipeline.
A1 Computer fundamentals

In the CPU, the fetch—decode—execute cycle is divided into distinct stages:
1

Fetch: The instruction is retrieved from memory.

2

Decode: The instruction is interpreted to understand the required operation.

3

Execute: The operation is carried out.

4 Memory access: Any necessary data is read from or

Cycle
1

L]

2

3

written to memory.

4

5

D000

;

s

O

T

D

\i] - L/ U

L
DO0RDEQD L

m[

][

}[

]

() (

A

m

“ [

] l

l

\

pipeline, ensuring continuous and efficient processing

A

___/

the carwash example, pipeline performance in CPUs is

™

[

]

Rather than measuring performance in minutes, as in

measured in cycles. To manage the five stages mentioned,

C

.

l [

CPU register.

)

—

i

‘Write back: The result is written back to the

i

mrssmimmnicisoyors

the CPU is constructed with a five-stage instruction
of instructions. A well-optimized pipeline can achieve
close to one instruction per cycle, maximizing the

)

M Example of a pipeline cycle

CPU’s performance by reducing idle times and ensuring
continuous instruction processing.

B How cores in multi-core processors work independently and
in parallel
In multi-core architectures, each core can independently execute its own pipeline of
instructions. This is similar to having multiple carwash teams, each capable of processing

cars simultaneously but independently. They are also capable of parallel execution when
dealing with larger, more complex tasks, where each team completes a part of a larger task to
improve execution time. This combination of pipelining and parallelism significantly boosts
computational efficiency, enabling modern processors to handle complex and resourceintensive tasks more effectively.

Independent execution
Each core in a multi-core processor has its own set of pipelines, allowing it to fetch, decode,
execute and write back instructions independently of the other cores. This independence
means that, even if one core is handling a computationally intensive task, other cores can

continue to execute their tasks without waiting for the first core to finish. This increases
overall efficiency and utilization of the CPU resources.
Consider our carwash with multiple bays:
Team 1 (Core 1): Car A undergoes initial wash — detailed cleaning — rinse — drying
Team 2 (Core 2): Car B undergoes initial wash — detailed cleaning — rinse — drying
While Team 1 is drying car A, Team 2 might be rinsing car B. Both bays operate independently.

Parallel execution
Parallel execution takes the concept further, by allowing multiple cores to work on different
parts of a single large task or multiple tasks simultaneously. For instance, in a multi-threaded
application, different threads can be scheduled on different cores, with each core processing its

thread in parallel. This drastically reduces the time needed to complete complex computations.
Imagine a large car that needs washing, detailing and interior cleaning. Multiple teams (cores)
can work on different sections of the car at the same time:
Team 1 (Core 1): Washes the exterior

Team 2 (Core 2): Details the interior
A1.1 Computer hardware and operation

ATNO TH

Team 3 (Core 3): Cleans the wheels and undercarriage.

Each team works in parallel on different parts of the same car, drastically reducing the overall
time required to complete the job.

GTop tip!
Think of pipelining like an assembly line in a factory. Each stage in the pipeline handles a
different part of the process and, once a stage finishes its task, it passes the work to the next
stage and immediately starts on a new task. This way, multiple instructions are being processed
simultaneously, just at different stages. In a multi-core architecture, imagine multiple assembly lines
(cores) working in parallel, each running its own pipeline. This set-up greatly increases efficiency
because more tasks are completed in less time, and the CPU can handle multiple instructions or
even different programs at one time.

1

What is pipelining and how does it improve performance?
How does a non-pipelined CPU differ from a pipelined CPU in terms of instruction execution?

3

What are the stages of a basic instruction pipeline, and how do they function together in
a CPU?

4

How do multi-core processors use pipelining and parallel execution to improve
computational efficiency?

A1.1.7 Internal and external types

of secondary memory storage
B Internal storage
Hard disk drive (HDD) and solid state drive (55D)

cache
controller

NAND

flash

memory
spindle

actuator arm

actuator axis

M The internals of an HDD and an S5D

A1 Computer fundamentals

Hard disk drives (HDD) and solid state drives (SSD) are the most typical storage solutions for

personal computers. HDDs are older technology but are still often used, especially in nonmobile devices, as they are relatively cheap compared to the amount of storage they offer.
HDDs utilize a spinning magnetic disk to read / write data. They are suitable for storing large
volumes of data, such as media files, backups and documents, where speed is not so critical.

SSDs have no moving parts. They use flash memory to store data, offering high-speed data
access and durability. This makes them very popular in portable devices such as laptops and

tablets. They are ideal for operating systems, software applications and games due to their fast
read / write speed, which enhances the overall system performance.
M HDD vs 55D
Feature

HDD (hard disk drive)

SSD (solid state drive)

Storage technology | Magnetic storage with spinning disks and read / write heads | Flash memory with no moving parts
Speed

Slower read / write speeds (generally 50-150 MB/s)

Faster read / write speeds (generally 200-500 MB/s)

Durability

Maore prane to physical damage due to moving parts

Maore durable; resistant to physical shock

Noise

Produces noise due to moving parts

Silent operation

Power consumption | Higher power usage due to mechanical parts

Lower power consumption

Cost

Generally cheaper per GB

More expensive per GB

Capacity

Awailable in larger capacities {up to several TB)

Typically available in smaller capacities (up to several TB,
but at a higher cost)

Weight

Heavier due to mechanical components

Lighter

Heat generation

Generates more heat due to moving parts

Generates less heat

There is another form factor for SSDs that is currently popular and offers various advantages.
M.2 SSDs look like a stick of chewing gum. They are very small and thin, and rake up a lot
less space than a standard SSD. M.2 NVMe SSDs are also faster than 2.5” SATA SSDs and are
considered easier to install — you just slot them into the motherboard and use a single screw to
keep them in place.

B M.2 55D

eMMC (Embedded MultiMediaCard)
In low-cost devices, such as entry-level smartphones and budget laptops, where all the benefits
of S5Ds are not essential, eMMCs are a popular choice. They are also a type of flash storage
that utilizes NAND flash memory. They are soldered directly on to the motherboard of the
device. While the capacity and speed do not match a standard SSD, their performance is
adequate for basic computing needs and simple applications.
B Two eMMCs

A1.1 Computer hardware and operation

B External storage
Hard disk drive (HDD) and solid state drive (S5D)
As external storage solutions, both HDD and SSD are popular choices. Their performance and
comparison are identical to the internal versions. Which is used depends on the requirements

of the user. If you require quick file transfers, backups and a portable solution that is less likely
to be impacted by being carried around, SSDs are the best choice. If you need to do extensive

backups, store media files or transport large files, but speed is less critical, you may decide an
M An external 55D

1IDD is the better option.

Optical discs and optical drives

M From left to right: CD, DVD and Blu-Ray

Optical drives that read / write optical discs, such as CDs, DVDs or Blu-Rays, are becoming
less popular, but are still a consideration for external media storage. The cost of an optical disc
is low compared to an HDD or SSD and, while their read / write speeds may be slower, they are
sufficient for data archiving and playback. However, the discs are prone to scratches, especially
if they are not stored correctly, and they require an optical drive to read and write to them, and
these are becoming less common in devices these days.

Memory cards
Memory cards are compact storage devices often used in cameras, smartphones and other
portable devices. They are ideal for expanding storage in mobile devices and for storing photos

and videos in cameras, using NAND flash memory. They come in multiple sizes, such as SD,
microSD and CompactFlash, catering to different devices and space requirements. They are

known for their durability — they are resistant to physical shocks, extreme temperatures and
water, making them ideal for portable devices. Their read / write times are generally slower
# RAID (Redundant
Array of Independent
Disks): a data storage
technology that
combines multiple
physical drives into a
single logical unit to
improve performance,
provide redundancy and
ensure data protection.

than SSDs, but outperform those of optical discs.
Network Attached Storage (NAS)
NAS is a dedicated file storage connected to a network that allows multiple users to access
data. It is often used in homes or businesses for centralizing data storage, file storage
and data backup. NAS is usually made up of multiple HDDs or SSDs configured in RAID
(Redundant Array of Independent Disks) configuration. It is normally connected to the
network via Ethernet, and runs a lightweight operating system designed for file storage, and
the management and sharing of files. As it uses multiple HDDs or S5Ds, its capacity is usually

high, and it is possible to expand the system further by adding additional drives.

A1 Computer fundamentals

B Memory cards

W NAS storage solution

1

What are the primary differences between an HDD and an SDD in terms of performance
and durability?

2

Why might a low-cost device, such as an entry-level smartphone, use eMMC storage
instead of an SSD?

3

What advantages do NAS (Network Attached Storage) systems offer for home or
business environments?

4

How do memory cards compare to optical discs in terms of durability and data
storage capabilities?

A1.1.8 Describe the concept of compression
Compression is the process of encoding information using fewer bits than the original
representation. Making file sizes smaller has two main advanrtages: it takes less room on
secondary storage and it is faster to transfer across a network. There are two main types of
compression: lossless and lossy.

Il Lossless vs lossy compression
Lossless compression is when data is compressed to a smaller size, but can be restored back to
the original without any loss of information. This is important for files such as text files and
databases, where a loss of information would be critical. This technique works by identifying
* Statistical

and eliminating statistical redundancy within the data, and this process can be reversed

redundancy: the
repetition of information
within a data set that

when needed.

does not contribute to

its unigueness.

Lossy compression generally ourperforms lossless compression when it comes to file sizes;
however, it reduces files by permanently eliminating certain information. This information
is redundant or less critical data, resulting in a compressed version that is not identical
to the original but is, ideally, indistinguishable from the original to human senses. Lossy
compression is commonly used for compressing multimedia files such as images, audio and
video, where some loss of quality is acceptable in exchange for significantly reduced file sizes.

A1.1 Computer hardware and operation

This can be seen in the images below. While it may be pretty ditficult to visually distinguish
the difference in quality, the lossy version uses 50 per cent less data than the original.
®

.

*

"

Original

Lossless

Saved

Lossy

Saved

1.73 MB

1.58 MB

9%

886 KB

50%

B Run-length encoding (RLE)
Run-length encoding is an effective lossless data-compression technique used to reduce the
size of files containing many consecutive repeated characters.

For example, take this string:
AAAAABBBCCDAA
RLE looks for “runs” where a character is repeated. In the example above, we have five runs:
AAAAABBB CCDAA
Omnce RLE has identified these, it encodes the run by replacing it with a pair: the character that
repeats and the number of repetitions. So, the runs above become:

5A3B2C 1D 2A
The encoded string is then stored as:
SA3B2CID2A
If we assume each letter stores 8 bits of information, the initial data is 13 x 8 = 104 bits, or

13 bytes.
After compressing with RLE, the data is 10 x 8 = 80 bits or 10 bytes: a 23 per cent reduction
in size.
RLE is straightforward to implement and it is very effective for data with lots of repetitions,
such as simple graphics and certain types of text files. RLE was often used on fax machines,

which would send text documents via the telephone line. This was because they contained a
lot of white space, which meant RLE could achieve compression ratios of up to 8:1. However,

for data that does not contain many repeated characters, like a portrait photograph, RLE may
not be very effective and, in some cases, may even increase the file size.

Create an RLE application that has two options: compress or decompress.
The compress option should receive a string and output the encoded version using the
RLE algorithm.
The decompress option should do the opposite.

A1 Computer fundamentals

H Transform coding
Image

Construct

Forward

(N x N)

nxn

transform

sub-images

Quanti

y|

AR

"l

Symbol

Compressed

encoder

image

M The stages of transform coding

Transform coding is a form of lossy compression often used in JPEG image compression or
MP3 audio compression.
Using JPEG compression as an example:
B Transform coding takes an image of N x N size and sections it into smaller sub-images of
size n x n.

B Then the forward transform is carried out on each of the sub-images. The forward transform
can use different algorithms, depending on the type of file compression, but for JPEGs
DCT (discrete cosine transform) is used. This takes the image data from the spatial domain
# Low-frequency
data: correspond
to slow changes in
pixel values, such as
broad areas.

(pixel values) to the frequency domain. The output breaks the sub-image down into lowand high-frequency coefficients.
B These frequency coetficients are then passed to the quantizer. This step significantly
reduces file size by simplifying the frequency coefficients obtained from the DCT. The
purpose of quantization is to reduce the precision of high-frequency components (the

# High-frequency
data: correspond to
rapid changes in pixel

fine details) rather than low-frequency components. This is because the human eye is less
sensitive to high-frequency data loss compared to low-frequency detail. The extent of the

values, representing

quantization determines the compression level and the quality of the final image.

fine details, edges

B The final step of transform coding is the symbol encoder. This is where the quantized

and textures.

coefficients are further compressed using entropy coding techniques. This runs through
three further algorithms to reduce the file size by efficiently representing the frequency of

occurrence of each symbol. The algorithms used at this stage are (in this order):
1

Zigzag scan

2 Run-length encoding (RLE)
3

Tuffman coding.

N

Explain the difference between lossless and lossy compression.

W

What are the two main advantages of compressing files?
How does run-length encoding (RLE) work, and in what types of files is it most effective?

B

-

Once this stage has finished, the final compressed image is complete.

Describe the process of transform coding in JPEG image compression and explain why it
is considered a lossy compression method.

A1.1.9 Types of services in cloud implementation
Cloud computing has revolutionized how organizations manage and deploy IT resources,
offering flexible and scalable solutions to meet diverse business needs. There are three
primary cloud service models: Software as a Service (SaaS), Platform as a Service (PaaS) and

Infrastructure as a Service (IaaS). Each one provides distinct levels of control, flexibility and

management solutions.
A1.1 Computer hardware and operation

B Software as a Solution (Saa$)
Saa$ delivers software applications over the internet. Users can access these applications
through web browsers without needing to install, maintain or update the software locally.

SaaS provides a cost-effective and convenient solution for businesses and individuals,
offering a wide range of applications from productivity tools to customer-relationship

management systems.
Saa$ allows users to access their software from anywhere, on any device, as long as they have
an internet connection. This eliminates the need for complex software installations. Many SaaS
providers charge a subscription fee, which is often less than the cost of purchasing software

licences. Additionally, updates and new features are automatically added by the provider,
ensuring that users always have the most up-to-date version of the software.
However, SaaS software relies on the user having an internet connection; without it, they

cannot run the software, unlike locally installed software. Data security is also a concern, as
users rely on the provider’s security measures to protect sensitive data.

Example
Google Workspace is an example of SaaS. This suite provides productivity tools, including
Gmail, Google Docs and Google Drive, used by businesses and educational institutions for
communication, collaboration and storage.

B Platform as a Service (PaaS)
PaaS provides a cloud-based platform that allows developers to build, test and deploy
applications without managing the underlying infrastructure. PaaS includes tools and services to
4 Middleware:
software that connects
different applications,
allowing them to
communicate and share

data. It helps different
parts of a computer

system work together
smaoothly.

facilitate application development, such as databases, middleware and development frameworks.
PaaS accelerates software development by allowing developers to focus on coding rather than
infrastructure management. It also makes it easier and cheaper to scale hardware as the user
base increases. However, this solution can lead to vendor lock-in, making it difficult to move
applications to different platforms and offering less control over the hosting environment.

Example
Microsoft Azure App Service is an example of PaaS. It is a platform for building, deploying
and scaling web apps and APIs, used by developers to create scalable and reliable applications

without managing the underlying servers.

B Infrastructure as a Service (laaS)
laaS provides virtualized computing resources over the internet, such as virtual machines,

storage and networks. This allows businesses to rent IT infrastructure instead of buying and
managing physical servers.

Unlike Paa$, IaaS gives users full control over their virtual machines and networks. This
reduces the need for upfront investment in hardware and allows businesses to rent solutions

at a lower initial cost using a subscription model. IaaS is also scalable, making it easy to adjust
resources as the user base grows. However, laaS requires more technical knowledge than Paas,

as users must manage their own devices and secure their own data and applications.

Example
Amazon Web Services (AWS) EC2 is an example of TaaS. Businesses use AWS EC2 to create

and manage virtual servers, providing the flexibility to run applications without owning

physical hardware.

A1 Computer fundamentals

1

What is Software as a Service (SaaS) and how does it differ from traditional
software installation?

3

Why might a business choose Infrastructure as a Service (laaS) over purchasing
physical hardware?

Explain how Platform as a Service (PaaS) benefits software developers.

Note: All the exam practice questions are representative of those that will be found on Paper 1
for the International Baccalaureate Diploma in Computer Science.
1 Describe the function of the arithmetic logic unit (ALU).
2]
2

Outline the role of the program counter (PC).

3
4

Explain the advantages of multi-core processors compared to single-core processors.
[3]
Describe how the architecture of a GPU differs from a CPU, and why it is better suited for
tasks such as video rendering.

5 Compare the processing power of a CPU and a GPU in handling complex computations.
6 Explain the role of L1 cache in a computer system.
7 Describe the fetch-decode—execute cycle that a CPU uses to process instructions.
8 Explain the concept of pipelining in multi-core processors.
9 Describe the differences between solid state drives (SSD) and hard disk drives (HDD).
10 Describe the method of lossy compression and give an example of its use.

A1.1 Computer hardware and operation

2]

3]

[4]
2]
[4]
[3]
(4]
3]

Data representation
and computer logic
SYLLABUS CONTENT

yvwy

By the end of this chapter, you should be able to:
» A1.2.1 Describe the principal methods of representing data
A1.2.2 Explain how binary is used to store data
A1.2.3 Describe the purpose and use of logic gates
A1.2.4 Construct and analyse truth tables
A1.2.5 Construct logic diagrams

A1.2.1 Principal methods of representing data
Binary (base-2) is the language for modern-day computers;
however, this was not always the case. When developing

early computers, several number systems were trialled.

"N T

Charles Babbage, the inventor of the Analytical Engine,
used decimal for his inventions. This seemed a logical
choice as people already commonly used base-10.

The ternary system (base-3) was also explored. The Setun
computer, developed in the Soviet Union in 1958, used this
system. Over 50 of these were produced for educational
and scientific institurions to help explore the benefirs of
ternary logic in computing. Despite its innovative
approach, the practical challenges and the widespread
adoption of binary logic eventually led to its replacement.
Other scientists and inventors also explored quaternary

W The Analytical Engine, conceived by Charles Babbage in the
19th century

(base-4) and other number systems. However, practical

implementations of these systems were rare due to the
increased complexity in hardware design and the limited
benefits compared to binary.
Modern computing ultimately settled on binary (base-2) as
the primary number system. The base-2 system represents
two possible states: 1 or 0. This is in contrast to the number
system we are all comfortable with, the decimal system
(base-10), which has ten possible states: 0 to 9. The binary

system is particularly well-suited to represent the state of
electrical switches within a computer system: on (1) and

off (0). This simplicity reduces hardware complexity and

enhances reliability.
Binary reduces the complexity in hardware design because
digital electromics, such as transistors, naturally operate
M The Setun computer, developed in 1958

in binary mode. Transistors act as switches that can be

A1 Computer fundamentals

turned on or off, aligning perfectly with the binary system'’s two-state logic. Additionally,
Boolean algebra, the mathematical framework for logical circuit design and operation, enables
straightforward implementation of complex operations using simple logic gates with binary
inputs: 1 (on / rue) or 0 (off / false).
The increased reliability of binary systems stems from their use of only two states. Small

variations in signal strength do not affect data integrity as much as in systems using larger
# Noise: unwanted

bases, making binary more robust in noisy environments.

electrical disturbances
that can affect the
integrity of signals
being processed by a
computer; this noise is
not related to sound,
but to variations in

As all data on a computer system is stored in binary, we need systems to represent numerous

voltage or current

In the decimal system, as we count, we start with a single digit and increment it by 1 until we

that can disrupt the

reach 9. After 9, we introduce a new digit to the front to represent larger numbers. Let’s break

accurate transmission

and processing of
digital data.
# Bit: binary digit; a
single digit, either 1 or 0.
4 Byte: 8 bits.

types of data, such as integers, strings, characters, images, audio and video, in binary form.

H Representation of integers in binary
To represent numbers in binary, it is useful to remember the basics of our decimal system

(base-10).

down the decimal number 1024:
1000s

100s

10s

1s

1

0

2

4

This can be expressed as:
(1 x1000) + (0 x 100) + (2 x 10) + (4 x 1) = 1024

Each decimal place value increases by a multiple of 10 as we move to the left because we are
working in base-10.

Binary, and other base systems, work in a similar way but, instead of 10 possible states per
digit, binary has only two (0 and 1). Consequently, each digit increases by a multiple of 2. Let’s

break down the binary number 0110:
8s

4s

2s

1s

0

1

1

0

This can be expressed as:
0x8)+(1xPD+1Ax2)+O0OxD=6
In this example, we have no 8s, one 4, one 2 and no 1s. Adding 4 + 2 gives us the decimal

(;Common
mistake

(base-10) equivalent of the binary (base-2) number 0110. To clearly denote whether

we are showing a binary or decimal number, we usually put the base as a subscript, to
avoid confusion:

When seeing the
number 11111111,

0110,=6,,

a common mistake

‘When working with computer systems, we usually deal with 8-bit binary numbers. A bit can

is to say this is 256.

be defined as a “binary digit”, and 8 bits is equivalent to 1 byte. If the number does not require

However, remember

8 bits to represent it, we usually pad out the extras with 0s. For example, the decimal number

that while there
are 256 number

33 would be represented as:

possibilities, 255 is
the largest number
we can represent in 1
byte (as 0 can also be

represented).

128s

64s

32s

16s

8s

4s

2s

1s

0

0

1

0

0

0

0

1

This means that with 8 bits, we can represent 256 different numbers, from 0 to 255. If we
want to represent larger numbers, we need more bits to represent this.

A1.2 Data representation and computer logic

When referring to bits and bytes, a lowercase “b” is used to represent bits and an uppercase “B”
is used to represent bytes. We then use a prefix system as the numbers increase.
There are two types of prefixes when referring to bits and bytes: one for base-10 (e.g. kilo,

mega, giga) and another for base-2. There was a time when base-10 prefixes were also used for
base-2 quantities due to their similarity (e.g. 1024 is close to 1000). However, the confusion

this generated led to calls for change. To address this, in 1999 the IEC introduced new prefixes
(e.g. kibi, mebi, gibi) specifically for base-2 multiples (1024, 1,048,576, 1,073,741,824).
Kibibyte

Mebibyte

Gibibyte

Tebibyte

Pebibyte

Exbibyte

Zebibyte

KiB

MiB

GiB

TiB

PiB

EiB

ZiB

1KiB=

1 MiB
=

1GiB=

1TiB=

1PiB=

1EB =

1ZiB=

1024 bytes

1024 KiB

1024 MiB

1024 GiB

1024 TiB

1024 PiB

1024 EiB

Kilobyte

Megabyte

Gigabyte

Terabyte

Petabyte

Exabyte

Zettabyte

KB

MB

GB

TB

PB

EB

ZB

1KB=

1MB=

1GB=

1TB=

1PB=

1EB=

1ZB=

1000 bytes

1000 KB

1000 MB

1000 GB

1000 7B

1000 PB

1000 EB

Bits and byte notation are worth knowing when dealing with mobile-phone and internet companies.

Download speeds of up to 100Mb/s!

ar

Download speeds of up to 100MB/s!

If the two advertisements above were from two different internet companies, assuming the
cost is the same, which one offers faster speeds and by how much?

Converting binary numbers to decimal
There are two main methods for converting a binary number to decimal: the positional
notation method and the doubling method.
Positional notation method:
This is possibly the most straightforward method, where you assign the place values and sum.

(.-Top tip!
When converting to
and from binary, it is

always a good idea to
write the digit place
values down first.
Trying to remember
these in your head can
lead to silly mistakes.
128
16
2

64
8
1

32
4

1

Starting from the right, assign the place values for each binary bit.

2

Sum each of the place values that has a 1 underneath it.

For example, to convert 10111011, to decimal:
128

64

32

16

8

4

2

1

1

0

1

1

1

0

1

1

128+32+16+8+2+1=187
Doubling method:
1

Start with the leftmost bit (the most significant bit).

2

Double the current total and add the next bit.

3 Repeat until all bits are processed.

A1 Computer fundamentals

For example, to convert 10111011, to decimal:
Step

Binary digit

Current total

Calculation

1

1

1 | Initial value

2

0

2|

1x2+0=2

3

1

5|/

2x2+1=5

4

1

Mis5x2+1=1m

5

1

23 | NMx2+1=23

e

0

46 | 23x2+0=46

7

1

93 | 46x2+1=93

8

1

187 | 93 x2+1=187

(‘Common mistake
If you use this method, remember to start with the most significant bit (MSB), not the least
significant bit (LSB).

# Least significant bit
(LSBY): the rightmost
bit in a binary number,
representing the
smallest value position
(0 or1).

Convert the following binary (base-2) numbers to decimal (base-10):

4 Quotient: the result
obtained when one
number is divided by
another, e.g. in the
division of 15 by 3, the

1

11001010,

4

00011110,

2

01101101,

5

11100001,

3

1011001,

quotient is 5.

Converting decimal numbers to binary
There are two main methods for converting a decimal number to binary: the division method
and the subtraction method.
Division method:
1

Divide the decimal number by 2.

2 Write down the quotient and the remainder.
The remainder will be either 0 or 1. This represents a digit of the binary number (the LSB
on the first division).
3

Update the quotient.

4 Repeat until the quotient is 0.
5

Construct the binary number (this is read from the remainders from the first to the last).

Tor example, to convert 42, to binary:

(‘Common

Division step

Quotient

Remainder

mistake

4272

21

0

21/2

10

1

10/2

5

0

5/2

2

1

2/2

1

0

1/2

]

1

Remember to
construct the

remainders in the
correct order to

format your binary
number. The first
remainder is the least
significant bit (LSB).

Construct the binary number from the remainders and pad to 8-bits: 00101010,

A1.2 Data representation and computer logic

Subtraction method:
Write down the place values for an 8-bit binary number:

128

64

32

16

8

4

2

1

Starting with the largest place value (128):
1

Try and subtract it from the number you are converting.
[0 If the place value is larger than the number, write a 0 below it.
[0 Ifitis smaller or equal to it, write a 1 and calculate the remainder of the subtraction,
carrying the result to the next place value.

2

Repeat.

For example, to convert 42, to binary:
128, and 64, are larger than 42, so we write 0 below these.
128

64

32

16

8

4

2

1

32, is smaller, so we write a 1 below it and calculate the remainder from the subtraction, the

result of which will carry to the next place value:
42y =32, =10,
128

64

32

16

8

4

2

1

16 is larger than 10, so write a 0
8 is smaller, so write a 1 and calculate the remainder:
1010 - 8m = 210

4, is larger than 2 so writea 0
2,,is equal, so calculate the remainder (0) and write a 1
128

64

32

16

8

4

2

1

0

0

1

0

1

0

1

0

Convert the following decimal (base-10) numbers to binary (base-2):

1
2
3
4
5

20,
87,
123,
199,
250

\Write a binary-to-decimal and decimal-to-binary application in either Python or Java.

A1 Computer fundamentals

B Representation of integers in hexadecimal
Hexadecimal (often abbreviated as hex) is a base-16 number system that uses 16 distinct

symbols to represent values, rather than the 10 of decimal or 2 of binary. The symbols
include the digits 0 to 9 and then the letters A to T, where A represents 10, B represents 11,
C represents 12, D represents 13, E represents 14 and F represents 15.
4 Debugging tools:
software applications
or utilities used by
developers to identify,
analyse and fix bugs
or issues within a
program by inspecting

Hexadecimal is used with computers for several reasons. The ease of conversion between

code, variables and

Converting binary numbers to hexadecimal

execution flow.

Converting binary to hexadecimal is a straightforward calculation.

4 Memory dump:
a process where
the contents of a
computer's memory
are captured and
saved, typically for the
purpose of diagnosing
and debugging
software issues.
# Nibble: 4 bits.

binary and hexadecimal is straightforward because each hex digit maps directly to a 4-hit

binary sequence. For example, the binary number 1111 can be represented as F in hex.
Another reason is that it provides a more compact way to represent a binary value. This makes
it much easier for us to read and communicate large binary numbers. This is why you often see
hex used in debugging tools, memory dumps and assembly language programming.

1

Split the binary byte (8 bits) into two nibbles (2 x 4 bits).

2

Calculate the decimal value of these 4 bits.

3

Convert the decimal values into their hexadecimal equivalents and rejoin them.

For example, to convert 01101011, to hexadecimal:

1

Split the byte into 2 nibbles:

0110,
2

1011,

Calculate the decimal value:
6l[}

3

1110

Convert both decimal values to their hexadecimal equivalents and rejoin them:

Convert the following binary (base-2) numbers to hexadecimal (base-16):

1

10101100,

4

00111010,

2

11010110,

5

10011101,

3

11010001,

Converting hexadecimal numbers to binary
Moving from hex to binary is just a reverse of the binary-to-hexadecimal process:
1

Split the two hexadecimal digits.

2

Convert each of them to a 4-bit binary number using the same integer-to-binary method.

3 Join the two 4-bit numbers together to form 1 byte.

For example, to convert F2 _ to binary:
1

Split the two hexadecimal digits:
Flﬁ

2

216

Convert each of them to a 4-bit binary number using the same integer-to-binary method:

1111,

0010,

3 Join the two 4-bit numbers together to form 1 byte:
11110010,

A1.2 Data representation and computer logic

Convert the following hexadecimal (base-16) numbers to binary (base-2):

1 3F,
2 A9,
3 10,

4 7C,
5 E2,

Converting decimal numbers to hexadecimal
To move berween decimal and hexadecimal is one of the trickier calculations to perform, as
you need to be comfortable with your 16 times table. To convert a decimal number to hex:
1

Divide the decimal number by 16 and record the remainder.

2

Repeat the process with the quotient until the quotient is 0.

3

Form the hex number from the remainders, with the last remainder obtained being the
most significant bit (the number on the lefo).

For example, to convert 254, to hexadecimal:

1

Divide the decimal number by 16 and record the remainder:
254,716, = 15, remainder 14,
quotient = 15,

remainder 14 =T
2 Repeat the process with the quotient until the quotient is 0:
15,716, =0, remainder 15
quotient =0,

remainder 15 =T
3

Form the hex number from the remainders, with the last remainder obtained being the
most significant bit (the number on the left):

Convert the following decimal (base-10) numbers to hexadecimal (base-16):

142,

2 157,
3 89,

4 200,

5 123,

Converting hexadecimal numbers to decimal
To convert from hexadecimal to decimal:
1 Convert hex digits to their decimal equivalents.
2

Multiply them by 16 raised to the power of its position index, starting from 0 on the right.

3

Sum the results.

For example, to convert 2F to decimal:
1

Convert hex digits to their decimal equivalents:
25=2y

F 16 =15 1]

A1 Computer fundamentals

2

Multiply them by 16 raised to the power of its position index, starting from 0 on the right:

3

Sum the results:

21x16'=2x16=32,

15x16°=15x1=15,
32+415=47,,

Add hexadecimal conversion functionality to the binary converter app you created before.

A1.2.2 How b inary is used to store data
The binary system underpins everything from numerical values and textual informarion to
complex multimedia files, ensuring efficient and reliable data processing. In this section, we
are going to discover the mechanisms that are used to store such data as characters, strings,
images, audio and video in binary form.

B Characters and strings
Characters and strings are stored using standardized binary encoding schemes, enabling
consistent storage, retrieval and processing across different systems and applications. The
most common encoding standards are ASCII (American Standard Code for Information

Interchange) and Unicode.

ASCll encoding
The development of ASCII began in 1960 and was officially standardized in 1963. It was
developed because there was no standardized way to encode text characters, which led to
compatibility issues between devices and systems. Each manufacturer used its own proprietary
encoding system, which made it very difficult for devices to communicate with each other.
ASCII was designed to provide a common standard for the interchange of text data.
ASCII initially started out as a 7-bit encoding system, which gave it the ability to represent
128 (27) different characters, which was considered sufficient for most basic text data (letters,
numbers, punctuation and control characters). HHowever, as computing became more global
and applications required support for additional characters, an 8-bit extension to ASCII
was developed, giving it the ability to represent 256 (2%) characters. This was referred to as
extended ASCII, and the new characters were mainly used for Western European languages.
ASCII uses a simple but clever system to represent characters in binary (as long as we are
only considering the Latin (English) alphabet). The first five bits from the right are used to
represent the letter by its numerical place in the alphabet.
Tor example:

01100001,
01100010,
01100011,

-

A1.2 Data representation and computer logic

1,
2,
3,

=
=
=

b
c

(;Top tip!
If the first five bits
from the right are
00000 (five zeros), it
is almost certainly a

The first three bits from the left represent whether it is an uppercase or lowercase letter.
011 = lowercase; 010 = uppercase:

01100001,

=

01000001,

a
A

space (00100000).

If the first three bits
from the left are not
011 or 010, it is likely

to be a punctuation
mark.

Convert the following binary back into text to reveal the hidden message.
01000110 01101111 01101100 01101100 01101111 01110111 00100000 01110100 01101000
01100101 00100000 01110111 01101000 01101001 01110100 01100101 00100000 01110010
01100001 01100010 01100010 01101001 01110100

Create an application so that you can send secret messages to your friends.
Write an application that accepts either a string of characters or a stream of binary. It should
either encode the characters using ASCIl and binary or convert the binary back into text.
To make the binary less easy to decode by hand, you could remove all spacing between the
8-bit characters.

Unicode encoding
In the 1960s, the United States and the majority of English-speaking countries had a system
in 7-bit ASCII that worked for the English alphabet. Other non-English speaking countries
had their own unique encoding systems to work with their own languages. When the ASCII
system was increased to 8 bits (extended ASCII), allowing for 256 characters for use in

modern computers, countries did not agree on the same standard. Nordic countries started
using the extra space to encode characters for their own languages, and Japan used four
different systems that were not even compatible with each other. This was not a huge issue
as communication between these systems was rare, but then the internet was launched and
compatibility became very important as more and more information was being shared between

systems in different countries.
In 1991, the Unicode Consortium was created to try and solve this problem. The organization
was established to develop, maintain and promote the Unicode Standard, which provides a
unique number for every character, regardless of platform, program or language. It needed
to create a system that was capable of storing all the characters and punctuation marks from
all the languages in the world, but also wanted it to be backwards compatible with ASCIL At
the time of writing, the current Unicode Standard version 15.0, released in September 2022,
encodes 149,186 different characters. Unicode includes the Latin, Cyrillic, Greek and Arabic

alphabets, and Chinese characters, as well as many others, and also includes emojis and
mathematical and other technical symbols. In Unicode, each letter or symbol is assigned a

unique number, for example:
B A=65
m {L=27721
m & =128169

A1 Computer fundamentals

You can find the numerical representation for any character or symbol using the code below:

Python
# Python examples
char
a = 'A'

char_han = '{l"
char poo =

'&'

# Get Unicode code points as integers
code_point_a = ord(char
a)

# 65

code_point_
han

ord(char_han)

# 27721

code point poo

ord(char poo)

# 128169

# Print integer representations
print
(code point a)

# Output:

65

print (code point_han)

# Output:

27721

print (code point
poo}

# Output:

128169

Java
public class UnicodeExample {

H

public static void main(Stringl[]

args)

HH
H
HH

({

// Define characters
char charA =

H

'A';

H

char charHan = 'i{';
String charPoo = "&"; // Note: Java uses UTF-16 and
// the emoji is usually a surrogate pair
// Get Unicode code points as integers
int codePointA =

(int)

int codePointHan =

chard; // 65

(int)

charHan;

// 27721

H

int codePointPoo = charPoo.codePointiAt
(0); // 128169

// Print integer representations
System.out.println("Unicode code point of

'A':

"

1H
HH

+

codePointd); // Output: &5
System.out .println("Unicode code point of
codePointHan); // Output: 27721
System.out.println("Unicode code point of
codePointPoo); // Output: 128169

'{i':
'&':

" +
" +

HH
Haesessasessssiessatastasitatasanstassanantsnnn sesssssssessassessasesrsansarasnnranannnanns

A1.2 Data representation and computer logic

How did they manage this? The story is that it was conceived in a café on the back of a napkin
when Joe Becker (Xerox), Lee Collins (Apple) and Mark Davis (Apple and later Google) met
and designed the encoding scheme in 1987. There are a few different versions of Unicode:
UTF-8, UTF-16 and UTF-32. Each has its own uses:
UTF-8
Variable length | 1-4 bytes per character

UTF-16

UTF-32

2 or 4 bytes per character

4 bytes per character

Surrogate pairs: for
characters outside the
Basic Multilingual Plane

Simplicity: easier to process
because each character is
exactly 4 bytes

encoeding

# Basic Multilingual
Plane (BMP): the
maost commonly used
characters and symbals
for almost all modern
languages.

Note

Compatibility: backward
compatible with ASCII

(BMP), two 16-bit code
units are used
Usage

Most commonly used
Often used in Windows and | Less common due to higher
encoding on the web and in | Java environments
storage requirements

many applications

Let’s examine UTF-8, the most commonly used encoding system, and understand
its functionality.

Instead of merely expanding the size to accommodate over 100,000 characters, which would
have adversely impacted most online content, a more efficient solution was devised. Iad

all characters been standardized to use 32 bits, each letter in the ASCII system would have
quadrupled in size. This would have resulted in significantly larger documents and web pages,
leading to increased storage requirements and slower transfer times. The system also needed
never to send eight zeros (00000000) in a row, as many older systems would see this as the end
of communication and would stop listening.
So the UTT-8 system kept the ASCII system the same. The letter “A” is encoded as:
01000001 = A

However, if the character needed went beyond the standard ASCII system, “¢” for example,
more than one byte would be required:
11000011 10101001 = ¢
The bits in bold are important. The first three significant bits “110” on the first byte represent
that this character is made up of two bytes in total (a 0 is needed at the end to show when this
information is finished). The second byte starts “10”, which means this is a continuation. If

you remove those 53 bits and then put both bytes together:
00011101001 =233 =¢
Another example is:
11110000 10011111 10011000 10000100 = =
This emoji requires four bytes using the UTT-8 system. The first byte communicates that this
character is made up of four bytes (“11110”) and the next three bytes start with “10”, showing
they are continuation bytes. If we remove that information:
0001 1111 0110 0000 0100 = 128516 = &
UTF-8 has been adopted by the internet as the main character encoding system; however,

it doesn't come without some issues. Due to the variable length, some characters (especially
those from Asian languages or emojis) take more space compared to single-byte encodings.

This can lead to larger file sizes in certain contexts. The processing required to handle
variable-length encoding also requires more complex processing compared to fixed-length

systems such as UTF-32.
A1 Computer fundamentals

# Shift cipher: a type

Despite these issues, UTF-8 has proved to be a versatile and effective encoding standard that

of substitution cipher,

meets the needs of the modern internet. Its backward compatibility, efficiency and broad

where each letter in

support make it an enduring choice for encoding text. While it does have some challenges,

the plaintext is shifted

particularly with handling non-ASCII characters and variable-length encoding, these are not
significant enough ever to warrant a wholesale replacement. Therefore, it’s likely that UTF-8

a certain number of
positions down or up
the alphabet.

will continue to be the dominant text encoding standard for the foreseeable furure.

The code below uses a Caesar cipher to encrypt the string that is input using a key. A Caesar cipher is a simple shift cipher,
where each letter is considered to be an integer (a=1, b = 2, ¢ = 3, and so on) and the key is added to this to find the
encrypted letter, for example:
5tring input: "Hello”

Key input: 1
Output: fmmp

Python
def caesar cipher encrypt (message, key):
encrypted message =

"'

for char in message:
if char.isalpha():

# Check whether the character is a letter

shift = ord("A")

if char.isupper()

else ord("a")

# Determine the

# ASCII offset

# Shift the character and wrap around the alphabet if necessary
encrypted char = chr((ord(char)

- shift + key)

% 26 + shift)

encrypted message += encrypted char
else:
encrypted message += char

# Non-letter characters remain unchanged

return encrypted message
# User input

message = input ("Enter the message to encrypt:
key = int(input ("Enter the key
# Encrypt the message

(an integer):

")

"))

encrypted message = caesar cipher encrypt(message, key)
print (f"Encrypted message:

{encrypted message}")

A1.2 Data representation and computer logic

: Java
i

import java.util.Scanner;
public class CaesarCipher (

H
q

public statiec String caesarCipherEncrypt (String message, int key)
StringBuilder encryptedMessage = new StringBuilder();
for

(char ch : message.toCharArray())
if

(Character.isLetter(ch))

{

{

({

// Check whether the character is

// a letter

:

char shift;

g

if

(Character.isUpperCase
(ch))
shift = 'A';
// letters

:

{

// Determine the ASCII offset for uppercase
i

} else {
shift = 'a';
// letters

i

é

}

saresssnssrsssssnans

:

// Determine the ASCII offset for lowercase

// Shift the character and wrap around the alphabet if
// necessary
char encryptedChar =

(char)

((ch -

% 26 + shift);

} else {
encryptedMessage.append(ch);

]

1

shift + key)

encryptedMessage
. append (encryptedChar) ;
// Non-letter characters remain

// unchanged

return encryptedMessage.toString();
public static void main(String[]

args)

{

Scanner scanner = new Scanner (System.in);

q

// User input
System.out
.print ("Enter the message to encrypt:

3

");

String message = scanner.nextLine();
System.out.print ("Enter the key

(an integer):

");

int key = scanner.nextInt();
// Encrypt the message
String encryptedMessage = caesarCipherEncrypt (message, key);
1

System.out.println("Encrypted message:

" + encryptedMessage);

1

After studying how this code works, write the decrypt function for someone who receives an encrypted message.

2

Write a function that is able to brute force an encrypted message so you can identify the key used.

4 Brute force: a method
of breaking a cipher by
systematically trying
every possible key until
the correct one is found.
A1 Computer fundamentals

l Images
In 1957, Russel Kirch scanned an analogue photo of
his son Walden, converting the picture into a digital

file. This was the first ever digital image created. Tt
was a significant milestone in the evolution of visual

technology, revolutionizing the way we capture, store
and manipulate pictures. The development of early

digital cameras and scanners, which enabled devices to
convert light into digital data, started the trend that has
now become commonplace, and the transition from film
to digital has transformed numerous industries, from

photography and medical imaging to telecommunications

and entertainment.
Bitmap images
Bitmap images, also known as “raster” images, are one
of the most fundamental forms of digital graphics. They
reproduce images by using a grid of pixels, with each pixel
assigned a specific colour and intensity.
At the bottom of the page is a bitmap image with an image

resolution dimension of 13x10 (13 pixels wide by 10 pixels
high). Each pixel is “described” using 1 bit of data: either
1 or 0. In this case, 1 = black and 0 = white (a monochrome
image), and the amount of bits used to describe the colour

is known as the “bit depth” or colour depth. So, we have a
M The first ever digital image: Russel Kirch’'s son, Walden, in 1957

# Analogue: a
continuous signal that
represents varying
physical quantities, such
as sound waves, which
varies smoothly over a
range; digital represents
data in discrete binary
values (0s and 1s),
enabling precise and

13x10 image with a 1-bit colour depth in this example.

To calculate the size of this image, the formula is:
image size = width (pixels) x height (pixels) x colour depth (bits per pixel)
13 x 10 x 1 = 130 bits (or 130/ 8 = 16.25 bytes)
However, in reality, this calculation is not completely accurate, as the image would require

more data to store metadata and other header information. This could include information
such as dimensions, colour depth and other attributes that allow the CPU to read the image
data accurately so it displays the image correctly to the screen.
oc|lo|lo|o|o|lo|lo|oOo|O|O|O|O]|O

error-resistant processing.
.

# Bitmap: a type of
digital image composed
of a grid of pixels, each
holding a specific colour
value, representing the
"
.
image in a rasterized
format.
# Pixel: short for “picture
element”; the smallest
unit of a digital image or
display, representing a
single point in the image
with a specific colour

and intensity.

0

0

0

ololo

0

0

0

0

0

olololo

0

00

0

0

[4]

o]

0
0
0

0

olololo

0|0
0

0

0

0
0
0

olololo

ol
olliie

meyo
ITol
o
0

e
1o

0
o

0
o

olololo

olo|lo|lo|lo|o|lo|o|o|o|o|o]|oO

A1.2 Data representation and computer logic

4 Image resolution:
the number of pixels
contained within a digital
image, typically expressed
as the dimensions (width
x height) in pixels, and
sometimes as the pixel
density (PPI/ DPI) for
print quality.
# Colour depth: also
known as “bit depth”;
the number of bits used
to represent the colour
of each pixel in a digital
image, determining the
range and precision
of colours that can
be displayed.
+ Metadata:
information that
describes other data,

To improve the quality of a bitmap image, we have two options: We can increase the number of
pixels (resolution) or we can increase the colour depth.
Resolution — increasing the number of pixels:
Increasing the number of pixels in a bitmap image increases the image quality. A higher
resolution allows for greater detail and clarity, and images with lower resolutions can lead
to a loss of detail and a pixelated appearance. However, the quantity of pixels is not the only
consideration: the size of the screen they are displayed on is also important. Images with
a higher PPI (pixels per inch) look clearer than those with a lower PPIL. Imagine having an
image with a resolution of 1024x768 shown on your phone compared to on a cinema screen.

The higher PPI on the phone will give a clearer image due to the increased pixel density.
The trade-off for a higher resolution image is larger file size, which can impact storage and

transfer efficiency.
W Common image resolutions
Resolution name

Pixel dimensions

Common usage

VGA

640 x 480

Early computer screens, basic web graphics

SVGA

800 x 600

Standard computer monitors, web graphics

HD (720p)

1280 x 760

HD video, basic HD television

providing context and
details about the data's

Full HD (1080p)

1920 x 1080

Full HD video, modern monitors and televisions

2K

2048 x 1080

Digital cinema, some monitors

content, structure and

Quad HD (1440p)

2560 x 1440

High-resolution monitors, gaming, professional use

4K (Ultra HD)

3840 x 2160

Ultra HD televisions, high-end monitors, video

8K

7680 x 4320

Cutting-edge televisions, professional video

attributes. In the context
of digital images,
metadata includes such
information as the
image’s dimensions,
colour depth, creation

date, author, camera
settings and other
properties that help
with managing,
understanding and using
the image effectively.

Colour depth — increasing the amount of colours:
When we increase the colour depth, it allows for a wider range of colours to be represented,
resulting in more vibrant and accurate images. If an image’s colour depth is low, this can lead
to banding, where gradients appear as distinct steps rather than smooth transitions. However,
just like image resolution, we must also consider the impact of file size for storage and transfer
times. The higher the colour depth, the larger the file size.
To work out the number of colours available, we calculate 2 to the power of the colour depth of
the image; for example, for an image with an 8-bit colour depth:
2%=1256
B Common colour depths
Colour depth
(bits per pixel)

Number of colours

Common usage

1 bit

2

Simple graphics, monochrome displays

4 bit

16

Early computer graphics, icons

8 bit

256

GIF images, simple web graphics

16 bit

65,536

High-colour images, some video formats

24 bit (true colour)

16.8 million

Standard for most images and video, digital photography

30 bit (deep colour)

Over 1 billion

Professional photography, high-end monitors and televisions

36 bit

Over 68 billion

Medical imaging, professional graphics

48 bit

Trillions

High-end personal applications, detailed scientific imaging

A1 Computer fundamentals

G A+

"

AT,

A

.

The majority of modern-day screens are 24 bit, allowing for
16.8 million colours. They have three lights per pixel: a red,
a green and a blue light, otherwise known as “RGB”, and
have a value range from 0 to 255 (1 byte per colour channel).

This is sufficient for most applications, as most human eyes
can only distinguish between around 10 million distinct

colours. Monitors that go beyond 24 bit are normally only
necessary in professional fields where precision is crucial.
On the left is a high-resolution image. If we zoom in to
the dress on this image, we can see the breakdown of the
individual pixels and the values of the distinct colour
channels. When working with graphics, these values are
often shown in hexadecimal. If we take the top left pixel of
—

the dress as an example:

b T T AR TS T

R: 216, G: 190, B: 199 = #d8bec7

R
G

E= RS©

[l
w
G
8
R

mowm so®m «

G

S
e
.
AL BTN
M A high-resolution image with a resolution of 2268 x 4032, a 24-

M A zoomed-in area of the image above, showing the value of
each pixel - created using www.csfieldguide.org.nz/en/interactives/

bit colour depth and a file size of 1.77 MB

pixel-viewer

RGB Calculator
rgp(216, 199, 199)
aBbec?

hsl(339, 258, sex)

26

R

28
0

G im
19

L]

M The colour values for the top left pixel of the dress in the photo
— created using www.w3schools.com/
colors/colors_rgb.asp

A1.2 Data representation and computer logic

We can also see the impact of lower colour depths on the same image:

M The same image using multiple colour depths: 24 bits to 0 bits - created using www.csfieldguide.org.nz/
enfinteractives/image-bit-comparer

1

A bitmap image uses a colour depth of 3 bits, allowing for eight distinct colours.

How many bits are needed to represent the colours if the bitmap image uses 32 distinct colours?
Raj is creating a bitmap graphic fora game. The image dimensions are 10 pixels wide and

12 pixels tall.
How many pixels are there in total in the image?
Alice is organizing her digital artwork collection that she has created over the years.
While transferring her artwork files to a new cloud storage service, she notices that each
file is larger than she anticipated. This is because, aside from the actual image data, the file
includes extra information necessary for accurate reproduction of the image. What is this
additional information, which contains details about the pixel data, called?

Determine the storage capacity needed for a bitmap image with dimensions of
800 x 600 pixels that supports 512 different colours.
Then, calculate the file size in kilobytes (kB) if the file metadata occupies an additional 25 per
cent of the space. Present your answer as a real number, including the decimal values.

A1 Computer fundamentals

Here are some fun ways to explore images in more depth using Python or Java.
1

Extract and print RGB values.

import java.awt.Color;
import java.awt.image.BufferedImage;

import java.io.File;
import java.io.IOException;
import javax.imageio.ImageIO;

public class ImageToRGB {
public static void main(String[]

args)

{

try {
// Load the

image

BufferedImage image = ImagelIO.read(new File("sample image.jpg"));
// Get image dimensions
int width = image.getWidth();
int height = image.getHeight
() ;
// Loop through each pixel
for

(int yv = 0; y < height; y++)

{

for (int = = 0; x < width; x++)

{

// Get the RGB wvalue of the pixel
int pixel = image.getRGB(x, y);
Color color = new Color(pixel);

// Extract the red, green and blue components
int red = color.getRed();

int green = color.getGreen();
int blue = color.getBlue();
// Print the RGB values
System.out.println("Pixel at
red +

",

G=" + green +

",

(" + x +

",

"

+ y +

"}:

R=" +

B=" + blue);

}
} catch (IOException e)

{

pu——

e.printStackTrace()
;

T TT

T T

A1.2 Data representation and computer logic

L L

T LR T L

T T T TT T TRT TP IPTN

For Python, you need to install the Pillow library first. Run this command in your terminal to install the necessary libraries:
pip install pillow

Python
pip install pillow

Use this code to access the RGB values for each pixel
from PIL import Image
# Load the image
image = Image.open('sample image.jpg")
# Convert the image to RGB mode
image = image.convert ("RGE")

# Get the image dimensions
width,

height = image.size

# Extract and print RGB wvalues
for y in range (height):
for x in range (width) :

pixel = image.getpixel
((x, y))
red,

green,

blue = pixel

print (f"Pixel at ({x},
2

{vy}): R={red}, G-{green}, B={blue}")

Apply a grayscale filter.
Warning:
This code processes the image pixel by pixel, which means it iterates through every pixel in the image to apply the
grayscale filter. For very large images (e.g. high-resolution photos), this process can be computationally intensive and take a

significant amount of time to complete. Consider testing this code on smaller images first (e.g. 100x100 pixels) to observe
its behaviour before applying it to larger files.

Python
from PIL import Image
# Load the image
image = Image.open("sample image.jpg")

# Convert the image to RGB mode
image = image.convert ('RGE')
# Get the image dimensions

width, height = image.size
# Create a new image to store the grayscale result
grayscale_image = Image.new("RGB",

(width, height))

# Apply a grayscale filter
for y in range (height) :
for x in range (width) :

pixel = image.getpixel((x, y))
red,

green,

blue = pixel

grayscale = int (0.3 * red + 0.59 * green + 0.11 * blue)
grayscale image.putpixel((x,

y),

(grayscale,

grayscale, grayscale))

# Save the grayscale image

grayscale_image.save('grayscale
image.jpg")

A1 Computer fundamentals

import java. awt .Color;
import java. awt .image.BufferedImage;
import java. io.File;
import java. io.I0OException;

import javax.imageio.ImagelO;
public class ImageToGrayScale

{

public static void main(String[]

:

try

args)

{

{
// Load the image

BufferedImage image = ImagelIO.read(new File("sample image.jpg"));
// Get image dimensions

int width = image.getWidth();
int height = image.getHeight
() ;
// Create a new image to store the grayscale result

BufferedIimage grayscaleImage = new BufferedImage (width,
BufferedImage.TYPE
INT RGB);

height,

// RBpply a grayscale filter

for (int y = 0; y < height; y++)
for

{

(int x = 0; x < width; x++)

{

// Get the RGB value of the pixel
int pixel = image.getRGB(x,

¥);

Color color = new Color (pixel);

// Extract the red, green and blue components
int red = color.getRed();
int green = color.getGreen();

int blue = color.getBlue();
// Compute the grayscale value
int grayscale = (int)

(0.3 * red + 0.59 * green + 0.11 *

blue)
;

// Create a new Color object with the grayscale value
Color grayColor = new Color(grayscale, grayscale, grayscale);
// Set the new pixel value in the grayscale image
grayscalelmage.setRGB(x,

y,

grayColor.getRGB());

}
// Save the grayscale image
ImageIO.write (grayscaleImage,

"jpg",

new File("grayscale
image

java.jpg"));
} catch (IOException e)

{

——

e_printStackTrace
() ;
:
HH
HH
H

3

After studying how the grayscale filter works, are you now able to create your own unique filters?

A1.2 Data representation and computer logic

B Audio
Audio in its analogue form is a continuous signal that represents sound waves through
variations of air pressure. These sound waves can be captured through input devices, such as
4 Amplitude: the
magnitude of change in a
sound wave, representing
the loudness or intensity
of the sound.
4 Sampling: the
process of converting
a continuous analogue
signal into a series of
discrete digital values by
measuring the signal’s
amplitude at regular
intervals.

microphones, which convert the sound waves into a digital signal, which is stored as binary.
This process involves several steps:

Analogue-to-digital conversion (ADC)
Sound is a continuous analogue signal. An ADC samples the amplitude (loudness) of the

sound at discrete intervals in a process known as sampling. The rate at which this happens is
measured in IHertz (11z) — the higher the Hertz, the more samples are recorded per second. CDquality audio uses 44.1 kHz, but professional quality audio is sampled at 48 kHz.
This sample 1s then stored and represented as a numerical value in binary. The precision is
determined by the bit depth. The larger the bit depth, the more possible values that can be
used to describe the sample. For example, the bit depth of CD-quality sound is 16 bit, which
gives 2' or 65,536, values. Professional audio, which uses 24 bit, has 2%, or 16,777,216, values.

4 kHz (kilohertz): a

A single second of a 44.1 kHz, 16-bit stereo (meaning two channels) audio has:

unit of frequency equal
to 1000 cycles per

B 44,100 samples per second

second, commonly used

B cach sample represented by 16 bits

to measure the sampling
rate of audio signals.

m atotal storage need per second of 44,100 samples / second x 16 bits / sample x 2 channels =
1,411,200 bits per second, or 176,400 bytes per second.
Analogue vs digital sound

1.0

—Analogue signal
0.5
L]
3

= 0.0+

[
E

<

-0.5+
-1.0

T

0.0

T

0.2

1.0

{

T

T

0.4

0.6

[

T

0.8

I

T

1.0

—Analogue signal
-2 Digital signal

0.5
@

°3

=
0.0
[-%
E

<

—0.5
-1.0-

T

T

T

T

T

T

0.0

0.2

0.4

0.6

0.8

1.0

Time (s)

M The blue continuous waveform represents an analogue signal, which is a smooth and continuous representation of sound. The
digital signal consists of discrete samples taken at regular intervals (sampling rate), illustrating how the continuous analogue signal is
converted into a series of discrete points in digital form.

Storage formats
There are many different types of file formats for storing audio. The most common are WAV,
AIFF, MP3 and FLAC. They mainly differ by whether they are compressed or uncompressed.

Uncompressed formats store the raw binary data, whereas compressed formats use algorithms
to reduce the file size for storage or transmission. Just like with image compression, audio

A1 Computer fundamentals

# Stereo: a method
of sound reproduction

compression attempts to reduce the file size by removing parts of the audio signal that are

that uses two or more

of compression used with audio. Lossless algorithms compress the data without any loss of

audio channels to create
the perception of sound
coming from different
directions, enhancing
the sense of spatial
depth and dimension.

less noticeable to human senses, in this case the ears. There are both lossy and lossless types
quality, whereas lossy algorithms permanently remove audio that is less noticeable to the

human ear on the recording.
B

WAV (Waveform Audio File Format): uncompressed

AIFF (Audio Interchange File Format): uncompressed
MP3 (MPEG Audio Layer III): compressed (lossy)
FLAC (Tree Lossless Audio Codec): compressed (lossless)

1

What is the main difference between an analogue signal and a digital signal in the context
of audio?

2

What is the process of converting an analogue audio signal into a digital signal called, and
what does it involve?

3

Calculate the storage needed per minute for a 44.1 kHz, 16-bit stereo audio file.

4

Explain the difference between lossy and lossless audio compression and give an example
of each type of format.

Explore audio files further using the code below. This will allow you to analyse the amplitude of
any MP3 file.
You will need to install the following libraries:
B soundfile
H numpy
m matplotlib
B scipy.
Run this command in your terminal:

pip install soundfile numpy matplotlib scipy

Python

1
1
1

import soundfile as sf

!

import numpy as np

:

import matplotlib.pyplot as plt
from scipy.fftpack import fft

:
1

# Load the audio file

:

samples,

:

sample rate = sf.read("name
of file. mp3")

# If stereo,

select one channel

if samples.ndim > 1:
samples = samples[:,

:
0]

# Visualize the waveform
plt.figure(figsize=(12,

:
:

:
6&))

:

plt.plot (samples)

:

plt.title("Audio Waveform")

:

A1.2 Data representation and computer logic

plt.xlabel ("Sample Index")
plt.ylabel ("Amplitude")
plt.show()
# Perform FFT
spectrum = fft (samples)
frequencies = np.fft.fftfreqg(len(spectrum),

plt.figure(figsize=(12,

1 / sample rate)

&))

plt.plot (frequencies|[:len(frequencies)//2],
np.abs (spectrum[:len (spectrum) //2]))
plt.title("Audio Spectrum")
plt.xlabel ("Freguency

(Hz)")

plt.ylabel ("Magnitude")
plt.show()

M Video
Videos are made up of various components that are all contained within an encapsulated
container format such as MP4, MKV or AVIL. The components are:
frames (visual data)

audio tracks
metadata
subtitles and closed captions.
Audio is stored as described in the Audio section above,

and metadata and subtitles are stored as text, so this

section will focus only on how the video data is stored.
Video is essentially stored as a sequence of still images,
otherwise known as “frames”. When played in quick
succession (usually 24 to 60 frames per second), these
frames create the illusion of motion. This is very similar
to the technique you may have used to create a flipbook.

The frames are stored and encoded in binary format,
M Digital video playback is similar to a flipbook: a number of
images that are shown quickly, creating the illusion of motion

utilizing various techniques to optimize space and ensure
efficient playback.

Frames
In their raw form, frames are stored the same as images, with each pixel having a value that
can be represented using a colour model such as RGB. To improve colour efficiency, frames are
often converted from the RGB colour model to a different one such as YUV. This helps with
compression, as this colour model emphasizes luminance (brightness), which the human eye
is more sensitive to than changes in colour detail.
However, we cannot store frames in the same way as we store photos because, in this format,
they would be too large. They need to be compressed, and there are two main techniques used
for this: spatial (intraframe) and temporal (interframe).

A1 Computer fundamentals

Compression techniques
Spatial compression is particularly effective and commonly used for video that has significant
detail variation in each frame. It reduces file size by eliminating redundant information

within each frame, such as colour depth or detail levels. This approach is important for videos
with a lot of detail that may change significantly between frames, such as animations, nature

documentaries and live news broadcasts.
Temporal compression is particularly effective and commonly used for video that has

consistent motion across frames. It reduces file size by eliminating redundant information
between consecutive frames, capturing only the changes or movements from one frame to the

next. As a predictive compression technique, it predicts frame content based on the preceding
and sometimes following frames, only storing the differences. This approach is important for

videos with a lot of detail that may change significantly between frames, such as animations,
nature documentaries and live news broadcasts.

1

What is the role of frames in a video, and how do they create the illusion of motion?

2

Explain the difference between spatial compression and temporal compression in
video storage.

3

Describe how converting video frames from the RGB colour model to the YUV colour
model can improve compression efficiency.

4

Calculate the total storage needed for a 10-minute video with a frame rate of 30 frames
per second, using 24-bit colour depth and a resolution of 1920x1080 pixels. Assume

no compression.

H Different binary methods for storing integers
Unsigned binary
This is the system we covered in Section A1.2.1. This system only represents positive integers
using straightforward binary digits (0s and 1s).

Signed binary
This includes methods for representing both positive and negative integers.
Two’s complement:
Two's complement is a method for representing signed integers in binary, where the most

significant bit (MSB) indicates the sign (0 for positive, 1 for negative). To convert a positive
binary number to its negative counterpart in two’s complement, you first invert all the bits
(change 0s to 1s and 1s to 0s) and then add 1 to the least significant bit (LSB).

For example:
00000101 = +5
Invert the bits
11111010

Add 1
11111011 =5

A1.2 Data representation and computer logic

However, a limitation of two's complement is that, in an 8-bit system, it reduces the range of
representable numbers. Instead of being able to represent 0 to 2553, as with unsigned binary,
two's complement allows for numbers ranging from —128 to +127, effectively halving the
number of positive values that can be represented.
One’s complement:
Ome's complement is a binary representation method for signed integers, where the most
significant bit (MSB) indicates the sign (0 for positive, 1 for negative). To obtain the one’s
complement of a positive number, you simply invert all the bits (change 0s to 1s and 1s to 0s).
For example:
00000101 = +5
11111010 = -5

Unlike two's complement, one’s complement has two representations of the number zero:
positive zero (00000000) and negative zero (11111111). This is one of its main limitarions

and can cause confusion when using arithmetic and logical operations. This means two’s
complement is normally the preferred system to use. Similarly to two’s complement, one’s
complement also has a limited range, representing numbers from —127 to +127.
Sign-magnitude:
Sign-magnitude is a binary representation method for signed integers where the most

significant bit (MSB) serves as the sign indicator, with 0 representing positive numbers and 1
representing negative numbers. The remaining bits represent the magnitude of the number,
like how unsigned binary numbers work.
For example:
00000101 = +5
10000101 = -5
This system also has two representations for zero: positive zero (00000000) and negative zero
(10000000). It also has the same range as one’s complement, from —127 to +127. It is a simple
system but, like one’s complement, is less efficient compared to two’s complement.

Binary-coded decimal
Binary-coded decimal (BCD) is a method of representing decimal numbers where each digit
of the decimal number is encoded separately into its own binary form. Unlike pure binary
representation, which converts the entire decimal number into a single binary sequence, BCD
assigns a 4-bit binary code to each decimal digit (0-9).

For example:
0100 0101 = 45
as 0100 represents 4, and 0101 represents 5
This system is useful where exact decimal representation is crucial, such as financial
applications or digital clocks, as it avoids the rounding errors that can occur in other systems.
However, due to using four bits per digit, more bits are required to store numbers, making it
less space efficient than pure binary representations. Calculations using BCD are also more

complex as they require additional steps to handle carry and overflow, so they are not good
choices for general-purpose computing.

A1 Computer fundamentals

Gray code (reflected binary code)
Gray code is a binary system where two successive values are only allowed to differ by one bit.
That makes this system particularly useful in situations where data integrity during transitions
is important. An example system is a robotic arm where we want to monitor its position. As

the arm rotates, the rotary encoder generates a sequence of binary outputs corresponding
to the arm’s angle. If the encoder used standard binary code, small mechanical vibrations or
inaccuracies could cause multiple bits to change simultaneously, leading to incorrect readings.

However, by using Gray code, the risk of these transition errors is minimized.
B Comparison of Gray code to standard binary for the numbers 0-7
Numbers

Standard binary

Gray code

0

000

000

1

001

001

2

010

on

3

on

010

4

100

110

5

101

m

6

110

101

7

m

100

Excess-N (biased representation)
Excess-N is a system where a fixed bias (N) is added to the actual value to form an encoded
value, and you subtract this bias to decode it. This is used to make all signed integers appear as
non-negative binary numbers to allow for easier comparisons and arithmetic operations.
For example, with Excess-3:
The decimal number 2 would be encoded as:
2+3=5
0101

The decimal number —2 would be encoded as:
-2+3=1
0001

In an 8-bit system, Excess-127 is often used, which adds 127 to encode an 8-bit number and
subtracts 127 to decode it. If you consider trying to order a set of signed binary numbers, this
can be difficult as the negative numbers are larger binary numbers than the positive.
Tor example, take 127 and —127 (using sign-magnitude):
Pre-encoded numbers:
01111111 =127
10000001 =127

When we encode these numbers with Excess-127, the positive numbers now appear larger than
the negative numbers, making them easier to put in order:
Encoded numbers (Excess-127):
127 + 127 = 254
11111110
—127 + 127 =0

00000000
A1.2 Data representation and computer logic

After this process has been completed, we decode the numbers again to return them to their
original form:
Decoded numbers (Excess-127):
254 -127 =127
11111110
0-127 =-127
00000000

Fixed-point representation
Fixed-point representation is a method used to store real numbers (numbers with fractional
parts) in binary by fixing the position of the binary point. In a fixed-point system, the binary
point is placed at a predetermined position, either between certain bits or at a specific location

in the binary sequence. This allows for a straightforward representation of fractional numbers,
though with some trade-offs in terms of precision and range.
For example, if we want to represent 5.25 in an 8-bit system where four bits represent the
integer and four bits represent the fractional part:
Integer part (four bits): 0101 = 5
Fractional part (four bits): 0100 = 0.25

Combined: 0101.0100
Note: Binary fractions are used for the fractional part, where the first bit to the right represents
! the second bit represents ! the third } and the fourth &. So, in the example above, we have 04

,14,03and
04
The number of bits assigned in this system limits the range and precision. In this example,

with a 4-bit signed integer, we only have the range of -8 to 7.9375, with the smallest
representable value being 0.0625 (35). This means this system is unable o handle very large
or very small numbers effectively. However, it is a simpler and faster system compared to
floating-point arithmetic (see below), and does not require any complex operations to adjust
the position of the binary point.

Floating-point representation
Floating-point representation is a method used to represent real numbers that can have a
very large range or fractional parts. It does this by storing numbers in a format that includes a
sign, an exponent and a mantissa (or significand). This formar allows computers to efficiently

handle very large numbers, very small numbers and numbers with fractional parts, all with a
reasonable degree of precision.
Using the IEEE 754 standard for single-precision floating-point numbers (which uses 32 bits):

1

Sign bit (one bit):
The sign bit determines whether the number is positive or negative.

2 Exponent (eight bits):
This is used to scale the number by a power of two and is stored using the Excess-127
system in its “biased” form; in other words, 127 is added to the actual exponent value.
3

Mantissa (23 bits):

This represents the significant digits of the number. The mantissa does not store leading
ones (in normalized form).

A1 Computer fundamentals

For example, this is how we could represent the decimal number -5.75:
Convert the number to binary:

101.11
Normalize this number to the form of Lxxxxx x 2™
1.0111 x 22
Determine the components:
Sign bit: 1 (as it is a negative number)
Exponent: 2 + 127 (Excess-127) = 129 = 10000001
Mantissa: 01110000000000000000000 (ignoring the leading 1)
So, the IEEE 754 single-precision binary representation of —3.75 is:
1 (sign) 10000001 (exponent) 01110000000000000000000 (mantissa)
This system allows for the representation of both very large and very small numbers, which is

essential in scientific computing, engineering and graphics, and is more precise than fixedpoint representation.

However, it is still not precise enough to represent all decimal numbers, and this can lead
to rounding errors. The complexity of the system also makes it slower than others, often

requiring special handling in hardware.

A1.2.3 Purpose and
use of logic gates
M The history of logic gates
In the mid-19th century, a British mathemarician named

George Boole developed an algebraic system known
as “Boolean algebra”. This provided a mathemarical

framework for representing logical statements and
operations that laid the foundations for modern

digital logic.
In the early 20th century, an American mathematician

and electrical engineer named Claude Shannon was the
first person to recognize the potential of Boolean algebra

for electrical circuit design. He demonstrated how the
design of electrical relay circuits could be optimized

using Boolean algebra, and then the development of
semiconductor technology further propelled the evolution

of logic gates.
The transistor was then invented in 1947 at Bell Labs,
which made it possible to build compact and efficient
logic gates. By the 1960s to 1970s, integrated circuits were
incorporating multiple transistors on a single chip, which
led to the development of microprocessors. Logic gates are

M George Boole, the British mathematician who developed
Boolean algebra, laying the groundwork for digital logic and

the building blocks of modern digital systems, from the

modern computer science

basic calculator to advanced supercomputers.

A1.2 Data representation and computer logic

H Basic gates
Logic gates are fundamental components in digital electronics, crucial for building various
types of circuits within computers and other digital devices. The basic types of logic gates

include AND, OR and NOT gates, each performing a specific logical function. These gates take
one or more binary inputs and produce a binary output based on the logical operation they

perform. To understand and verify the behaviour of these gates, we use truth tables, which
systematically list all possible input combinations and their corresponding outputs, providing

a clear representation of the gate’s function. Additionally, each gate has a corresponding
Boolean algebra representation that simplifies complex logical expressions.

Logic gates are made up of transistors, which act as electronic switches, allowing or blocking
the flow of electrical current. In a transistor, the control wire (or “gate”) regulates the current

between the two electrodes, known as the “source” and the “drain”. When voltage is applied
to the gate, it allows current to flow from the source to the drain, enabling the transistor to

switch states and perform logical operations.

Transistor

Electrode

Electrode

source

T

Electrode

Control wire

/ drain

M A Buffer gate that shows the inner workings of the gate when the control wire is off, no electricity can flow between
the electrodes

T

Electrode

Control wire

B When electricity flows down the control wire, the transistor
allows for the flow of electricity between electrodes

Above is a simple Buffer gate, where we can consider the control wire as the input and the
electrode drain as the ourput. If the input is on, the output is on; and if the input is off, the

output is off. We can show this using a truth table:
Buffer gate truth table

@

Input A

Output X

1

1

0

0

A1 Computer fundamentals

-

-.

/

=,

N

Va

Output

N/

AND gate
The diagram on the left shows an AND gate implemented
using transistors. The gate has two inputs and one output.

If only one of the inputs is on, one of the transistors
without an input would stop the current passing through.

It is only when both inputs are high (1) that the transistors
Input
Current

allow current to pass through, resulting in a high output (1).

Input

-

Qutput

A—

X

B—

W AND gate

Transistor A

M Input and output rules: The AND gate outputs 1 only if both
inputs are 1

Transistor B

AND gate truth table
Current

>

Output

Transistor A

Transistor B

M Transistor-level schematic of an AND gate

Input A

Input B

Output X

0

0

0

0

1

0

1

0

0

1

1

1

Boolean algebra:

X=A - B

OR gate
The diagram on the left shows an OR gate implemented
Current

Output

using transistors. The gate has two inputs — A and B —
and one output. When either input A or B is high (1), the

corresponding transistor turns on, allowing current to
flow through the circuit and resulting in a high ourpur (1).
Transistor A

© Transistor B

—_—
Current @

When both inputs are low (0), neither transistor conducts

[ On |
s

and the ourput remains low (0).

Output

T

Transistor A

|

Transistor B

El Off |

M Transistor-level schematic of an OR gate

B OR gate

M Input and output rules: The OR gate outputs 1 if at least one
input is 1
OR gate truth table
Input A

Input B

Output X

0

0

0

0

1

1

1

0

1

1

1

1

Boolean algebra:

A1.2 Data representation and computer logic

X=A + B

NOT gate
The diagram below illustrates a NOT gate (inverter) using a
transistor. In this configuration, the input line is connected

to the gate of the transistor, the output line is connected to
Current
T

the source and the drain is connected to ground.

Ground

Input

A

X

B NOT gate

When the input is high (1), the transistor turns on, allowing
—

current to flow from the source to the drain, effectively
Outout

grounding the output and resulting in a low voltage at the

utpu
*

output (0). When the input is low (0), the transistor turns

off, preventing current from flowing to the ground. In this
state, the output then outputs a high voltage (1).
¥ Current

M Input and output rules: The NOT gate outputs the opposite
value of the input

NOT gate truth table

4~ Ground

Inlut

B Transistor-level schematic of a NOT gate

Input A

Output X

0

1

1

0

Boolean algebra: X = A

H Derived (complex) gates
The following gates — NAND, NOR, XOR and XNOR — are examples of derived gates. Derived
gates are combinations of the basic gates and provide more complex logic functions. To
show these, we will move up a level of abstraction and, rather than examine the transistor
schematic, we will look at how the basic gates are combined to create them.

NAND gate (NOT AND)
A NAND gate is constructed with an AND gate followed by a NOT gate. Due to this, it gives
the opposite output to an AND gate. If both inputs are high (1), the output is low (0). In all

other cases, the output is high (1).

1

>

"

B How a NAND gate is constructed: an AND gate followed by a NOT gate

B NAND gate

M Input and output rules: The NAND gate outputs 1 unless both inputs are 1

NAND gate truth table
Input A

Input B

Output X

0

0

1

0

1

1

1

0

1

1

1

0

Boolean algebra:

X=A- B

A1 Computer fundamentals

NOR gate (NOT OR)
An NOR gate gives the opposite output to an OR gate as it is constructed using an OR gate
followed by a NOT gate. This means that it is only when both inputs are low (0) that the output
is high (1). In all other cases, the output is low (0).
.

A

—

B

M How a NOR gate is constructed: an OR gate followed by a NOT gate

B A NOR gate

X

M Input and output rules: The NOR gate outputs 1 only if both inputs are 0

Input B

OQutput X

0

0

1

0

1

1

0

o

1

1

Boolean algebra:

o

Input A

o

NOR gate truth table

X=A+ B

XOR gate (exclusive OR)
The XOR (exclusive OR) gate differs from the OR gate in one key way: its output is true only
when the inputs are different. This means the XOR gate outputs true when exactly one of the
inputs is true, but false when both inputs are the same. For example, if both inputs are high
(1), the XOR gate’s output is low (0). This is unlike the OR gate, which would output high (1) in

this case.

31—
.

By

M How an XOR gate is constructed

)
M An XOR gate

M Input and output rules: The XOR gate outputs 1 if the inputs are different
XOR gate truth table
Input A

Input B

Output X

0

0

0

0

1

1

1

]

1

1

1

0

Boolean algebra:

X=A @ B

XNOR gate (exclusive NOT OR)
The XNOR gate is constructed using an XOR gate followed by a NOT gate. This means the

output is the opposite to an XOR gate, only outputting high (1) when both inputs are the same
(either high or low).

A1.2 Data representation and computer logic

A
X

B

M How an XNOR gate is constructed: an XOR gate followed by a NOT gate

M An XNOR gate

M Input and output rules: The XNOR gate outputs 1 if the inputs are the same

XMNOR gate truth table
Input A

Input B

Output
X

0

0

1

0

1

0

1

0

0

1

1

1

Boolean algebra:

X=A D B

A1.2.4 Constructing and analysing truth tables
B Truth tables to predict the output of simple logic circuits
The following diagram shows a logic circuit, where a number of logic gates are connected

together. In this scenario, you need to be able to handle circuits with up to three inputs.
I

A

B

=
e

L

14

I

I

I

1

i

II

|I

|

I

—

I
I

TN

I

I
I
I

R}
L S

|

1

|

|

I

|
|

I
I

|

I

I

[

I
N
f\Q)

=

e

’

X

[

|

I

I

I

1I

iI

|

I

1

i

T

part 1

I
I

L

part 2

part3

When creating a truth table, first enter the three inputs and their possible input states; in this

case, A, Band C. As there are three inputs, you can calculate the number of rows you will need
by 2", where n represents the number of inputs. In this example:
2°=8

Populate the furthest right column, alternating between 0 and 1.
Populate the middle column by alternating, every two rows, between 0 and 1.
Populate the left-hand column by alternating, every four rows, berween 0 and 1.

A1 Computer fundamentals

Following this pattern will give you every possible input state.
A

B

C

0

0

0

0

0

1

0

1

0

0

1

1

1

0

0

1

0

1

1

1

0

Once this is complete, we then add the intermediate values to make it easier to remember the
state at each stage of the circuit. In this example, we have three intermediate values: P, Q and

R. Finally, we add the output column, X.
A

B

C

0

0

0

0

0

1

0

1

0

0

1

1

1

0

0

1

0

1

1

1

0

P

Q

R

Now, starting with the intermediate values, work through the logic circuit.

A

B

[«

P
(AANDB)

Q

R

X

(BNORC) | (PORQ) | (CXORR)

0

0

0

0

1

1

1

0

0

1

0

0

0

1

0

1

0

0

0

0

0

0

1

1

0

0

0

1

1

0

0

0

1

1

1

1

0

1

0

0

0

1

1

1

0

1

0

1

1

1

1

1

1

0

1

0

A1.2 Data representation and computer logic

Produce the truth tables for the following logic circuits.

{>c

X

=

—

A1 Computer fundamentals

———
B Truth tables to determine outputs from inputs for a
problem description
Problem description: A baby alarm that goes off when the alarm is switched on and the baby is
crying or the room is too cold.
With a problem description, we first need to identify the inputs. Here we have three: alarm
switch, baby crying and room temperature, which we can represent as A, B and C and set up
our truth table.

We know the alarm goes off if the device is switched on AND the baby is crying OR the room
is too cold. From here, we can identity the logic gates in the description. We can determine
from this that the device must be switched on before the alarm can go off, so if the switch is
off, all outputs would be 0. If the device is switched on, at least one of the other two inputs
must be on for the alarm to trigger. We have one intermediate value (baby crying OR room is
cold), represented with P.
A

B

C

P

X

(switch)

(crying)

(cold)

(BorQ)

(A and P)

0

0

0

0

0

[¢]

0

1

1

0

0

1

4]

1

0

]

1

1

1

0

1

0

0

0

0

1

0

1

1

1

1

1

4]

1

1

1

1

1

1

1

A1.2 Data representation and computer logic

Complete the truth tables for the following problem descriptions:
1

A traffic light control system that changes to green only if the pedestrian button is not

pressed and the road sensor detects no cars waiting on the side road.
2

A water irrigation system that activates if the soil is dry or the temperature is high,
provided the system is manually enabled.

3

A nuclear missile launcher: the missile should only launch if the president and two of his

three cabinet ministers flip the switch.

B Logical expressions
We can represent logic circuits using Boolean algebra. If we use the baby alarm scenario again,
we can represent this as:
X=A-(B+(C)

In Boolean algebra, parentheses are often used to indicate which operations should be
performed first. However, there is a standard order of operations, similar to PEMDAS

(or BODMAS) in mathematics. If no parentheses are present, follow this sequence:
m NOT
B

AND (including NAND)

B

OR (including NOR and XOR)

This ensures that operations are executed in the correct order for accurate results.

Using the Boolean algebra from the gates in Section A1.2.3, write the Boolean algebra for the
three logic circuits created in the previous problem descriptions:

1

Traffic light control system

2

Water irrigation system

3

Nuclear missile launcher

B Karnaugh maps and algebraic simplification
Karnaugh maps (K-maps) are a tool that helps simplify Boolean expressions, making it easier
to create simpler and more efficient digital circuits. Instead of using complicated algebraic
methods, K-maps allow you to visually group terms from a truth table, which makes it faster to
find a simplified expression. This process is useful because it reduces the number of logic gates
needed in a circuit, saving time, space, cost and power consumption.

Two inputs
This two-input K-map is used for expressions with two variables. In this map, variable A is
placed along the side and variable B across the top. llowever, the order of the variables doesn’t

matter — B could be along the side and A across the top. Both possible states (0 and 1) for each
variable are shown in the map, representing all combinations of their values.

A1 Computer fundamentals

K

[

Expression: A + B

—

| Qo

o

ANB

‘We split the expression at the OR operator and focus first on the term involving A. We
populate the K-map where A is 1, which, in this case, corresponds to the entire bottom row. At

this stage, we ignore B and only fill in the cells where A is 1.

This completed K-map now shows the expression A + B.

=|l
=

=

B

L

r
-

This is another example of a completed map for the expression A + B:

Expression: A-B+A - B
This is a more complicated expression, but still has only two inputs. Using this expression, the

T

circuit would look like this:

A1.2 Data representation and computer logic

The table map structure is still the same:
A\B

RB

o]

1

We again split the expression at the OR symbol, focusing initially on A - B. In this case, we
insert a 1 into only one cell, where both A and B are 1.
A\B
0

1

Next, we focus on the second part of the expression, A - B. In this case, we insert a 1 into the

cell where Ais 1 and Bis 0.
ANB

The K-map is now complete and shows that the value of B has no impact on the outcome,
allowing us to simplify the expression to just A. If we create the circuit using this simplified
expression, we can see that the circuit is significantly more efficient, while still performing the
same function.

A

-

-

Three inputs
Expression: A-B-C+A-B-C+A-B.C
With three inputs, we use a similar K-map but, this time, we place two of the inputs across the
top. The digits across the top may seem out of order compared to standard binary counting
(00, 01, 10, 11). Instead, they follow the Gray code convention (see Section A1.2.2 for more
information), where only one digit changes at a time. It is important to set the map up this way
to ensure correct grouping and simplification.
AB

C\AB

00

o

n

10

We now follow similar steps as with the two-input K-map. We separate the expression by
the OR operator and focus on the first term: A - B - C. In this step, we populate the K-map by
inserting a 1 into the cells where

Ais 0,Bis 1 and Cis 1.

A1 Computer fundamentals

C\AB

AB

AB

AB

AB

00

01

1"

10

0

1

Followed by:

1

A-B - C
C\AB

AB

AB

AB

AB

00

01

n

10

0

1

1

1

And finally: A-B- C
C\AB

AB

AB

AB

AB

00

01

1

10

0

!

L1

L]

jnedl)

Grouping the 1s and simplifying the expression
Although it wasn't explicitly stated before, you may have noticed the boxes drawn around

groups of 1s in the K-maps. These boxes help simplify the Boolean expression, but there are
some important rules that must be followed when grouping 1s:
B Groups must contain powers of 2: One, two, four, eight or sixteen 1s can be
grouped together.
B Groups must be rectangular or square: Each group should form a rectangle or

square shape.
B Groups cannot be diagonal: Adjacent 1s can only be grouped horizontally or vertically,
not diagonally.
B Groups must be as large as possible: Always aim to make the largest groups to simplify the
expression further.

B Groups can overlap: Some 1s may be included in more than one group if it helps form
larger groups.
B Minimize the total number of groups: The goal is to use the smallest number of groups to
cover all the 1s.
To determine the expression from the groups, we look at each group of cells and refer to the

variables. If a variable’s value stays the same across all the cells in the group, we keep that
variable in the simplified expression. Iowever, if the variable’s value changes across the group,
we discard it from the expression.
C\AB
00

A1.2 Data representation and computer logic

01

1

10

The first group is entirely along the bottom row, meaning C stays the same (C = 1), so we keep
it in the expression. A changes from 0 to 1 between the cells in the group, so we discard A. B
remains 1 in both cells, so we keep B. Therefore, the first part of our final expression is:
B-C
C\AB

AB

AB

AB

AB

00

01

n

10

The second group, like the first, is located along the bottom row, meaning that C stays as 1
because it does not change across the group. In this case, A remains 1 in both cells, while
B changes from 0 to 1. Since B changes, we discard B from this part of the expression. As a
result, we keep A and C, giving us the second part of our expression:

A-C
We then combine these expressions with an OR operator, giving us the final expression:
B-C+A-C

(.-Common mistake
When setting up your K-map for three inputs, make sure to use Gray code for the headings, not
standard binary. Gray code ensures that only one bit changes between adjacent cells, which helps
when grouping 1s and simplifies the expression more effectively.

Wrapping around edges in K-maps
Here is the K-map for the expression:
B+A-B-C
AB

C\AB

AB

AB

AB

AB

AB

AB

AB

00

01

1

10

1

1

To group these 1s, you may assume this is the answer:
C\AB

1

1]

However, K-maps are considered three-dimensional, and groups can be formed from left
to right and top to bottom (although only left to right is possible with three inputs). In this
example, it is possible to build a larger group by combining the two groups on the edges,
forming a square group of four 1s.

1

AB

AB

AB

AB

00

01

1

10

1

1

k

C\AB

A1 Computer fundamentals

Using these groups, we can form the simplified expression:

NS
I

A-C+B

B+A-B
Draw the truth table for the above expression.
Draw the Karnaugh map for the expression and
write the simplified expression.

U
I

& w

‘B-C+A-B-C+A-B-C
Draw the truth table for the above expression.
Draw the Karnaugh map for the expression and
write the simplified expression.

‘B-C+A-B-C+A-B-C
Draw the truth table for the above expression.
Draw the Karnaugh map for the expression and
write the simplified expression.

M K-map drawn on a torus and in a plane - the dot-marked cells
are adjacent

A1.2.5 Constructing logic diagrams
B Designing digital circuits from Boolean algebra expressions
By understanding the principles of Boolean algebra, we can simplify complex logic expressions
and translate them into circuit diagrams. This journey from abstract mathematical notation
to circuit design is essential for creating efficient and reliable digital systems. We will start by
creating the digital circuit from the expression below:

Y=(A-B)+(A-B)
1

Start with two inputs: A and B.

2 Work on the first parenthesis by introducing an AND gate and joining both A and B to it.

:

A1.2 Data representation and computer logic

——
.

A

Connect both the outputs to an AND gate.

VYT Y YT

3 Work on the second parenthesis, connecting A to a NOT gate and B to a NOT gate.

—

Now work outside the parentheses and introduce the OR gate to link them together.

>
Create the digital circuits from the following Boolean expressions.

wN

Y=(A+B)-A.B

B

Y=(A.B@DA

Y=(A®B)
- B®CO

i

1

Y=(A.B).C+{A+B)

Y=4A.TB+0

A1 Computer fundamentals

Operating systems
and control systems
SYLLABUS CONTENT
By the end of this chapter, you should be able to:
» A1.3.1 Describe the role of operating systems
» A1.3.2 Describe the functions of an operating system
P A1.3.3 Compare different approaches for scheduling
» A1.3.4 Evaluate the use of interrupt handling and polling
» A1.3.5 Explain the role of the operating system in managing multitasking and resource
allocation (HL)
P A1.3.6 Describe the use of the control system components (HL)
» A1.3.7 Explain the use of control systems in a range of real-world applications (HL)

A1.3.1 The role of operating systems
An operating system (OS) is the fundamental software that manages computer hardware
and software resources and provides common services for computer programs. It acts as an
intermediary between the user and the computer hardware, ensuring efficient and secure
operation of the system.

Operating systems simplify user interactions with computer hardware by abstracting the
underlying complexities. This means users and applications do not need to understand the

detailed workings of hardware components such as CPUs, memory and input/ output devices.
Instead, the OS provides a set of high-level services and interfaces that hide these complexities,

making the system easier to use and program.
The primary role of an operating system is to manage the computer’s resources effectively.
This includes:
B

CPU management: allocating CPU time to various processes and ensuring

efficient execurion
B memory management: handling the allocation and de-allocation of memory to
applications, and managing virtual memory to extend physical memory capacity
®m storage management: organizing and managing data on storage devices, ensuring reliable

data storage and retrieval
B device management: controlling and co-ordinating hardware devices, providing drivers
and interfaces for seamless operation.
Some of the most famous modern operating systems are Microsoft Windows, Apple macOS
and Linux on larger computers and laptops, with Android and iOS being more popular for
smaller portable devices such as smartphones.

A1.3 Operating systems and control systems

A1.3.2 Functions of an operating system
Operating system functions are multifaceted, ensuring thar the system runs smoothly,
efficiently and securely. Here, we will delve into the various critical functions of an operating
system, illustrating how it maintains system integrity while running background operations
and managing resources.

[ ] Memory management
4 Virtual memory: a
memory-management
technique that allows

Memory management is a fundamental function of an operating system (OS), involving the
control and co-ordination of a computer’s primary memory (RAM). The OS ensures that
memory is allocated efficiently to processes and applications, maintains system stability and

a computer to use

protects memory areas from unauthorized access.

more memory than is
physically available by
temporarily transferring
data from RAM to
disk storage, enabling
the execution of
larger programs and
multitasking.

When you open / run an application, the OS will load it into RAM. First, it will locarte the

Virtual memory

application on the storage device (likely a hard disk drive or solid state drive) and read the
executable file (.exe on Windows or .app on Mac). This file contains all the application’s code

and initial data.
The OS then allocates the necessary memory space for the application. This includes space
for the code, data and any other required resources. The OS ensures that the application has
enough space to execute without interfering with other processes.
Physical memory

(per process)

Once the application is loaded into RAM, the OS
continuously manages memory to ensure efficient operation
and system stability. While the application is running,
the OS can dynamically allocate and de-allocate memory
as needed by the application. The OS also ensures that
each process operates within its own memory space. This
prevents processes from interfering with each other, which
enhances the security and stability of the system.

Another process’s
memory,

If the applications require more memory than is available
in the RAM, the OS can use virtual memory to keep the
system running smoothly. Virtual memory is when the
OS allocates some space on the hard disk drive (HDD) or
solid state drive (SSD) to use as RAM. This is not an ideal

situation, as reading from a storage device is much slower

than accessing RAM but, by switching processes with a
higher priority into RAM, and those with lower priority

into virtual memory, the OS is able to continue to run the
system at an optimal level.

(;Top tip!
Think of memory management as organizing books on
a bookshelf. The operating system allocates each book
(process) its own space on the shelf (memory). Just as you

wouldn't let books overlap or mix up, the OS ensures that
each process has its own protected area in memory.
Disk
W Relationship between virtual memory and physical memory

A1 Computer fundamentals

H File management
File management is a crucial function of an OS, involving the storage,
retrieval, organization and manipulation of data on storage devices. The OS

provides a structured way to manage files and directories, ensuring system
stability and security.
The OS employs a hierarchical file system to organize files in a logical and
structured manner. Files are organized into directories (or folders), which can
contain further directories, creating a tree-like structure. This organization
makes it easier for users and applications to locate and manage data.
The OS allows a number of set file operations that users and applications
can perform on the files and directories, including creating new files and
directories; reading and writing data to files; deleting files; renaming files;
and moving or copying files and directories to different locations.
To ensure consistency and avoid conflicts, the OS enforces rules for naming

files, ensuring no two files in the same directory have the same name.
Files often have extensions, like .jpg or .exe, to indicate the file type and
B Windows File Explorer view displaying a

associated application although, depending on the OS settings, these may be

hierarchical directory structure

hidden from the user.

= ek v
-

-

AN

AN

AN

AN

AN

N

TN

D

[N

[N

4 e
e

= Lo
= Ly

B MacOS finder view displaying a hierarchical directory structure

M Some of the most commonly used file extensions

¢ File extension: 3

When managing the storage of files, the OS uses various methods to improve performance;

suffix at the end of a

this includes how it allocates files on the physical storage medium, manages free space

filename that indicates

and performs maintenance on the saved data. One important maintenance task is

the file type and the
program associated with
opening or processing
that file (e.g. .docx for

defragmentation, which reorganizes fragmented data on a hard disk drive (I11DD).

Word documents, .jpg

Fragmentation occurs over time as files are created, modified and deleted, causing them to
be scattered across different
sectors of the. disk. Defragmentation
[ aims to rearrange these file
.
.
)
]

ragments into contiguous sequences, so improving system performance.

for images).

# Defragmentation:
the process of
reorganizing the data on

a hard drive so that files
are stored in contiguous
blocks, reducing
fragmentation and
impraving access speed
and overall system
performance.

A1.3 Operating systems and control systems

# Device drivers:
specialized software
programs that allow
the operating system

to communicate with
and control hardware
devices, e.g. printers,
graphics cards or network
adapters, by providing
the necessary instructions

and protocols.
# Buffering: the
process of temporarily
storing data in a memory

area (buffer) while it
is being transferred
between two devices
or processes, helping
to manage differences
in data-flow rates
and ensuring smooth,
uninterrupted operation.
# Caching: the process
of temporarily storing
frequently accessed data
in a high-speed storage
area (cache) to reduce

l Device management
Operating system device management ensures that hardware devices operate etficiently
and interact seamlessly with software applications. The OS controls and co-ordinates the

use of hardware components such as printers, disk drives, display screens, keyboards and
network interfaces through specialized software called device drivers. Device drivers are

essential programs that enable the OS to communicate with connected hardware. Each piece
of hardware requires a specific driver to function correctly and efficiently. The OS uses these

drivers to provide a uniform interface, allowing applications to interact with the hardware
without needing to understand the hardware’s specifics.

The OS also handles input/output (I/0) management to co-ordinate data transfer between
the computer and peripheral devices. It employs techniques such as buffering, caching and

spooling to optimize performance and reliability. Buffering involves using temporary storage
areas to hold data while it is being transferred between devices, accommodating speed

differences between the CPU and peripheral devices. Caching stores frequently accessed data
to reduce access times, improving overall system efficiency. Spooling queues data and sends it
in a manageable order to devices such as printers that cannot handle interleaved data streams.
Modern operating systems have introduced user-friendly ways of connecting devices, such

as Plug and Play (PnP) technology. With PnP, the OS can automatically identify a device that
has been attached and install the necessary drivers and configure settings without the need

for user interaction. The OS is also capable of detecting errors and taking action to recover
from them, by resetting the device, reinitializing drivers or notifying the user of the issue.
Additionally, the OS provides security and access control to ensure that only authorized users
and processes can access certain devices, maintaining system integrity and security.

access time and improve
system performance
by enabling quicker
retrieval of the data.

Application

Software —

the system to continue

working on other tasks
in the meantime.

- = =

4 Spooling: the process
of gqueuing data or tasks
in a buffer, typically for
input / output devices
such as printers, so that
they can be processed
sequentially and at their
own pace, allowing

User

y
L]

Operating system

Device driver

# Plug and Play (PnP):
a technology that allows

Hardware in __|

the operating system

W Device drivers act as intermediaries between the operating system and hardware devices, enabling
software to communicate effectively with hardware components

to detect, configure

and install drivers
automatically for new
hardware devices when
they are connected to
the computer, enabling
them to work without
requiring manual set-up
by the user.

most cases

Device

H Scheduling
The OS schedules the process of managing the execution of multiple processes by determining
which process runs at any given time. The scheduler is responsible for allocating CPU time

to processes, ensuring efficient and fair use of system resources. This function is crucial
for mulritasking environments, where multiple applications and background processes run

concurrently. By implementing various scheduling algorithms, the OS aims to optimize
performance, reduce wait times and maintain system stabiliry.

A1 Computer fundamentals

In Section A1.3.3, we will delve deeper into specific scheduling approaches, including first
come first served, round robin, multilevel queue scheduling and priority scheduling. Each
method has its own advantages and trade-offs, and its suitability depends on the specitic
requirements and goals of the system.

B Security
The OS security is designed to protect the integrity, confidentiality and availability of information
and resources within the computer system. It has mechanisms to safegnard against threats,

prevent unauthorized access and ensure that users and applications can operate securely.

User authentication
User authentication can be used in multiple ways. Initially, the OS may require the user to
authenticate themselves to log in to the system. It would require the user to provide credentials
# Security tokens:
physical or digital
devices that generate
or store authentication
credentials, such as
one-time passwords or
cryptographic keys, used
to verify a user’s identity
and secure access to
systems, networks or
online services.

such as a username and password, biometric data or security tokens. Once logged on, based
on the user settings, the OS can then grant or prevent access to certain files, folders or
applications on the system. This allows systems to have multiple users with ditferent access
credentials, such as an administrator and a standard user.

Encryption
The OS can provide tools and frameworks for encrypting files, communication channels
and devices. The encryption ensures that the data, even if it is intercepted or accessed by
unauthorized individuals, cannot be read without the decryption key.

Auditing and monitoring
All system activities, such as users logging in, file access, system errors and administrator
actions, are tracked by the OS in a log. These logs are used for auditing and monitoring
purposes and can help administrators detect suspicious activities and potential security

breaches. They can also be used to help identify issues and areas for improving the
system performance.
[*]
Fls

Adbon

Ve Help

e sE AT
& Cremt Voo fLosall

Dot

5 Cusstem Vs

- e Wt Lage
5T
B
fonmtr

& Open Swetdl
.

|| st

oot St

['] Femmared Evanen

Clemag

7 hpphostons
sad Serecus Lo | (1

Y

e Conn

b Subporghiang

0[

-

o e

:
L bu-

e pocesn Pesmaey o o T ey Rty s oeta .o
'Mmm«“qcmm\wnmmlw-umn

el S o
AmnenaTee
Wt

"

0 ey

.

i Rebesh
i

2] Eeara Pt

B actucn
e
Leg hame

Sywam

Uer

SraTEM

Sowsw
forw 2
Lo

oo

e St
*
e
L

Wy imlgrmate: (e L Omine
e

B Windows Event Viewer

A1.3 Operating systems and control systems

[
S
N
[Ru—
Compumer

1000

IR

oy

J

0 e

.

Ll St tuincta
=

Malware protection
# Malware: a general
term for any software
designed with malicious
intent, e.g. viruses,

The OS includes mechanisms to detect and prevent malware infections and intruders. These
include antivirus software, firewalls and intrusion detection systems (IDS). These tools scan
for malicious software, monitor network traffic and block unauthorized access attempts,
protecting the system from viruses, worms, trojans and other malicious threats.

worms, trojans, spyware
and ransomware, which

Bl Accounting

can damage systems,
steal data or disrupt

Operating system accounting functions are essential for monitoring and managing the usage

# Viruses: malicious
software programs
that attach themselves
to legitimate files or
programs and spread to
other files or systems,
often causing damage
or disruption.
4 Worms: selfreplicating malware that
spreads across networks
without needing
to attach to other
programs, exploiting
vulnerahilities to infect
multiple systems.
# Trojans: deceptive
programs that appear

legitimate but carry
hidden malicious code,
which can create
backdoors, steal data

or cause harm once
executed by the user.

of system resources. These functions track resource consumption by users and processes,

providing valuable data for system administrators to analyse performance, allocate costs and
optimize resource utilization. The key aspects of OS accounting functions include:
Resource usage tracking
The OS continuously monitors the consumption of various resources by users and

processes; this includes tracking:
00 CPU usage: the amount of CPU time consumed by each process or user

00 memory usage: the amount of RAM allocated and used by each process
O disk usage: the amount of storage space occupied by files and directories owned by

each user
O nerwork usage: the volume of data sent and received over the network by each process
Or user.

Process accounting

Process accounting involves maintaining detailed records of each process that runs on the
system,; this includes information such as:
[ process ID: a unique identifier for each process
Ooooao

operations.

user ID: the identifier of the user who initiated the process
execution time: the total CPU time used by the process
start and end times: the timestamps indicating when the process started and finished
resource consumption: details on the amount of memory, disk I/O and other resources
used by the process.

User accounting
User accounting tracks the resource usage by individual users or user groups; this
information is crucial for:
O

cost allocation: in mulri-user environments, such as universities or enterprises,

resource usage data can be used to allocate costs to different departments or projects
based on their consumption

0 quota management: enforcing resource usage limits for users to prevent any single user
from monopolizing system resources; this can include disk quotas, limiting the amount
of storage a user can use and memory Cll.lDlEl’S.

Performance monitoring

The OS accounting functions are integral to performance monitoring; by analysing
resource usage data, system administrators can identify:

0 bottlenecks: areas where resources are being overutilized, causing performance
degradation

O underutilization: resources that are underused, indicating potential areas for
optimization
[ trends: patterns in resource usage over time, which can inform capacity planning and

system upgrades.

A1 Computer fundamentals

B Auditing and reporting

The OS generates detailed reports based on the collected accounting data; these reports can
be used for:
O auditing: ensuring compliance with organizational policies and regulatory requirements
by reviewing resource usage and access patterns
[ security analysis: detecting unusual or suspicious activity by analysing resource

usage anomalies
[0 resource management: making informed decisions about resource allocation, system
configuration and future investments.
B Billing and chargeback
In environments where resource usage needs to be billed to individual users or

departments, such as cloud-computing services or academic institutions, OS accounting
functions enable:
[0 usage-based billing: charging users based on their actual resource consumption, such
as CPU hours, memory usage and network bandwidth
00 chargeback: allocating costs to different departments or projects based on their

resource usage, promoting accountability and efficient resource use.

Bl Graphical user interface
By offering visual elements such as windows, icons, menus and pointers, the OS provides a
user-friendly environment for interacting with the computer and allows the user to execure
commands, manage files and run applications.

M The Ubuntu GUI

User interface elements
The user interface elements provided by the OS allow the user to interact with the system
intuitively. These elements include windows, which display the contents of applications,

documents or system information. Icons give graphical representation to applications, files
and system functions, providing quick access to frequently used items. Menus offer lists
of commands or options to access various functions, making navigation and operation

straightforward. Pointers, usually represented by an arrow or cursor, can be controlled
with an input device like a mouse, enabling users to select, drag and interact with GUI

elements seamlessly.
A1.3 Operating systems and control systems

-

Application management
The GUIT facilitates the management of and interaction with multiple applications, enhancing
user productivity and experience. Task switching allows users to move quickly between

open applications, with features like the taskbar or application switcher (Alt + tab) enabling
efficient navigation. Window management helps users organize their workspace by arranging,

overlapping and tiling windows. Features such as snapping windows to edges or corners
create a split-screen effect for multitasking. The desktop environment, where users can place
icons, shortcuts and widgets, allows for a personalized and organized workspace, catering to
individual preferences.

File and system management
The GUIT simplifies file and system management tasks through visual tools and interfaces. A
GUI-based file management tool, like the File Explorer, allows users to navigate directories,
view file properties and perform operations such as copying, moving, deleting and renaming
files and folders. This tool often includes features such as search, sort and filter to facilitate file
management. The GUI also provides access to system settings and control panels, enabling
users to configure hardware, software and system preferences through intuitive graphical

interfaces. Drag-and-drop functionality offers a user-friendly method for transferring files and
data between applications and directories.

Accessibility
The GUT includes features that enhance accessibility for users with disabilities, ensuring that
the system is usable by everyone. Screen readers convert text and GUI elements into speech
or Braille, helping visually impaired users to navigate the system. High-contrast themes and
screen magnifiers improve readability for users with low vision. Keyboard shortcuts allow
users to perform actions quickly without relying on a mouse or touchpad, benefiting users

with limited mobility.
‘e

¢

s

}

Security& Privacy
General

FileVault

Q

Firewall

Allow the apps below to control your computer.

Input Monitoring

- Full Disk Access
. Fies and Folders

[ screen Recording

.

Click the lock to make changes

W MacOS accessibility features

A1 Computer fundamentals

Visual feedback
The GUI provides immediate visual feedback to user actions, enhancing the overall user
experience. Progress indicators, including progress bars and loading animations, inform

users about the status of ongoing operations such as file transfers or software installations.
Notifications, in the form of pop-up messages and alerts, keep users informed about important

events, updates or errors. Tooltips — small informative text boxes that appear when users hover
over icons or interface elements — provide additional information or guidance.

Customization and personalization
The GUI allows users to personalize their computing environment to suit their preferences,
making the system more enjoyable and efficient to use. Users can change the appearance of the
GUI by selecting different themes, wallpapers and window styles, creating a more customized
experience. Widgets and gadgets — small applications that provide quick access to information
and tools such as weather updates, calendars and system monitors — enhance the functionality
and aesthetics of the desktop. These customization options enable users to tailor their
workspace to their needs and preferences, improving overall satisfaction and productivity.

B Virtualization
# Hypervisor:

software that creates
and manages virtual
machines by allowing
multiple operating
systems to run

Virtualization is a key feature of modern operating systems that allows multiple virtual
machines (VMs) to run on a single physical machine. Each VM operates independently, with
its own OS and applications. The operating system manages this through a hypervisor, which

allocates CPU time, memory and storage to each VM, ensuring efficient use of resources and
allowing each VM to function as if it were on a separate physical machine.

simultaneously on a
single physical machine,
sharing the underlying
hardware resources.

Virtualization enhances security and stability by isolating VMs from each other, preventing

# Load balancing: the
process of distributing
netwaork or application
traffic across multiple
Servers or resources
to ensure optimal
performance, reliability
and availability,
preventing any single
server from becoming
overwhelmed.

crucial fearure, aiding in load balancing and hardware maintenance.

issues in one VM from affecting others. It also allows for snapshots and backups, enabling
administrators to save the current state of a VM and revert to it if necessary. Live migrations,
which move VMs from one physical host to another without interrupting services, are another

Additionally, virtualization supports disaster recovery and cloud services. By allowing
VMs to be easily backed up and restored, the OS ensures that critical applications and

data can be quickly recovered in case of failure. Virtualization also enables dynamic
scaling of IT infrastructure in cloud environments, allowing businesses to adapt quickly to
changing demands.

B Networking
Operating systems manage and facilitate network communication. One of the primary

functions of an OS in networking is to establish and maintain network connections. The
OS manages network interfaces and protocols, enabling devices to connect to local area
networks (LANs), wide area networks (WANs) and the internet. It configures network settings,
assigns IP addresses through DHCP (Dynamic Host Configuration Protocol) and handles
the underlying hardware, such as network interface cards (NICs), ensuring that devices can
communicate effectively.
The OS also provides essential services for data transmission and communication between
devices. It implements various networking protocols, such as TCP/IP (Transmission Control
Protocol/Internet Protocol), which govern how data is packetized, addressed, transmitted,
routed and received. The OS ensures data integrity and efficient transmission by handling
error checking, flow control and congestion avoidance. Additionally, the OS supports higherlevel protocols and services, such as HTTP for web browsing, FTP for file transfers and

A1.3 Operating systems and control systems

SMTP for email communication, facilitating seamless interaction between applications and
network resources.

Security and access control are critical network functions managed by the OS. The OS employs

firewalls, encryption and authentication mechanisms to protect data as it travels across
networks. Firewalls monitor and control incoming and outgoing network traffic based on

predetermined security rules, helping to prevent unauthorized access and attacks. The OS also
supports virtual private networks (VPNs), which encrypt data and create secure connections

over public networks, ensuring privacy and security for remote users. These security features
safeguard nerwork communication and ensure that only authorized users and devices can

access network resources.

1
2

What is the primary role of an operating system in a computer?
How does the operating system abstract hardware complexities for users? Provide
an example.

3

Explain how the operating system manages multitasking and resource allocation. Why is
this important?

4

What are some of the key challenges the operating system faces in resource management?

5

What is memory management, and how does the operating system ensure efficient use
of memory?
Describe the role of device drivers in operating system device management.
How does the operating system manage files and directories? Give examples of filemanagement operations.

8

What is the importance of process scheduling, and what are some common scheduling
algorithms used by operating systems?

9

Explain how the operating system handles security and access control. Why are these
functions critical?

Risk-taker: Research and information literacy
In this task, you will improve your research and information literacy skills by installing
Ubuntu, a popular Linux distribution, and comparing it with another operating system of
your choice.
1 Install Ubuntu on to a device (this could be a spare PC, a Raspberry Pi, a virtual
machine or even a USB drive). Document the installation process, noting how the OS
manages hardware and interacts with the user.
2 Research and compare:
a Choose another OS you are familiar with (for example Windows or macOS).
b Research the difference in how Ubuntu and your chosen OS handle key aspects
such as:
i
user interface (including accessibility features)
ii file management
il memory management
iv software installation and updates.
3 Present your findings:
a Create a comparison table or chart to visually present the differences.
b Include a reflection on what you learned.

A1 Computer fundamentals

1

Run the simple Python “Memory Hog” program below, which continuously allocates memory
until the system runs out.

Important note: Running this script may cause your system to become unresponsive, as it
will use up all available memory. It's recommended to run this in a controlled environment,
such as a virtual machine. You can use Ctrl + C (Windows) or Cmd + C (Mac) to stop the
program running.

Python
memory hog =

[]

try:

while True:
# Allocate a large list and append it to the
# memory hog list
memory hog.append([0] * 10**¢)
# Each list has
# 1 million zeros
print (f"Allocated {len(memory hog)} million items")
except MemoryError:
print ("Memory allocation failed! The system has run out
of memory.")

This script creates a large list and appends a million zeros each time it loops. When
the system can no longer allocate memory (due to running out of available RAM), a

“"MemoryError” exception is raised and will be output. You can monitor your system memory
using Task Manager on Windows or Activity Monitor on macOS.

Processes

Ho Run new task

Processes

Ho Run new task

M Windows Task Manager showing the memory usage of the program above as it runs

A1.3 Operating systems and control systems

2

File-management tasks
a

Creating directories and files:
Step 1: Open the File Explorer (Windows) or Finder (macOS) on your computer.
Step 2: Navigate to a location where you can create a new directory (for example your
desktop or documents folder).
* Windows: Right-click > New > Folder
* MacOS: Right-click or Ctrl-click > New Folder
Step 3: Inside "ProjectFiles”, create three subfolders named "Reports”, “Data” and "Images”.

Step 4: Within the "Reports” folder, create three text files named “Report1.txt”,
“Report2.txt” and "Summary.txt”. Use a text editor (for example Notepad or TextEdit) to
create these files, and include a few lines of sample text in each file.
b

Moving files:
Step 1: Move "Report2.txt” from the “Reports” folder to the “Data” folder.
*

Windows: Drag and drop the file to the new location or right-click > Cut, then rightclick in the destination folder and select Paste

*

MacOS: Drag and drop the file or use Cmd + C (copy) and Cmd + V (paste).

Step 2: Move “Summary.txt” from the “Reports” folder to the “Images” folder using the
same methods.
¢

Renaming files:
Step 1: Rename "Reportl.txt” to "FinalReport.txt”.
* Windows: Right-click the file > Rename
e

MacOS: Click the file name once to select, then click again to edit.

Step 2: Rename the “Data” folder “ProjectData”.
d

Deleting files and directories:
Step 1: Delete the “Images” folder along with its contents.
* Windows: Right-click the folder > Delete
*

MacOS: Drag the folder to the Trash or right-click = Move to Trash.

Step 2: Recover the deleted “Images” folder from the Recycle Bin (Windows) or Trash (macOS).
* Windows: Open the Recycle Bin, right-click on the “lmages” folder, and choose “Restore”
*

3

MacOS: Open the Trash, locate the “Images” folder, right-click it, and choose
"Put Back” to restore it to its original location.

Research how to complete the same tasks away from the GUI using the OS terminal
(Command Prompt / cd on Windows or Terminal on macOS).

4

Accessibility features
Complete one of the following tasks on your chosen OS.
a

Explore accessibility features on Windows:

Step 1: Open the Control Panel by pressing Windows + R, typing control, and pressing Enter.
Step 2: Navigate to Ease of Access Center.
Step 3: Explore various accessibility features, such as Narrator (screen reader), Magnifier,
High Contrast Mode, Speech Recognition and On-Screen Keyboard.
Step 4: Activate and interact with at least two of these features, for example turn on
Narrator and Magnifier, and navigate through the desktop or a web page to understand
how these features assist users.
b

Explore accessibility features on macQS:

Step 1: Open System Preferences by clicking on the Apple menu and selecting System
Preferences.
Step 2: Go to the Accessibility section.
Step 3: Explore various features, such as VoiceOver (screen reader), Zoom, Display (for
colour filters, invert colours), Speak Selection and Dictation.

Step 4: Activate and interact with at least two of these features, for example enable
VoiceOver and Zoom and use them to navigate the system or read through a document.

A1 Computer fundamentals

Monopolize

A1.3.3 Approaches for scheduling

resources: the control
or domination of the
use of system resources

An operaring system needs scheduling methods to efficiently manage the execurion of
multiple processes, ensuring optimal use of the CPU and other resources. Scheduling

(e.g. CPU, memory or

determines the order in which processes are granted access to the CPU and their duration,

network bandwidth) by
a single process or user,
often to the detriment
of other processes
or users, leading to

effective scheduling, processes could experience significant delays or monopolize resources,

inefficiency or system

scheduling and multilevel queue scheduling, each with its own advantages and trade-offs.

balancing the needs of various applications and maintaining system responsiveness. Without
leading to poor performance and user frustration. In the following section, we will examine
several different scheduling methods, including first come first served, round robin, priority

slowdowns.

B First come first served
First come first served (FCFS) is one of the simplest

scheduling algorithms used by operating systems to
manage the execution of processes. In FCFS scheduling, the
processes are executed in the order they arrive in the ready

queue. When a process arrives, it is added to the end of the
queue. The CPU scheduler selects the process at the front

of the queue and assigns it to the CPU until it completes its
execution or moves to an I/Q wait state. Once the current
process is finished, the next process in the queue is selected,

and this continues until all processes have been executed.
The simplicity of FCFS makes it easy to implement and
understand. [However, it has some drawbacks, such as the

“convoy effect”, where short processes may be delayed by
long-running processes, leading to increased waiting time
and lower system throughput. This method is non-preemptive, meaning that once a process is assigned to the
CPU, it cannot be interrupted until it completes, which can
B FCFS: waiting in line to be served

cause inefficiency in certain scenarios.

Advantages

Disadvantages

Simple and easy to implement

Convoy effect can cause significant delays

Fair, as it processes requests in the order they arrive

Non-pre-emptive nature can lead to inefficiency and
longer than average waiting times

In this example, P1 arrives first and is executed immediately, followed by P2 and P3 in the
order they arrive. Each process runs to completion before the next process begins.
Process

Queue

P1 arrives

P1

P2 arrives

P1, P2

P3 arrives

P1, P2, P3

Time

Process

0

P1
P2
P3

A1.3 Operating systems and control systems

1

2

3

4

5

6

7

8

9

B Round robin
Round robin (RR) is a pre-emptive scheduling algorithm
designed to provide fair time-sharing among processes.
Each process is assigned a fixed time slice, known as a
“gquantum”, during which it can execute. When a process’s
quantum expires, the CPU scheduler pre-empts the process
and places it at the end of the ready queue, then selects the
next process in line for execution. This cycle continues
until all processes are completed.
The primary advantage of round robin scheduling is that
it ensures a high level of responsiveness, as no process
can monopolize the CPU for an extended period. This
approach is especially effective in time-sharing systems
where multiple users or applications need to interact with
the CPU frequently. The length of the time quantum is

critical: if it is too short, the system spends too much time
B Round robin: each task takes a turn in a continuous cycle,

switching between processes; if it is too long, it resembles

ensuring that each one gets equal time

FCFS scheduling.

Advantages

Disadvantages

Fair allocation of CPU time between processes

Time quantum selection is crucial for performance

High responsiveness and improved system
interactivity

High context-switching overhead if the time quantum
is too short

Prevents any single process from monopolizing
the CPU

Potential inefficiency if processes frequently complete
their tasks within a single quantum

In this example, process P1 runs from time O to 2, then is pre-empted. Process P2 runs from
time 2 to 4, then is pre-empted. Then, process P3 runs from time 4 to 6 and is pre-empted. The
cycle repeats, with P1 running again from time 6 to 8, P2 from 8 to 10 and P3 from 10 to 12.
Process

Queue

P1 arrives

P1

P2 arrives

P1, P2

P3 arrives

P1, P2, P3

Time
Process

0

1

2

3

4

5

6

7

8

9

10

n

P1
P2

P3

A1 Computer fundamentals

B Priority scheduling
Priority scheduling is a method where each process is
assigned a priority level, and the CPU is allocated to the
process with the highest priority. Processes with higher
priority levels are executed before those with lower priority
levels. If two processes have the same priority, they are
scheduled according to their arrival order, typically
using FCFS. Priority can be either static (meaning it is
assigned when the process is created and does not change)

or dynamic (meaning it can change over time based on
various factors such as ageing).
The main goal of priority scheduling is to ensure that
critical tasks are executed as soon as possible, enhancing
the responsiveness of high-priority processes. However,
a significant drawback is the potential for low-priority

processes to suffer from starvation if high-priority
processes continually dominate CPU time. To mitigate

with higher priority (such as first class ticketholders or those with

this, some systems implement ageing, which gradually
increases the priority of waiting processes to ensure they

a disability) are given faster service

eventually receive CPU time.

M An example of a priority lane at an airport, where passengers

Advantages

Disadvantages

Prioritizes important tasks, improving system
responsiveness for critical applications

Risk of starvation for low-priority processes

Flexible, as priorities can be adjusted dynamically

More complex to implement and manage than

based on system needs

simpler scheduling methods

Priority inversion, where a lower-priority process
holds a resource needed by a higher-priority process,
can be an issue if not handled properly

In this example, P1 and P4, both high-priority processes, are executed first. After the high-

priority processes are completed, the medium-priority process P2 is executed, followed by the
low-priority process P3.
Process

Arrival time | Priority level

P1

0

High

P2

1

Medium

P3

2

Low

P4

3

High
Time

Process

P1 (High)
P2 (Medium)
P3 (Low)

P4 (High)

A1.3 Operating systems and control systems

0

1

2

3

4

5

6

7

B Multilevel queue scheduling
Multilevel queue scheduling is a scheduling algorithm that partitions the ready queue into
several separate queues, each with its own scheduling algorithm and priority level. Processes

are permanently assigned to one of these queues based on certain characteristics, such as
process type, priority or memory requirements. Each queue may use a different scheduling

algorithm, such as FCFS or round robin, and the queues themselves are scheduled in a specific
order, often based on priority.
In this approach, higher-priority queues are given more CPU time compared to lower-priority
queues. For example, interactive processes might be placed in a high-priority queue scheduled

with round robin, while batch processes are placed in a lower-priority queue scheduled with
FFCFS. The CPU scheduler selects processes from the highest-priority queue first, moving to

lower-priority queues only when the higher-priority queues are empty.
Advantages

Disadvantages

Flexibility in handling different types of processes

Starvation of lower-priority processes if higherpriority gueues are frequently occupied

Prioritizes critical and interactive processes, improving | Complex implementation and management
responsiveness for important tasks
Different scheduling algorithms can be tailored to the | Processes are permanently assigned to queues, which
needs of each queue
might not be optimal if their behaviour changes
over time

In this example, processes in the high-priority queue (P1 and P2) are scheduled first using
round robin. Both P1 and P2 complete. The scheduler then moves to the medium-priority
queue (P3), and then to the low-priority queue (P4) only when the high-priority queue does
not have processes ready to run. However, it frequently checks back to the high-priority queue,
which is why P2 (high) runs again after P4 (low).
Queue priority

Process type

Scheduling algorithm

Process queue

Q1 -High

Interactive

Round robin (time quantum = 2)

P1, P2

Q2 — Medium

Batch

FCFS

P3

Q3 - Low

Background / idle

FCFS

P4

Time
Process

0

1

2

3

4

5

6

7

9

10

1

12

P1 (High)
P2 (High)
P3 (Medium)
P4 (Low)

(;Common mistake
Don't forget that context switching — when the CPU switches from one task to another - can

slow things down. Even though it allows for multitasking, too much switching can reduce how
efficiently the system runs because the CPU spends time saving and restoring tasks.

A1 Computer fundamentals

1

Explain the difference between first come first served (FCFS) scheduling and round
robin scheduling. How does the choice of time quantum in round robin affect
process performance?

2

What is the purpose of priority scheduling, and how does it differ from multilevel queue
scheduling? Provide an example of where each might be preferred.

3

In the context of operating systems, what is meant by context switching, and why is it

important in process scheduling?
4

Describe how multilevel queue scheduling works and discuss its advantages

and disadvantages.
5

How does the operating system ensure fairness in scheduling while also optimizing
performance? Discuss this in the context of round robin and priority scheduling.

6

What are the potential drawbacks of using a first come first served scheduling algorithm
in a multi-user environment?

7

Why might an operating system choose to implement a hybrid scheduling approach, and
what benefits does this provide?

Write a program to simulate different CPU scheduling algorithms and analyse their performance on process execution.
Here is an example of how you could implement FCFS scheduling in Python.

Python
# Define a class to represent a process in the system
class Process:
def _ init_ (self, pid, arrival_ time, burst_time):
self.pid = pid

# Process ID

self.arrival time = arrival time
# arrives in the system
-

# The time at which the process

self
. burst time = burst time # The total time required by the
# process to complete execution
self.waiting time = 0
# starts execution

# Time the process has to wait before it

self.turnaround time = 0
# completion

# Total time taken from arriwval to

(w;iting_time + burst_time)

# Define a function to simulate FCFS scheduling
def calculate fcfs(processes):
start time = 0

# Variable to track the current time at which a process

= starts execution
# Iterate over each process in the list
for process in processes:
# If the current time is less than the process's arrival time,
# the CPU remains idle until the process arrives

if start_time < process.arrival
time:
start_time = process.arrival
time
# Calculate the waiting time for the process

A1.3 Operating systems and control systems

83

process.waiting
time = start time - process.arrival
time
# Calculate the turnarcund time for the process
process.turnaround
time = process.waiting
time + process.burst
time
# Update the current time to reflect the process's execution

start_time += process.burst
time
# After all processes are scheduled,

calculate the total and average

# waiting / turnaround times
total waiting time = sum([p.waiting time for p in processes])
= all_waiting_times
N

# Sum of

total turnarocund time = sum([p.turnaround time for p in processes])

# of all turnaround times

# Sum

N

avgwaiting
time = total waiting time / len(processes)

# Average waiting

# time
avg_turnaround
time = total turnaround
time / len(processes)
# turnaround time

# Average

# Display the results in a table format
print ("Process\tArrival Time\tBurst Time\tWaiting Time\tTurnaround Time")
for process in processes:

print (£"{process.pid}\t{process.arrival time}\t\t{process.burst_time}\
t\t{process.waiting time}\t\t{process.turnaround time}")
# Print the calculated average times
print (f"\nAverage Waiting Time:

{avg waiting time:.2f}")

print (f"Average Turnaround Time:

{avg turnaround time:.2f}")

# Example process list to simulate FCFS scheduling
processes =

[

Process
(1, 0,

5),

# Process 1 arrives at time

0

and requires 5 time

# Process 2 arrives at time 2

and requires 3 time

1),

# Process 3 arrives at time 4

and requires 1 time unit

7)

# Process 4 arrives at time 6

and requires 7 time

# units to complete
Process
(2, 2,

3),

# units to complete
Process
(3, 4,

# to complete
Process
(4, 6,

# units to complete
# Sort the processes by their arrival time before running the FCFS algorithm
processes.sort (key=lambda x: x.arrival time)
# Run the FCFS scheduling simulation

calculate fcfs(processes)

A1 Computer fundamentals

A1.3.4 Interrupt handling and polling
Interrupt handling and polling are two fundamental techniques used by operating systems to
manage communication between the CPU and peripheral devices. Each method has its own
advantages and drawbacks that can affect system performance and efticiency, depending on
the context in which they are used.

M Interrupt handling
Interrupt handling is a mechanism where peripheral devices signal the CPU to gain its
attention and request service. When an event occurs, such as an input from a keyboard or
data from a network interface, the device sends an interrupt signal to the CPU. The CPU then
# Interrupt service
routine (ISR): a
special function in a

pauses its current operations, saves its state and executes an interrupt service routine (ISR)

computer system that

sporadically or unpredictably. Interrupt handling ensures that the CPU only deals with events

automatically executes in
response to an interrupt

signal, handling specific
tasks, e.g. processing
input from hardware
devices or managing
system events, before

returning control to the
main program.
4 Latency: the delay
between the initiation
of an action and the
corresponding response,
often referring to the
time it takes for data to
travel from its source
to its destination in a

network or systemn.

to address the event. This method allows the CPU to remain idle or perform other tasks until
an event actually occurs, making it highly efficient in environments where events happen
when necessary, reducing unnecessary CPU cycles spent on checking for events.
However, the frequent occurrence of interrupts can introduce processing overheads due to the
context switching involved. Each time an interrupt is handled, the CPU must save its current
state and later restore it, which can be time-consuming and resource-intensive if interrupts are
too frequent. Additionally, handling a high volume of interrupts can lead to increased power
consumption, which is particularly critical for battery-powered devices. Despite these potential
drawbacks, the efficiency of interrupt handling in managing sporadic events and minimizing

CPU idle time makes it a preferred method in many real-time and interactive systems where
immediate response to events is crucial.

(‘Top tip!
An interrupt is like a doorbell ringing while you're busy warking. You stop what you're doing (pause
the current process), answer the door (handle the interrupt) and then return to your task. The
operating system manages these interruptions efficiently so that your work (the main process) isn't

significantly delayed.

H Polling
Polling, on the other hand, involves the CPU periodically checking each peripheral device
to see whether it requires attention. This method is straightforward and can be efficient
in systems where events occur at regular, predictable intervals. Polling ensures controlled
latency, as the CPU checks devices at predetermined times, making it suitable for real-time
applications where timely response is crucial. Polling can be implemented easily and provides
a simple mechanism to ensure that devices are checked regularly.

However, polling can lead to significant CPU processing overheads, as the CPU spends a
considerable amount of time repeatedly checking devices instead of performing useful work.

This continuous checking is resource-intensive and can detract from the system’s overall
efficiency. Additionally, polling is less power-efficient compared to interrupt handling, as the
CPU remains active even when there are no events to process. This constant activity can drain
the battery in portable devices more quickly than systems that utilize interrupt handling. In

environments where event frequency is low or unpredictable, polling can be highly inefficient
and wasteful, consuming CPU cycles without necessarily detecting any new events.

A1.3 Operating systems and control systems

B Interrupts vs polling
Criteria

Interrupts

Polling

Event frequency

Efficient for infrequent or unpredictable
events, as the CPU only responds when an
event occurs

More effective for regular, predictable
events, as the CPU checks devices at set
intervals regardless of event occurrence

CPU processing
overheads

Lower overhead for infrequent events
but can increase with high-frequency
interrupts due to context switching

Higher overhead due to constant checking
of devices, consuming CPU cycles even
when no events occur

Power source

More power-efficient, especially for
battery-powered devices, as the CPU
remains idle until an event occurs

Less power-efficient, as the CPU remains
active and continuously checks devices,
leading to higher power consumption

Event predictability

Controlled latency

Security concerns

Best for unpredictable events, as the

Suitable for predictable events, ensuring

system responds immediately to any
event occurrence

regular checks at set intervals

Can provide quick response times but, if
interrupts are too frequent, it can lead to

Provides controlled latency with
predictable response times, as checks

variability in response times

occur at regular intervals

Potentially more secure as the system can
quickly respond to critical events, reducing

Less secure if polling intervals are too
long, as it may delay the detection of

the window for malicious activity

critical events

The choice between interrupt handling and polling depends on the specific requirements and
constraints of the system. Interrupt handling is generally more efficient for sporadic events
and battery-powered devices, but can introduce overheads with high-frequency events. Polling

offers predictable latency and is straightforward to implement, but can lead to inefficiencies
and higher power consumption. Understanding the trade-offs between these methods is

crucial for designing effective and efficient systems.

(;Common mistake
Remember that specific context is very important when deciding whether polling or interrupt
handling is a better system solution. It is not a simple choice of one being better than the other.
Interrupts are great for events that happen unpredictably, while polling is better for regular,
predictable events. Make sure you understand the difference so you can choose the right method
for each situation.

B Real-world scenarios
Mouse and keyboard
When a user moves the mouse or presses a key, these devices generate interrupt signals that
prompt the CPU to immediately pause its current tasks and execute the appropriate interrupt
service routine (ISR). This ensures that user inputs are processed in real-time, providing
instant feedback and seamless interaction. For example, as a user types, each keystroke
generates an interrupt that the OS handles promptly, ensuring that characters appear on the
screen without delay. Conversely, using polling for these devices would require the CPU to
continuously check the status of the mouse and keyboard, leading to unnecessary processing
overheads and increased power consumption, especially in battery-powered devices like
laptops. Polling could also result in delayed responses if the CPU is busy with other tasks

when a user input occurs.
For basic embedded systems like simple data-entry terminals or kiosks, where user interaction
is infrequent and the system is primarily idle, polling might be sufficient. Polling at regular

A1 Computer fundamentals

intervals to check for user input can simplify the system design and avoid the overhead of
setting up and handling interrupts. This is acceptable in low-activity environments where
immediate response is not critical.

Network communications
‘When data packets arrive at a network interface card (NIC), they generate interrupt signals
that alert the CPU to process the incoming data immediately. This prompt handling ensures
that data is quickly received, processed and passed to the appropriate application, maintaining
smooth and efficient network performance. For instance, during a video conference, interrupts
enable real-time processing of audio and video data, ensuring minimal latency and highquality communication. Conversely, using polling for network communications would require
the CPU to continually check the NIC for new data, leading to increased processing overheads
and potentially missing incoming packets if the CPU is occupied with other tasks. This could

result in delays, reduced network performance and higher power consumption, especially in
devices like smartphones or tablets.
In scenarios where network traffic is minimal and predictable, such as a remote monitoring
system that periodically sends small data packets, polling can be more efficient. Polling at
regular intervals to check tor network activity reduces the complexity of interrupt handling
and is sufficient to handle the infrequent, predictable communication needs.

Disk input / output operations
When a disk drive completes a read or write operation, it generates an interrupt signal that
alerts the CPU to handle the data transfer immediately. This approach allows the CPU to
execute other tasks while waiting for the disk operation to complete, enhancing overall
system efficiency. For example, when a file is saved, the CPU can continue processing other
applications until the disk signals that the write operation is finished, at which point the CPU
promptly transfers the data to the appropriate location. Conversely, using polling for disk 1/0
operations would require the CPU to continuously check the status of the disk drive, leading

to significant processing overheads and reduced efficiency. The CPU would waste valuable
cycles repeatedly checking for completion, especially during lengthy disk operations, resulting

in slower system performance and increased power consumption.
In a system where disk access is predictable and infrequent, such as a data logger that writes
to a disk at fixed intervals, polling can be appropriate. Polling the disk tor readiness before
scheduled writes can simplify the implementation and eliminate the need for interrupt-driven

complexity, making the system easier to manage.

Embedded systems
Embedded systems, such as those in automotive control units or industrial machinery, often
need to respond quickly to sensor inputs and external signals. For example, in an automotive
airbag system, sensors detecting a collision generate interrupt signals that prompt the CPU to
immediately deploy the airbags. This rapid response is crucial for the safety and effectiveness
of the system. Conversely, using polling in this scenario would require the CPU to
continuously check sensor statuses, leading to increased processing overheads and potentially
missing critical events if the CPU is occupied with other tasks. This delay in response could be
catastrophic in time-sensitive applications.
In situations where events occur at regular, predictable intervals and the overhead of handling
interrupts is not justified, polling can be a better approach. For example, in a climate-control
system for a building, the temperature sensors might need to be checked at regular intervals to
maintain a constant environment. Here, polling would be advantageous.

A1.3 Operating systems and control systems

-

Real-time systems
In real-time systems, the choice between polling and interrupt handling depends on the
specific requirements of the application. While interrupts are typically preferred for their

quick response times, there are scenarios where polling can be more suitable.
For instance, in a real-time system that controls an industrial robot performing repetitive

tasks at fixed intervals, polling can be more predictable and easier to manage. The robot might
perform sensor checks and actuator adjustments at precise, regular intervals, ensuring that

the tasks are executed in a controlled manner. This use of polling can simplify the design and
avoid the overhead associated with frequent context switching that comes with interrupts,

ensuring that the system meets its timing requirements consistently. In this scenario, the
predictability and regularity of the events make polling a viable option, as it ensures that

the system performs checks and adjustments at the exact required intervals without the
complexity of handling numerous interrupts.

In a real-time system like an automotive airbag deployment system, interrupt handling
is crucial. The system must respond immediately to sensor inputs indicating a collision.

When sensors detect a rapid deceleration or impact, they generate interrupts that prompt
the CPU to execute the airbag deployment routine instantly. This immediate response is

essential to ensure the airbags deploy in time to protect the occupants. In such critical
applications, the ability of interrupts to provide an immediate and high-priority response to
specific events makes them the preferred choice, as any delay in processing could result in

catastrophic consequences.

1

Explain the fundamental difference between interrupt handling and polling in terms of how

they manage CPU attention for peripheral devices.
In what scenarios might polling be more efficient than interrupt handling, and why?
Describe a situation in which interrupt handling could be preferred over polling,
considering factors such as power consumption and response time.
4
5

How does the frequency of events affect the choice between interrupt handling
and polling?
What are the potential drawbacks of using interrupt handling in a system with high

event frequency?
6

Discuss how power source (battery vs mains power) can influence the choice between using
interrupts or polling in a system.

7

How does the need for controlled latency impact the decision between using interrupt
handling and polling? Provide an example of a system where controlled latency is critical.

8

Explain how security concerns could affect the choice between interrupt handling and

polling in a networked system.

A1 Computer fundamentals

A1.3.5 The role of the operating

system in managing multitasking
and resource allocation (HL)
The operating system (OS) plays a critical role in managing multitasking and resource
allocation, ensuring that multiple processes can run concurrently and efficiently on a

computer system. Multitasking allows a system to perform multiple tasks seemingly
simultaneously by quickly switching between them, while resource allocation ensures that
each task receives the necessary resources (CPU time, memory, I/O devices) to execute
properly. This involves several key functions and faces numerous challenges.

H Task scheduling
Task scheduling is one of the primary responsibilities of the OS in a multitasking
environment. The scheduler decides the order in which processes are executed, aiming to
maximize CPU utilization and system responsiveness. As discussed in Section A1.3.3, there
are various scheduling algorithms, such as first come first served (FCFS), round robin, priority
scheduling and multilevel queue scheduling, each with advantages and drawbacks. The
scheduler must balance the need to provide quick response times for interactive processes
with the efficient processing of background tasks. This balancing act is crucial for maintaining
system performance and user satisfaction.

H Resource contention
Resource contention occurs when multiple processes compete for the same resources, such as
CPU time, memory or 1/0 devices. The OS must manage this contention to prevent conflicts
and ensure fair and efficient resource usage. Techniques like mutual exclusion are used to
manage access to shared resources. Mutual exclusion is a key concept used in concurrent
programming to prevent multiple processes from accessing a shared resource or critical section

simultaneously. This ensures that only one process can use the resource at a time, preventing
data corruption and ensuring consistency. Techniques for achieving murual exclusion include

using semaphores, locks and monitors.
Improper management can lead to such issues as resource starvation, where a process is
constantly denied necessary resources, or priority inversion, where a lower-priority process
holds a resource needed by a higher-priority process. The OS must implement strategies to

handle these conflicts effectively to maintain system stability and performance.

Semaphores
Semaphores are synchronization tools used to control access to shared resources in a
concurrent system. A semaphore is an integer variable that can be incremented (signal) or
decremented (wait) atomically. There are two types of semaphores:
B Binary semaphores (mutex): Can only be 0 or 1, effectively acting as a lock to ensure
mutual exclusion.
For example: There are two processes that need to write to the same log file. To prevent
both processes from writing to the file at the same time (which could cause data
corruption):

1

The semaphore is initially set to 1, indicating that the log file is available.

2 When Process A wants to write to the log file, it checks the semaphore. If the
semaphore is 1, Process A sets it to 0 (locking the resource) and proceeds to write to the

log file.
A1.3 Operating systems and control systems

@

ATNO TH

3

If Process B tries to write to the log file while Process A is still writing, it will find the
semaphore set to 0 and will be blocked until Process A is finished.

4

Once Process A finishes writing, it sets the semaphore back to 1, allowing Process B
to proceed.

5

Process B then sets the semaphore to 0, writes to the log file, and finally sets the
semaphore back to 1 when dome.

® Counting semaphores: Can take any non-negative value, allowing multiple instances of a
resource to be managed.
For example: There is a limited number of database connections (e.g. three connections)
available to a group of processes:
1

The semaphore is initialized with a value of 3, representing the three available
connections.

2 When Process A needs a connection, it checks the semaphore. If the value is greater
than 0, Process A decrements the semaphore by 1 and gains access to a connection.
3

Process B and Process C do the same, decrementing the semaphore by 1 each time they
gain access, leaving the semaphore value at 0 once all three connections are in use.

4 1If Process D then requests a connection, it finds the semaphore at 0 and must wait until
one of the other processes releases a connection.

5 When Process A finishes using its connection, it increments the semaphore by 1,
signalling that a connection is now available. Process D can then proceed to use
the connection.

Locks
Locks are tools used to make sure that only one process can use a shared resource at a time.
For example, if two programs want to write to the same file, the first one must “lock” the file

before it can start writing. If the file is already locked by another program, the second program
has to wait until the lock is released. There are different types of locks, such as binary locks
(also called “mutexes”™), which allow only one process at a time, and readers-writer locks,
which let multiple processes read a resource but only one process write to it.

Monitors
Monitors are tools used in programming to help manage access to shared resources safely. They
ensure that only one process can use certain variables or methods at a time, preventing conflicts.
A monitor acts like a container that holds shared variables and the code (methods) that works

with them. When a process uses a monitors method, it automatically locks the monitor, so no
other process can use it until the first one is done. Monitors also have condition variables that
let processes wait for certain events to happen and notify others when those events occur. This
makes it easier to manage and co-ordinate tasks between different processes sately.

Bl Deadlock
Deadlock is a problem in multitasking systems where processes get stuck because each one is
waiting for a resource that another process has, creating a cycle with no way to move forward.
To handle deadlocks, the OS can use different strategies:
B Deadlock prevention involves designing the system so that deadlocks can't happen.
B Deadlock avoidance, such as using the Banker’s algorithm, ensures a system only allocates
resources if it can guarantee that all processes can eventually complete without entering an
unsafe state.

B Deadlock detection means regularly checking for stuck processes and then taking steps to
tix the problem.
A1 Computer fundamentals

B Deadlock recovery might involve stopping one or more processes to break the cycle or
reallocating resources differently.

B Multitasking challenges
The challenges of multitasking extend beyond task scheduling and resource contention. The
OS must also manage context-switching efficiently, where the state of a currently running
process is saved so that another process can be executed. Frequent context switches can
introduce overheads, reducing overall system performance. The OS must also ensure data

consistency and integrity, particularly when multiple processes access shared data. This
involves implementing robust synchronization mechanisms to prevent data corruption and

ensure that processes do not interfere with each other.

1

Explain how the operating system uses task scheduling to manage multitasking. Why is it
important for maintaining system performance?

2
3

What is resource contention, and how does the operating system resolve it to prevent
issues such as resource starvation and priority inversion?
Describe the role of semaphores in managing resource allocation in a multitasking

environment. How do binary and counting semaphaores differ?
4

How does the operating system handle deadlock in multitasking systems, and what
strategies can be used to prevent, avoid or resolve deadlocks?

5

What challenges does the operating system face in managing context-switching, and
how does this impact overall system performance?

A1.3.6 The use of the control
system components (HL)
Control systems are fundamental in automating and regulating processes across a wide range
of industries, from manufacturing to robotics and environmental control. At the core of any

control system are various components that work together to achieve desired outcomes by
managing inputs, processing data and generating outputs. These systems rely on a precise

feedback mechanism to ensure that the process remains stable and meets the set objectives.
This section explores the key elements of control systems, including the roles of the input,
process, output and feedback mechanisms, as well as the critical components such as
controllers, sensors, actuators and transducers, and the control algorithms that drive them.

Understanding these components and their interactions is essential for designing effective and
efficient control systems.

B Input, process, output and feedback mechanism
Input
In a control system, the input is the initial signal or data received by the system, representing
the desired condition or target that the system aims to achieve. This input could be anything
from a set temperature in a heating system to the desired speed in a motor-control application.
The input is typically generated by a user, another system or an environmental condition, and
serves as the reference point for the system’s operation.

A1.3 Operating systems and control systems

@

ATNO TH

Output
The output is the result produced by the control system after processing the input. It
represents the actual state or action of the system, such as turning on a heater to reach a set

temperature or adjusting the speed of a motor. The output is directly influenced by the input
and the control process, and it is typically the element that can be observed or measured to

determine the effectiveness of the system in achieving its desired goals.

Feedback mechanism (open-loop and closed-loop)
Control signal

Input

Control system

.
System being

controlled

M Open-loop control system
Input

Control signal

Control system

System being

controlled

Feedback loop
M Closed-loop control system

The feedback mechanism is a critical component in determining how a control system operates
and adjusts itself to maintain desired performance.

m

Open-loop control: In an open-loop system, there is no feedback from the output back
to the input or process. The system operates solely based on the initial input without any

correction or adjustment based on the actual output. This type of control is simple and
used in situations where the relationship between input and output is straightforward and

predictable, such as in basic timers or simple heating systems.
m Closed-loop control: A closed-loop system, also known as a “feedback control system”,
continuously monitors the output and feeds this informarion back into the system to adjust
the process accordingly. If the output deviates from the desired input, the system makes
corrections in real time to bring the output back in line with the target. This type of control
is essential in applications requiring high accuracy and adaptability, such as temperature
control in HVAC systems, where the system must adjust heating or cooling based on actual
temperature readings.

B Key components
Controller
The controller is the central component of a control system that governs the operation by
processing inputs and generating appropriate outputs. It acts as the “brain” of the system,
implementing the control algorithm to make decisions based on the input data and feedback.

The controller compares the input (desired value) with the feedback from the output (actual
value) and determines the necessary actions to minimize the difference, or error, between

them. This decision-making process can involve complex calculations, adjustments or
commands that are sent to actuators or other system components to achieve the desired

outcome. Controllers can range from simple devices such as thermostats to complex
microprocessors used in industrial automation.

A1 Computer fundamentals

Sensors

4

i

Temperature and humidity sensor

Touch sensor

Proximity sensor

Gas sensor

M Different types of sensors

Sensors are devices that detect and measure physical quantities from the environment or the
system itself, such as temperature, pressure, speed or light. These measurements are then
converted into electrical signals that can be interpreted by the controller. Sensors serve as

the “eyes and ears” of the control system, providing the necessary data for the controller
to make informed decisions. The accuracy and reliability of the sensors directly impact the

performance of the control system, as they provide the critical feedback needed to adjust the
system’s operations. For example, a temperature sensor in a climate-control system constantly
monitors the room temperature, allowing the controller to adjust heating or cooling to
maintain the desired setpoint.

Actuators
Actuators are the components in a control system that carry out the physical actions or
adjustments in response to commands from the controller. They are responsible for converting
the controller’s electrical signals into mechanical motion or other forms of energy, such
as turning a valve, moving a robotic arm or adjusting a motor’s speed. Actuators are the
“muscles” of the control system, executing the tasks that directly impact the system’s output.
The performance and precision of actuators are critical in applications where exact control of
movements or processes is required, such as in manufacturing equipment or robotics.

Transducers
Transducers are devices that convert one form of energy into another, typically used to bridge
the gap between sensors and actuators and the control system. In many cases, a sensor or
actuator may not directly provide the type of signal that the controller can process or that is
needed to drive the actuator. A transducer converts these signals into a compatible form. For
example, a pressure sensor might detect mechanical pressure and convert it into an electrical
signal that the controller can interpret. Similarly, an actuator might require a specific voltage
or current that is supplied by a transducer. Transducers play a crucial role in ensuring
that all parts of the control system can communicate effectively, enabling accurate and
efficient operation.

A1.3 Operating systems and control systems

AINO TH

(;Common
mistake
Avoid oversimplifying
the roles of controlsystem components.
For example, don't

just say that sensors
and actuators
are important —

explain how they
waork together
within feedback
loops to maintain
system stability.
When discussing

Control algorithm
The control algorithm is the set of rules or mathematical procedures that the controller uses
to determine the appropriate output based on the input and feedback it receives. It is the logic

that drives the decision-making process within the controller. Control algorithms can vary in
complexity, from simple proportional control, where the output is adjusted in direct proportion

to the error, to more advanced methods like Proportional-Integral-Derivative (PID) control,
which considers past, present and future errors to make precise adjustments. The choice of
control algorithm depends on the specific requirements of the system, such as the desired
accuracy, speed of response and stability. A well-designed control algorithm is essenrial for
achieving optimal performance and ensuring that the system meets its objectives efficiently
and reliably.

1

Explain the role of the controller in a control system. How does it interact with sensors
and actuators to maintain system stability?

2

Describe how a feedback mechanism works in a closed-loop control system. Why is
feedback essential for maintaining accuracy and stability?

multitasking,

don't just say that
resource allocation is

challenging — discuss
specific risks, such as

3

deadlock or priority
inversion, to show a

Differentiate between open-loop and closed-loop control systems with examples.

Which type is more suitable for complex, dynamic environments?
4

What is the function of a transducer in a control system? Provide an example of a
transducer used in industrial automation.

deeper understanding.
5

Explain the importance of the control algorithm in a control system. How does it
impact the performance and reliability of the system?

A1.3.7 Uses of control systems (HL)
B Home thermostat
A home thermostat controls the room temperature by processing data from a temperature sensor
that continuously monitors the environment. This sensor provides input to the thermostat,

which compares the current temperature to the desired set point. If the temperature deviates
from the set value, the thermostat’s controller processes this information and decides whether to

activate the heating or cooling system to bring the temperature back to the desired level.
The system uses a closed-loop feedback mechanism, where the temperature sensor continually

feeds updated data back to the controller. As the heating or cooling system adjusts the
temperature, the sensor monitors the changes and provides real-time feedback to the thermostat.

B Automatic elevator control
An automatic elevator control system manages the movement of an elevator by processing
input from various sensors, such as those detecting the elevator’s current position, floor

requests and door status. These inputs are fed into the controller, which processes the data to
determine the elevator’s next action, such as moving up or down, stopping at a requested floor

or opening and closing the doors.
The system operates using a closed-loop feedback mechanism. As the elevator moves, sensors
continuously provide real-time updates to the controller about the elevator’s position and
speed. If the elevator needs to stop at a specific floor, the controller adjusts the motor’s
operation to slow down and halt the elevator precisely at the correct floor.
A1 Computer fundamentals

B Autonomous vehicles

x
=

Autonomous vehicles rely on a sophisticated control system that integrates key components
such as sensors, controllers, actuators and transducers to navigate and operate safely without
human input. The system begins with various sensors, including cameras, LiDAR, radar
and GPS, which gather critical data about the vehicle’s environment, such as obstacles, road
conditions and traffic signals. This data serves as the input for the vehicle’s control system.
The controller, often powered by advanced Al algorithms, processes this input using control
algorithms to make real-time decisions about the vehicle’s speed, direction and braking.
The controller then sends commands to the actuators, which carry out these decisions by

controlling the steering, acceleration and braking systems.
The control system operates within a closed-loop feedback mechanism, where sensors
continuously monitor the vehicle’s actions and environment, feeding updated data back to
the controller. This allows the system to adjust its actions in real time, ensuring the vehicle
can adapt to changes such as sudden obstacles or shifting traffic conditions. Transducers play
a crucial role in converting sensor data into signals that the controller can process and in

translating controller commands into the appropriate actions by the actuators.

mergency braking / Pedestrian detection

/ Collision avoidance

Traffic sign

Lane departure

recognition

warning
Cross traffic alert
/

Surround view

Surround view

Rear collision warning

Park assistance

B The sensors used for input and output by an autonomous vehicle

A1.3 Operating systems and control systems

@

[e]
=

-

ATNO TH

Bl Automatic washing machine
An automatic washing machine uses a control system to manage the washing process by
processing input from sensors that monitor water levels, load size and cycle progress. These

inputs are sent to the controller, which determines the appropriate actions, such as filling the
drum with water, agitating the clothes (the motion used by the washing machine to move the

clothes around in the water) or draining the water after the wash cycle.
The system operates with a closed-loop feedback mechanism, where sensors continuously
update the controller on the current state of the washing process. For instance, when the
water reaches the required level, the sensor signals the controller to stop filling and begin the

washing cycle. Similarly, the controller adjusts the duration and intensity of the spin cycle
based on the load size detected by the sensors.

B Traffic signal control system
A traffic signal control system manages the flow of vehicles at intersections by processing
input from sensors that detect the presence of vehicles and pedestrians and sometimes traffic

conditions. These inputs are fed into the controller, which processes the data to determine the
timing and sequence of the traffic lights — when to turn red, amber or green for each direction.
The system operates using a closed-loop feedback mechanism. As vehicles approach the
intersection, sensors detect their presence and provide real-time updates to the controller.

The controller then adjusts the signal timing based on current traffic conditions, such as
extending the green light for a congested lane or triggering a pedestrian crossing light when

needed. By continuously adapting to real-time data, the system optimizes traffic flow and
reduces congestion, contributing to smoother and safer movement through intersections.

B Irrigation control system
An irrigation control system automates the watering of agricultural fields or gardens by
processing input from sensors that monitor soil moisture levels, weather conditions and

sometimes the time of day. These inputs are sent to the controller, which determines when and
how much water should be delivered to the plants.
The system utilizes a closed-loop feedback mechanism, where the sensors continuously
update the controller on the current moisture levels in the soil. If the soil becomes too dry,
the controller activates the irrigation system to deliver the appropriate amount of water. Once
the desired moisture level is reached, the system shuts off the water supply. By responding
dynamically to the actual needs of the soil and plants, the irrigation system conserves water
and ensures optimal growing conditions, avoiding both under- and over-watering.

Bl Home-security system
A home-security system uses a control system to monitor and protect a property by processing
input from various sensors, such as door and window sensors, motion detectors and cameras.
These sensors provide real-time data to the controller, which assesses potential security threats
and determines the appropriate response, such as sounding an alarm, sending notifications to

the homeowner or contacting emergency services.
The system operates within a closed-loop feedback mechanism, where the sensors
continuously send updates to the controller about the status of the home. If a sensor detects an
intrusion, the controller immediately triggers the security protocols, such as locking doors or
activating cameras to record the event.

A1 Computer fundamentals

B Automatic doors
An automatic-door system uses a control system to manage the opening and closing of
doors by processing input from sensors that detect the presence of people or objects near the

entrance. These sensors, such as infrared motion detectors or pressure mats, send signals to
the controller, which then decides when to open or close the doors.
The system operates using a closed-loop feedback mechanism. As soon as the sensors detect
movement or pressure, they trigger the controller to open the doors. Once the person or object
has passed through and the sensors no longer detect any presence, the controller signals the
doors to close.

1

Describe how a control system operates in an autonomous vehicle. What components are
involved, and how do they interact to ensure safe and efficient operation?

2

Compare the control system used in a home thermostat with that of an irrigation control
system. What are the similarities and differences in how these systems maintain the
desired environmental conditions?

3

Explain the importance of a closed-loop feedback mechanism in the operation of an
automatic elevator control system. How does it ensure accurate and safe operation?

4

In the context of a trafficsignal cantrol system, discuss how the control system adapts
to changing traffic conditions. How does the use of sensors and feedback help in
optimizing traffic flow?

5

Describe how a smart home-lighting system operates as a control system. Identify the key
components, including the controller, sensors, actuators and feedback mechanism, and

explain how they interact to automatically adjust the lighting in the home based on the
time of day and occupancy.

1

Simulate a traffic-light control system. If you have access to an Arduino and the components, you can build this for real.
Otherwise, you can use simulation software such as Tinkercad.
Tinkercad instructions:
Step 1: Click on Circuits from the dashboard, and then

O Yellow LED:

click on Create new Circuit.

*

Connect the anode of the yellow LED to pin 12.

Step 2: From the component library, search for and add

*

Connect the cathode to one end of a 220-ohm
resistor.

*

Connect the other end of the resistor to GND.

the following components to your workspace:
[0 One Arduino Uno R3 with breadboard

[ Three LEDs (Red, Yellow, Green) for one traffic light
[0 Three resistors (220 ohms each)
[0

Breadboard (optional, for better organization)

O

Green LED:

*
+

0 Pushbutton (optional, for triggering sensors)
*
*

Connect the longer leg (anode - the bent leg) of

the red LED to pin 13 on the Arduino.
e

Connect the other end of the resistor to the
ground (GND) on the Arduino.

Connect the anode of the green LED to pin 11.
Connect the cathode to one end of a 220-ohm
resistor.
Connect the other end of the resistor to GND.

Step 4 (optional):
O Place a pushbutton on the breadboard.
01 Connect one side of the pushbutton to 5V.
[0 Connect the other side to a digital pin on the Arduino
(e.g. pin 7).
O Add a 10k-ohm resistor connecting the same side of
the pushbutton to GND (which acts as a pull-down
resistor).

A1.3 Operating systems and control systems

.
o
Z

e

=<

Set-up 1:

C++
// Pin assignments for LEDs
int redLED = 13;

int yellowLED = 12;
int greenLED = 11;

void setup()

{

// Set up the LED pins as ocutputs
pinMode(redLED,

OUTPUT);

pinMode(yellowLED,

OUTPUT);

pinMode(greenLED,

OUTPUT);

}
void loop() {
// Turn on the green light for 5 seconds
digitalWrite(greenLED, HIGH);
delay(5000);

// wait 5 seconds

// Turn off green,

turn on yellow for 2 seconds

digitalWrite(greenLED,

LOW);

digitalWrite(yellowLED,

HIGH);

delay(2000);

// wait 2 seconds

// Turn off yellow,

turn on red for 5 seconds

digitalWrite(yellowLED,
digitalWrite(redLED,

delay(5000);

LOW);

HIGH);

// wait 5 seconds

// Turn off red, and repeat the cycle
digitalWrite(redLED,

LOW);

A1 Computer fundamentals

Set-up 2 (with optional pushbutton):

C++
int buttonPin = 7;

// Pin for the sensor

(pushbutton)

int buttonState = 0;

int greenLED = 11; // Pin for green light
int yellowLED = 12; // Pin for vyellow light
int redLED = 13;

// Pin for red light

unsigned long previousMillis = 0; // Variable to store the last time the light
// changed
const long greenlnterval = 5000;

//

// Duration the green light stays on

(in milliseconds)

const long yellowInterval = 2000; // Duration the yellow light stays on
// (in milliseconds)
const long redInterval = 5000;
// (in milliseconds)

// Duration the red light stays on

// Define possible states for the traffic light
enum LightState {GREEN,

YELLOW, RED};

LightState currentState = GREEN;

void setupf()

// Start with the green light on

{

pinMode(buttonPin,

INPUT); // Set the pushbutton pin as an input

pinMode(greenLED, OUTPUT);

// Set the green LED pin as an output

pinMode(yellowLED, OUTPUT);

// Set the yellow LED pin as an output

pinMode(redLED, QUTPUT);

// Set the red LED pin as an output

digitalWrite(greenLED, HIGH); // Initially turn on the green light

}
void loop()

{

unsigned long currentMillis = millis();
buttonState = digitalRead(buttonPin);

switch(currentState)

// Cet the current time in milliseconds
// Read the state of the pushbutton

{

case GREEN:

// If the button is pressed or the green light has been on for the
// full interval

if (buttonState == HIGH || currentMillis - previousMillis >=
greenInterval)

{

A1.3 Operating systems and control systems

digitalWrite(greenLED,

LOW);

digitalWrite(yellowLED,

HIGH); // Turn on the yellow light

// Turn off the green light

currentState = YELLOW;

// Change the state to YELLOW

previousMillis = currentMillis;
// current time

// Reset the timer to the

}
break;

// The YELLOW and RED cases follow similar logic
case YELLOW:
if

(currentMillis - previousMillis »= yellowInterval)
digitalWrite(yellowLED,
digitalWrite(redLED,
currentState

=

{

LOW);

HIGH);

RED;

previousMillis = currentMillis;
// current time

// Reset the timer to the

}
break;

case RED:
if

(currentMillis - previousMillis >= redInterval)
digitalWrite(redLED,

{

LOW);

digitalWrite(greenLED,

HIGH);

currentState = GREEN;
previousMillis = currentMillis;

// Reset the timer toc the

// current time

}
break;

2

Observe how the control system manages the traffic-light sequence and adapts to changes (if a sensor is used).

3

Discuss how the components (LEDs, controller, optional sensor) work together as part of the control system.

4

Discuss the effectiveness of your traffic-light control system and how it could be improved or extended.

Simulate a motor control system where the speed of the motor is adjusted based on feedback from a sensor. It also has

a maximum speed that is set in code and should not be exceeded by the motor. If you have access to an Arduino and the
components, you can build this for real. Otherwise, you can use simulation software such as Tinkercad.
Tinkercad instructions:
Step 1: Click on Circuits from the dashboard, and then click on Create new Circuit.
Step 2: From the component library, search for and add the following components to your workspace:
0 One Arduino Uno R3 with breadboard
One potentiometer
H-Bridge motor driver (L293D)
One DC motor
One 9V battery

Ooooao

1

A1 Computer fundamentals

Step 3:
O Arduino:
* Connect 5V to the bottom positive (red) power rail on the breadboard.
* Connect GND to the bottom negative (black) ground rail on the breadboard.
* Connect the bottom negative (black) ground rail on the breadboard to the top negative (black) ground rail on the
breadboard.
[ Potentiometer:

O

*

Connect Terminal 1 to the ground (GND) on the Arduino.

¢
*

Connect Terminal 2 to the 5V on the Arduino.
Connect Wiper to AO.

9V battery:

* Connect the positive terminal of the battery to the top positive {red) power rail on the breadboard.
* Connect the negative terminal of the battery to the top negative (black) ground rail on the breadboard.
O H-Bridge motor driver (L293D):
* Placeit, ensuring that it straddles the centre gap between the two sides of the breadboard.
e Connect “Enable 1 & 2" to the 5V on the Arduino.
* Connect Power 1 to the 9V on the battery.
¢ Connect all four ground pins to the GND.
* Connect Power 2 to the top positive (red) rail on the breadboard.
¢ Connect Input 1 to pin 5 on the Arduino.
* ConnectInput 2 to pin & on the Arduino.
0O DC motor:
* Connect Terminal 1 to Output 2 on the L293D.
e

Connect Terminal 2 to OQutput 1 on the L293D.

C++
int potValue; // Variable to store the potentiometer input value
int maximumSpeed = 128;
int forwardPin = 5;

// Maximum motor speed (should not be exceeded)

// Pin connected to the forward control input on the

// motor driver
int reversePin = 6 ; // Pin connected to the reverse control input on the
// motor driver

A1.3 Operating systems and control systems

void setup()

{

pinMode(forwardPin,
pinMode(reversePin,
Serial.begin(9600);

QUTPUT);

// Set the forward pin as an output

QUTPUT);

// Set the reverse pin as an output

// Initialize serial communication at 9600 baud for

// debugging

}
void loop() {
potValue = analogRead(A0); // Read the analog value from the potentiometer
// (0-1023)
int motorSpeed = map(potValue,

// value to match PWM range

0,

1023,

0,

255);

// Scale the potentiometer

(0-255)

// Ensure the motor speed does not exceed the desired wvalue

if

(motorSpeed > maximumSpeed)

{

motorSpeed = maximumSpeed;

}
// Write the PWM value to the forward pin

analogiWrite(forwardPin, motorSpeed);
analogWrite(reversePin,

0);

// Ensure reverse pin is off

// Print the motor speed value and desired speed to the serial monitor
Serial
. print("Motor Speed:

");

Serial.print(motorSpeed);
Serial.print("

|

Desired Speed:

");

Serial.println(maximumSpeed);
delay(100); // Short delay to make the serial output readable

Observe how the motor speed changes as the sensor value changes. For example, turning the potentiometer should
increase or decrease the motor speed, depending on the direction.

3

Modify the maximumSpeed in the code to see how the system responds to different target speeds or positions.

N
b WwN -

2

Describe the role of an operating system in organizing files within a directory structure.
Outline the steps an operating system takes to load an application into memory.
Describe the function of memory management within an operating system.
Describe the function of process scheduling in an operating system.

Describe how an operating system ensures security through user authentication.
Compare the advantages and disadvantages of using first come first served (FCFS) and

(2]
3]
(3]
(3]
[2]

round robin (RR) scheduling algorithms in operating systems.

(4]

7

Explain how priority scheduling can cause some processes to be ignored or delayed in
an operating system. Describe a way to prevent this problem.

(4]

8

Discuss how event frequency and CPU processing overheads influence the choice

between interrupt handling and polling.
9 Describe the role of the operating system in preventing deadlock during multitasking.
10 Describe how an irrigation control system operates as a control system. What components
are involved, and how do they interact to ensure optimal watering conditions?

[4]
(3]

[4]

A1 Computer fundamentals

Translation

SYLLABUS CONTENT
By the end of this chapter, you should be able to:
» A1.4.1 Evaluate the translation processes of interpreters and compilers

A1.4.1 Translation processes of

interpreters and compilers
Understanding the translation processes of interpreters and compilers is essential for grasping
how programming languages are executed by computers. Interpreters and compilers both

transform high-level code into machine-readable instructions, yet they do so through different
methods, each with unique implications for performance, error handling and development

efficiency. This section delves into the specifics of how interpreters and compilers function,
examining their respective strengths and weaknesses and how these impact the choice of
translation method for different programming scenarios.

H Interpreters
Source code
(high-level
programming language)

Interpreter

Executable code
(machine language) /
output

Get next
instruction

M The interpreter process

Mechanics
Interpreters translate high-level programming code into machine code line-by-line or
statement-by-statement, executing each line as it is translated. Unlike compilers, interpreters
do not generate an intermediate machine-code file; instead, they directly execute the source
code on the fly. This means that the interpreter reads the code, translates it and runs it
immediately, repeating this process for each line or block of code until the entire program has
been executed.
One key characteristic of interpreters is their ability to start executing a program without
needing to process the entire codebase upfront. This allows for immediate feedback, which
is particularly useful during the development and debugging phases. However, this line-byline execution can result in slower overall performance compared to compiled code, as the
interpreter must repeatedly translate and execute code during each run of the program.

A1.4 Translation

Use cases
Interpreters are commonly used in scenarios where quick testing and debugging are essential.
Languages including Python, JavaScript and Ruby are often interpreted, making them popular

choices for web development, scripting and rapid application development. The ability
to execute code immediately withourt a lengthy compilation process allows developers to

experiment and iterate quickly. Additionally, interpreters are ideal for educational purposes,
as they enable beginners to see the results of their code in real time, making it easier to

understand programming concepts.
Interpreters are also favoured in environments where portability is important. Since the

interpreter itself handles the execution, the same source code can be run on different platforms
without modification, provided the appropriate interpreter is available on each platform.

B Compilers
Source code

(high-level language) —

Object code

Compiler

(machine language)

M The compiler process

Mechanics
Compilers, in contrast to interpreters, translate the entire high-level source code into machine

(;Top tip!
An interpreter is
like someone who
translates each
sentence of a book
for you as you read,
providing immediate
understanding but
requiring them to
translate each line

code in a single, comprehensive process betore the program is executed. This process involves
several stages, including lexical analysis, syntax analysis, semantic analysis, optimization and

code generation. The final output is a standalone executable file, typically in machine code or
an intermediate form like bytecode, which can be run directly on the target machine.
Omnce compiled, the machine code does not need further translation, allowing the program to
execute much faster than interpreted code. However, the initial compilation process can be
time-consuming, especially for large and complex programs. Additionally, because the entire
code must be compiled before execution, any errors in the source code need to be addressed

before the program can run, which can slow down the development cycle.

every time you

Use cases

revisit it.

Compilers are typically used in scenarios where performance is a critical concern. Languages

In contrast, a

including C, C++ and Java (which compiles to bytecode for the JVM) are compiled, making

compiler is like a
translator who first
converts the entire

book into your native
language, allowing you
to read it smoothly
without needing
further translation, but
requiring you to wait
until the whole book is
translated before you
can start reading.

them well suited for system software, application development and situations requiring highperformance execution, such as video games or real-time processing systems.
Compiled code is also advantageous in environments where security and resource control are
important. Since the machine code is pre-generated and optimized, it can be more difficult
for malicious actors to reverse-engineer, and the execution is less dependent on external
environments compared to interpreted code.
Compilers are often chosen when the software needs to be deployed across various
environments with different hardware specifications. The compilation process can be tailored
to oprimize the executable for specific architectures, resulting in better performance and
resource usage on the larget system.

A1 Computer fundamentals

B Advanced compilers and interpreters
Source code

Bytecode interpreters

Java file

{program)

Mechanics:

/%

Bytecode interpreters operate by first translating high-

Compiler

level source code into an intermediate form known as

_l—/

“bytecode”. This bytecode is not directly executed by
the machine’s hardware, but is instead run on a virtual

Bytecode

Machine code

~

|
Machine code

-~

JVM (Linux)
J

-

I

~N -

—

platform-independent representation of the program,

VM (Mac)

which allows it to be executed on any system that has the

|

appropriate VM or interpreter. The bytecode interpreter

Machine code

\

~

JVM (Windows)

X

machine (VM) or an interpreter that understands the

bytecode’s instructions. The bytecode serves as a compact,

“

s

—

«lass file

reads and executes the bytecode instructions, often with
some optimizarion, though it typically does so at a slower
pace than fully compiled machine code because each

M The Java Bytecode interpretation process

instruction is interpreted at runtime.

Use cases:

Bytecode interpreters are widely used in scenarios where portability and cross-platform
compatibility are important. Java is a prime example, where code is compiled into bytecode
that runs on the Java Virtual Machine (JVM). This allows Java applications to run on any
platform with a JVM, making it ideal for enterprise applications, web services and mobile apps
that need to operate across diverse environments. Python also uses a similar approach, where
the source code is compiled into bytecode (with the .pyc extension) and then executed by
the Python interpreter. This makes bytecode interpreters useful in educational settings, web
development and scripting, where flexibility and ease of deployment are more critical than
raw performance.

Just-in-time (JIT) compilation
Mechanics:
Just-in-time (JIT) compilation is a dynamic approach that combines elements of both

interpretation and compilation. Initially, the source code is compiled into bytecode, which
is then interpreted by a virtual machine. As the program runs, the JIT compiler identifies

frequently executed sections of the bytecode — often called “hot spots” — and compiles them
into machine code on the fly. This machine code is then cached, so the next time the same
code is executed, the system uses the compiled version instead of interpreting it again. This
process allows JIT-compiled code to execute much faster than interpreted code, while still
offering the flexibility and platform independence of bytecode.
Use cases:

JIT compilation is particularly beneficial in environments where performance is critical, but
where the application also needs to be portable and dynamically optimized. The Java Virtual

Machine (JVM) and the NET runtime both use JIT compilation to improve the performance of
applications. This approach is especially valuable in long-running applications, such as servers,

where the overhead of JIT compilation is outweighed by the performance gains in subsequent
executions of the same code paths. JIT is also used in web browsers for JavaScript execution,

where it optimizes [requently used scripts to improve page load times and responsiveness. In
general, JIT compilation is well suited for scenarios where applications need to balance the
need for speed with the ability to run on multiple platforms.
A1.4 Translation

B Evaluation of different translation processes
Error detection
Error detection varies significantly across these translation processes. Compilers offer the

most robust error detection because they analyse the entire source code before producing an
executable. This analysis ensures that all syntax and some semantic errors are caught and

must be resolved before the program can run, resulting in fewer runtime errors and a more
stable final product.
Interpreters detect errors at runtime, as they execute code line by line. This approach allows
developers to quickly identify and correct errors during development, which is especially
useful for testing and debugging. However, because errors are only discovered when the
specific problematic code is executed, there is a risk of encountering runtime errors that could
disrupt program execution unexpectedly.

Bytecode interpreters provide a middle ground. While they do compile source code into
bytecode before execution, allowing for some upfront error detection, errors may still occur at
runtime as the bytecode is interpreted. This combination of pre-runtime error-checking with
runtime interpretation can reduce the frequency of runtime errors compared to traditional
interpreters, but it does not offer the exhaustive error-checking of full compilation.
JIT compilation combines elements of both interpretation and compilation. While some errors
may still be detected at runtime, the JIT compiler’s ability to dynamically compile frequently
executed bytecode into machine code during execution can catch and optimize issues in
repeated executions, improving the reliability of long-running programs.

(.-Common mistake
Be careful not to underestimate the differences in error detection between interpreters and compilers.
With interpreters, errors are caught as the code runs, which means they can occur unexpectedly
during execution.
Compilers catch all syntax and some semantic errors before the program runs, preventing the
program from executing until these errors are fixed.

In these exercises, you will explore the differences in error detection between an interpreted
language (Python) and a compiled language (Java). By running and compiling short programs in
both languages, you will observe how and when errors are detected, providing insight into the
advantages and challenges of each approach.
1

Run the Python script below and observe what happens when the interpreter encounters

the error. What is the last line of output before the program crashes? What error message
is displayed?
"
1
1 Python
1
1 def greet (name) :
1
:

print ("Hello,

"

+ name +

"!")

:

greet ("Alice")

I
1
1
1

# Intentional error: Trying to use an undefined variable
print ("The length of the name is " + str(len(name)))

.
1
i
1
1
1
1
1
1
1
1
1
1
1

A1 Computer fundamentals

2

Attempt to compile the program below and observe what happens when the compiler
encounters the error. Does the program compile successfully? What error message is displayed?

. Java
public class SimpleProgram {
public static void main(String[]
System.out.println("Hello,

args)

{

World!");

// Intentional error: Missing semicolon
System.out.println("This line has a syntax error")

Compare the outcomes of running the Python script and compiling the Java program.
3

At what point is the error detected in each language?

4

How does the error-detection process affect the development workflow in each language?

5

What are the advantages and disadvantages of detecting errors at runtime vs at

compile time?

Translation time
Compilers require a considerable amount of time initially to convert the entire source code
into machine code before it can be executed. While this process may take longer, especially
with large projects, the payoff is that the compiled program runs significantly faster once the
translation is completed.
Interpreters, by contrast, execute code directly by translating it line by line. This allows the
program to run almost immediately, which is advantageous for quickly testing and iterating
code. However, because the code is translated during execution, programs with larger
codebases may experience slower overall performance.
Bytecode interpreters provide a balance between these approaches. The initial step of
compiling source code into bytecode is quicker than fully compiling it into machine code. The
bytecode is then executed more efficiently than direct interpretation of source code, resulting

in a compromise between start-up speed and execution efficiency.
JIT compilation goes a step further by converting bytecode into machine code dynamically
as the program runs. Although this introduces some runtime overhead, it enables the system
to optimize performance on the fly, particularly for code paths that are executed frequently.
This dynamic approach allows JIT to reduce initial translation time while improving execution

speed as the program continues to run.

Portability
Portability is a significant advantage of interpreters and bytecode interpreters. Since
interpreters execute source code directly, the same code can run on any platform with the
appropriate interpreter, making it ideal for cross-platform applications. Bytecode interpreters
extend this portability by compiling source code into a platform-independent bytecode, which
can be executed on any system with the appropriate virtual machine (for example Java's JVM).
This makes bytecode interpreters particularly valuable in environments where applications
must operate across diverse platforms without modification.

A1.4 Translation

-

Compilers, however, produce machine code tailored to specific hardware architectures, resulting
in highly efficient but less portable executables. Each target platform may require separate
compilation, limiting the flexibility of deploying the same code across multiple environments.

JIT compilation preserves the portability of bytecode while enhancing performance. The
bytecode can be distributed across different platforms, and the JIT compiler dynamically

optimizes the execution for the specific hardware at runtime. This combination ensures that
applications remain portable while still benefiting from platform-specific optimizations.

(.-Common mistake
It is easy to overlook the importance of portability. Interpreters and bytecode interpreters allow

the same code to run on different platforms without modification, as long as the appropriate
interpreter or virtual machine is available. Compiled code is optimized for specific hardware,
making it less portable.

Applicability
The applicability of these translation processes varies depending on the requirements of
the project. Compilers are best suited for applications where performance is critical, such
as system software, high-performance computing and real-time systems. The upfront time
investment in compilation is justified by the high execution speed of the compiled code.
Interpreters are ideal for scenarios where rapid development, testing and iteration are essential,
such as in scripting, web development and educational environments. Their immediate
execution and ease of use make them suitable for applications where flexibility and quick
feedback are more important than raw performance.

Bytecode interpreters are commonly used in enterprise applications, web services and mobile
apps where cross-platform compatibility is crucial. They offer a tlexible solution that balances
the need for portability with efficient execution, making them suitable for environments that
demand both.
JIT compilation is particularly valuable in long-running applications and complex systems
where performance needs to improve over time. It is well suited for server environments,
dynamic web applications and platforms such as Java and .NET, where the balance of
portability, performance and dynamic optimization is critical.
Criteria

Compilers

Interpreters

Bytecode interpreters

JIT compilation

Error detection

Comprehensive, with
all errors caught
before execution

Runtime errors detected as
code is executed line by line

Some errors are caught
before execution, but others
at runtime

Combines runtime
error detection with
dynamic optimization

Translation time

High initial translation time,
but results in fast execution

Immediate execution, low
initial translation time, but
slower overall execution

Moderate initial translation
time, with moderately
fast execution

Balances initial translation
with dynamic compilation
for optimized execution

Portability

Low; requires separate
compilation for
each platform

High; code runs on
any platform with the
appropriate interpreter

High; bytecode is platformindependent and runs
on any system with the
appropriate VM

High; maintains portability
with platform-specific
optimizations at runtime

Applicability

Best for performance-critical | Ideal for rapid development, | Suited for cross-platform
applications and
testing and cross-platform
applications with moderate
system software
scripting
performance needs

Well suited for long-running
applications requiring
dynamic optimization

A1 Computer fundamentals

Hl Example scenarios
Scenario

Best translation method | Explanation

Rapid development | Interpreters

*

and testing

|nterpreters allow immediate execution of code,
enabling quick iterations, debugging and real-time
feedback

Performance-critical | Compilers

*

|deal for scripting languages such as Python
or JavaScript

*

Compilers optimize the entire codebase into

applications

machine code before execution, resulting in highly
efficient and fast-performing applications
®

Suitable for system software, gaming and real-time
systems using languages such as C or C++

Cross-platform

Bytecode interpretersand | e

Bytecode interpreters (e.g. Java's JVM) provide

development

JIT compilation

platform independence by compiling code into
an intermediate bytecode, which can run on any
platform with the appropriate virtual machine
®

JIT compilation enhances performance by optimizing

frequently executed code at runtime, balancing
portability with execution speed
®

|deal for applications such as enterprise software,
maobile apps and web services

Rapid development and testing
Example: A startup developing a prototype web application using Python.

The team needs to quickly test and iterate on their codebase, making adjustments on the
fly. An interpreter allows them to run their code immediately and see the results of changes

without waiting for compilation.

Performance-critical applications
Example: A company developing a real-time trading system in C++ that requires high-speed
dara processing with minimal latency.
A compiler is used to translate the entire codebase into optimized machine code, ensuring the
system performs at the highest efficiency possible.

Cross-platform development
Example: A software firm creating an enterprise-level application in Java that needs to run on
Windows, macOS and Linux environments.

By compiling the code into bytecode, the application can be run on any platform with the Java
Virtual Machine (JVM). To enhance performance, the JVM’s JIT compiler further optimizes

the application’s execution on each specific platform.

1
2
3

A1.4 Translation

Compare the advantages and disadvantages of using a compiler vs an interpreter in
software development.
Describe the process of just-in-time (JIT) compilation and explain how it combines
elements of both interpretation and compilation.
Compare the error-detection capabilities of compilers and interpreters, and discuss the
implications for software development.

(4]
[4]
[4]

sesssssssssssssesssananaans

@ Linking questions
1
2

What role does multitasking in an operating system play in machine learning? (A4)
How might a conditional statement be constructed by Boolean logic gates in a circuit? (82)

3

What role does task scheduling in an operating system play in managing network traffic
and requests? (A1)

4

How does resource allocation in an operating system impact network performance

3

and stability? (A2)

5
6

What role do GPUs play in non-graphics computational tasks? (A4)
To what extent should computer systems not cause harm? (TOK)

A1 Computer fundamentals

A2 Networks

Network fundamentals

What are the principles and concepts that underpin how networks operate?

SYLLABUS CONTENT
By the end of this chapter, you should be able to:
> A2.1.1 Describe the purpose and characteristics of networks
» A2.1.2 Describe the purpose, benefits and limitations of modern digital infrastructures
» A2.1.3 Describe the function of network devices
» A2.1.4 Describe the network protocols used for transport and application
> A2.1.5 Describe the function of the TCP/IP model (HL)

A2.1.1 The purpose and
characteristics of networks
Welcome to computer networks. In recent decades, networks have become an all-pervasive

+ Computer
network: a system that

and integral part of our modern lives. We use networks to:

connects computers

u instantly communicate and collaborate with people around the world

and other devices
to share resources
(digital or physical)
and information.
# Local area network:
a system that connects

computers and other
devices within a small
geographical area, such
as an office or home.

u access a wealth of information, entertainment and services at our fingertips
u

conduct business transactions, banking and online shopping with ease

B learn new skills, attend virtual classes and expand our knowledge
B remotely control and monitor our homes, cars and other connected devices

u share photos, videos and stories with family and friends in real time.
The power and ubiquity of computer networks have truly transformed the way we live, work
and play. In this chapter, we will delve into the inner workings of these complex systems that
have become so ubiquitous that we barely give them a moment’s thought— except when things

g0 wrong.

B Local area networks (LAN)
A local area network is a network of computers that are interconnected in a small geographical
location, typically limited to a single property such as a home, building or campus. These are
the oldest types of networks, though the equipment used in modern versions looks nothing

like the historical versions.
The purpose of these networks is to facilitate sharing resources between the different computers,
such as files, printers, applications and access to external networks, such as the interner.
LANSs typically have a high bandwidth internally, with speeds ranging from 100 Mbps
(Megabits per second) to 10 Gbps (Gigabits per second). Their small geographical range

means there are typically no issues with latency (the time delay for data to transmit across
the network).
Most homes and many corporate LANs now use a mix of wired Ethernet cables and wireless
networking technologies. Dedicated wireless LANs may sometimes be referred to as WLANS.

A1 Computer fundamentals
Al.1 Computer hardware and operation
Al.2 Data representation and computer logic
Al.3 Operating systems and control systems
Al.4 Translation (HL only)

